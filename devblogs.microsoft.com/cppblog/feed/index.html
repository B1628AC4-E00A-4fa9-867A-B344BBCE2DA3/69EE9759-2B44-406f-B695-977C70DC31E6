<?xml version="1.0" encoding="UTF-8"?><rss version="2.0"
	xmlns:content="http://purl.org/rss/1.0/modules/content/"
	xmlns:wfw="http://wellformedweb.org/CommentAPI/"
	xmlns:dc="http://purl.org/dc/elements/1.1/"
	xmlns:atom="http://www.w3.org/2005/Atom"
	xmlns:sy="http://purl.org/rss/1.0/modules/syndication/"
	xmlns:slash="http://purl.org/rss/1.0/modules/slash/"
	>

<channel>
	<title>C++ Team Blog</title>
	<atom:link href="https://devblogs.microsoft.com/cppblog/feed/" rel="self" type="application/rss+xml" />
	<link>https://devblogs.microsoft.com/cppblog/</link>
	<description>C++ tutorials, C and C++ news, and information about Visual Studio, Visual Studio Code, and Vcpkg from the Microsoft C++ team.</description>
	<lastBuildDate>Tue, 13 Dec 2022 18:30:28 +0000</lastBuildDate>
	<language>en-US</language>
	<sy:updatePeriod>
	hourly	</sy:updatePeriod>
	<sy:updateFrequency>
	1	</sy:updateFrequency>
	

<image>
	<url>https://devblogs.microsoft.com/cppblog/wp-content/uploads/sites/9/2018/10/Microsoft-Favicon.png</url>
	<title>C++ Team Blog</title>
	<link>https://devblogs.microsoft.com/cppblog/</link>
	<width>32</width>
	<height>32</height>
</image> 
	<item>
		<title>Standards conformance improvements to /Gw in Visual Studio version 17.5 Preview 2</title>
		<link>https://devblogs.microsoft.com/cppblog/standards-conformance-improvements-to-gw-in-visual-studio-version-17-5-preview-2/</link>
					<comments>https://devblogs.microsoft.com/cppblog/standards-conformance-improvements-to-gw-in-visual-studio-version-17-5-preview-2/#respond</comments>
		
		<dc:creator><![CDATA[Kyle Brady]]></dc:creator>
		<pubDate>Tue, 13 Dec 2022 17:01:41 +0000</pubDate>
				<category><![CDATA[C++]]></category>
		<guid isPermaLink="false">https://devblogs.microsoft.com/cppblog/?p=31355</guid>

					<description><![CDATA[<p>The /Gw switch enables the linker to optimize global data to reduce binary size. As part of the 17.5 Preview 2 release a new flag, /Zc:checkGwOdr[-], has been added to improve C++ standards conformance when using /Gw. Previously, when using /Gw,</p>
<p>The post <a rel="nofollow" href="https://devblogs.microsoft.com/cppblog/standards-conformance-improvements-to-gw-in-visual-studio-version-17-5-preview-2/">Standards conformance improvements to /Gw in Visual Studio version 17.5 Preview 2</a> appeared first on <a rel="nofollow" href="https://devblogs.microsoft.com/cppblog">C++ Team Blog</a>.</p>
]]></description>
										<content:encoded><![CDATA[<p>The <a href="https://learn.microsoft.com/en-us/cpp/build/reference/gw-optimize-global-data">/Gw switch</a> enables the linker to optimize global data to reduce binary size. As part of the 17.5 Preview 2 release a new flag, <code>/Zc:checkGwOdr[-]</code><em>,</em> has been added to improve C++ standards conformance when using <code>/Gw</code>. Previously, when using <code>/Gw</code>, certain One Definition Rule (ODR) violations were being ignored and would not cause an error. The new flag ensures that we do raise the appropriate errors. If you are currently using <code>/Gw</code> we recommend setting <code>/Zc:checkGwOdr</code> on your builds, as it’s currently off by default. This may change in a future major update. For a more detailed explanation of ODR, <code>/Gw</code>, and how this issue came about, read on below.</p>
<p>Let’s go through three definitions that we need for background here:</p>
<ol>
<li>First up are COMDATs, a short description is that COMDATs are extra segments that data can be placed in to enable the linker to potentially fold out said data from the binary. Importantly, these sections are flagged with a strategy for how duplicates are handled. For a deeper dive into the history of COMDATs, see <a href="https://devblogs.microsoft.com/oldnewthing/20161024-00/?p=94575">Raymond’s blog post which covers their use and history</a>.</li>
<li>Next, just what does <code>/Gw</code> do? For a full explanation, check out the <a href="https://devblogs.microsoft.com/cppblog/introducing-gw-compiler-switch/">blog post announcing the switch</a>, but for our purposes the flag enables the compiler to place global data into COMDATs. This lets us optimize out unreferenced globals, or merge identical globals via their COMDAT sections</li>
<li>Finally, the One Definition Rule (ODR) <a href="https://en.wikipedia.org/wiki/One_Definition_Rule">as described on Wikipedia</a>.</li>
</ol>
<p>With the background out of the way we’ll go through a simple but common enough example:</p>
<p><strong>odr.h:</strong></p>
<pre class="prettyprint language-cpp"><code class="language-cpp">#pragma once
// defining a global here is an ODR violation
// the initialization to 0 isn’t required to cause a violation
// but is needed to exhibit the incorrect /Gw behavior
int MyGlobal = 0;</code></pre>
<p><strong>bar.cpp:</strong></p>
<pre class="prettyprint language-cpp"><code class="language-cpp">#include "odr.h"
int bar() {
    return 2;
}</code></pre>
<p><strong>foo.cpp:</strong></p>
<pre class="prettyprint language-cpp"><code class="language-cpp">#include "odr.h"
int foo() {
   return 1;
}

extern int bar();

int main() {
   foo();
   bar();
}
</code></pre>
<p>Compiling this without <code>/Gw</code> leads to an error as we’d expect:</p>
<pre class="prettyprint language-default"><code class="language-default">cl /nologo foo.cpp bar.cpp
foo.cpp
bar.cpp
Generating Code...
bar.obj : error LNK2005: "int MyGlobal" (?MyGlobal@@3HA) already defined in foo.obj
foo.exe : fatal error LNK1169: one or more multiply defined symbols found</code></pre>
<p>Since we defined <code>MyGlobal</code> in <code>odr.h</code>, we end up with a definition in both <code>foo.obj</code> &amp; <code>bar.obj</code>, causing the linker to report the ODR violation. Now, if we compile with <code>/Gw</code>:</p>
<pre class="prettyprint language-default"><code class="language-default">cl /nologo /Gw foo.cpp bar.cpp
foo.cpp
bar.cpp
Generating Code...</code></pre>
<p>We don’t end up with an error, so what happened? It ends up coming back to the COMDAT flags mentioned above. Looking at the obj headers, we can see that <code>MyGlobal</code> has indeed been placed in a COMDAT:</p>
<pre class="prettyprint language-default"><code class="language-default">link.exe /dump /headers foo.obj
…
SECTION HEADER #3
    .bss name
    …
C0301080 flags
         Uninitialized Data
         COMDAT; sym= "int MyGlobal" (?MyGlobal@@3HA)
         4 byte align
         Read Write</code></pre>
<p>What this doesn’t show is that this COMDAT has been flagged as PICKANY. So, when multiple definitions that would be candidates for merging are found the linker arbitrarily picks one of them and discards the rest. This is odd though, when <code>/Gw</code> is enabled this COMDAT was flagged with NOMATCH on creation. NOMATCH, as the name implies, means that the linker should raise an error if a duplicate is found, exactly what we want. So, what went wrong?</p>
<p>The key here is that the definition of <code>MyGlobal</code> includes an assignment to zero. This causes another optimization to kick in. Since this global is initialized to zero, we notice that it can be moved into the <a href="https://en.wikipedia.org/wiki/.bss">.bss section</a>. Since we don’t have to store the data for this global if it’s in <code>.bss</code>, moving the COMDAT lets us reduce the object file size. Unfortunately, when we move the COMDAT the flag was being reset from NOMATCH to PICKANY, causing our bug.</p>
<p>As of 17.5 Preview 2 you can now use the new flag to make sure you’re not hiding these ODR violations on accident with <code>/Gw</code>:</p>
<pre class="prettyprint language-default"><code class="language-default">cl /nologo /Gw /Zc:checkGwOdr foo.cpp bar.cpp
foo.cpp
bar.cpp
Generating Code...
bar.obj : error LNK2005: "int MyGlobal" (?MyGlobal@@3HA) already defined in foo.obj
foo.exe : fatal error LNK1169: one or more multiply defined symbols found</code></pre>
<p>With the error exposed, we can make the global extern in our header, and move the definition to one of the cpp files to resolve the problem:</p>
<p><strong>odr.h:
</strong></p>
<pre class="prettyprint language-cpp"><code class="language-cpp">#pragma once
extern int MyGlobal;</code></pre>
<p><strong>foo.cpp:</strong></p>
<pre class="prettyprint language-cpp"><code class="language-cpp">#include "odr.h"
int MyGlobal = 0;
…</code></pre>
<pre class="prettyprint language-default"><code class="language-default">cl /nologo /Gw /Zc:checkGwOdr foo.cpp bar.cpp
foo.cpp
bar.cpp
Generating Code...</code></pre>
<p>Alternatively, for C++17 and higher, you can use an <a href="https://en.cppreference.com/w/cpp/language/inline">inline specifier</a> on the definition:</p>
<p><strong>odr.h:</strong></p>
<pre class="prettyprint language-cpp"><code class="language-cpp">inline int MyGlobal = 0;</code></pre>
<p>Usually fixing an ODR violation looks something like this, though not every case will be so simple. We encourage using <code>/Zc:checkGwOdr</code> to prevent these violations from creeping into your builds if you’re using <code>/Gw</code>. As this is a standards conformance issue, we may change the default behavior of <code>/Gw</code> to imply <code>/Zc:checkGwOdr</code> in a future release.</p>
<h4 id="send-us-your-feedback">Send us your feedback</h4>
<p>We hope you found these details interesting! If you have ideas for similar posts you’d like to see, please let us know. We are also interested in your feedback to continue to improve our tools. The comments below are open. Feedback can also be shared through <a href="https://developercommunity.visualstudio.com/cpp" target="_blank" rel="noopener">Developer Community</a>. You can also reach us on Twitter (<a href="https://twitter.com/visualc" target="_blank" rel="noopener">@VisualC</a>), or via email at <a href="mailto:visualcpp@microsoft.com">visualcpp@microsoft.com</a>.</p>
<p>&nbsp;</p>
<p>The post <a rel="nofollow" href="https://devblogs.microsoft.com/cppblog/standards-conformance-improvements-to-gw-in-visual-studio-version-17-5-preview-2/">Standards conformance improvements to /Gw in Visual Studio version 17.5 Preview 2</a> appeared first on <a rel="nofollow" href="https://devblogs.microsoft.com/cppblog">C++ Team Blog</a>.</p>
]]></content:encoded>
					
					<wfw:commentRss>https://devblogs.microsoft.com/cppblog/standards-conformance-improvements-to-gw-in-visual-studio-version-17-5-preview-2/feed/</wfw:commentRss>
			<slash:comments>0</slash:comments>
		
		
			</item>
		<item>
		<title>High-confidence Lifetime Checks in Visual Studio version 17.5 Preview 2</title>
		<link>https://devblogs.microsoft.com/cppblog/high-confidence-lifetime-checks-in-visual-studio-version-17-5-preview-2/</link>
					<comments>https://devblogs.microsoft.com/cppblog/high-confidence-lifetime-checks-in-visual-studio-version-17-5-preview-2/#comments</comments>
		
		<dc:creator><![CDATA[Gabor Horvath]]></dc:creator>
		<pubDate>Tue, 13 Dec 2022 17:01:00 +0000</pubDate>
				<category><![CDATA[C++]]></category>
		<category><![CDATA[Diagnostics]]></category>
		<guid isPermaLink="false">https://devblogs.microsoft.com/cppblog/?p=31435</guid>

					<description><![CDATA[<p>New High-confidence Lifetimes Checks in Visual Studio 2022</p>
<p>The post <a rel="nofollow" href="https://devblogs.microsoft.com/cppblog/high-confidence-lifetime-checks-in-visual-studio-version-17-5-preview-2/">High-confidence Lifetime Checks in Visual Studio version 17.5 Preview 2</a> appeared first on <a rel="nofollow" href="https://devblogs.microsoft.com/cppblog">C++ Team Blog</a>.</p>
]]></description>
										<content:encoded><![CDATA[<p>The C++ team is committed to making your C++ coding experience as safe as possible. We are adding richer code safety checks and addressing high impact customer feedback bugs posted on the <a href="https://developercommunity.visualstudio.com/search?space=62">C++ Developer Community</a> page. Thank you for engaging with us and giving us great feedback on the past releases and early previews leading to this point. Below is the detailed overview of the improvements we made to the lifetime analysis.</p>
<h2 id="overview">Overview</h2>
<p>The C++ Core Guidelines’ Lifetime Profile, aims to detect lifetime problems, like dangling pointers and references, in C++ code. For more information on the history and goals of the profile, check out <a href="https://herbsutter.com/2018/09/20/lifetime-profile-v1-0-posted/">Herb Sutter’s blog post about version 1.0</a>. It has been quite a while <a href="https://devblogs.microsoft.com/cppblog/lifetime-profile-update-in-visual-studio-2019-preview-2/">since we last talked about</a> lifetime analysis. The Lifetime rules have good defaults for common cases so that they don&#8217;t require any annotations for most code. Where annotations are needed, we designed the syntax to follow the ISO C++ contracts proposals&#8217; syntax, and in the meantime while work on that syntax still in progress, we have focused implementation of the lifetime analysis on the other parts that do not require annotations. Support for the non-default lifetime annotations will be added later. Lately, there has been an increased push in the C++ community to introduce lifetime-related safety features, which has led us to revisit the lifetime analysis in MSVC.</p>
<p>We spent the last couple of months looking into the results of using the lifetime analysis on real world code. This blog post summarizes our experience and the improvements we made along the way. The biggest change is the introduction of a new set of warnings. These warnings are the high-confidence versions of the existing warnings. Users who want less noise can enable only the high-confidence warnings, while users who want more rigorous checks at the cost of noise can enable both the old and the new warnings. As of 17.5, the high-confidence warnings are still experimental, but depending on the feedback we might include them in some of the recommended profiles in future versions.</p>
<h2 id="high-confidence-warnings">High-confidence warnings</h2>
<p>Lifetime analysis was originally designed to work well with code written in a specific style that closely follows some of the recommendations of the C++ Core Guidelines. These recommendations include avoiding return arguments, naked unions, and replacing pointer arithmetic with higher level abstractions like <code>span</code>. Consequently, analysis has not worked well with arbitrary code out of the box. The goal of these newer, high-confidence warnings is to be applicable for a wider range of code bases (at the cost of potentially missing more bugs).</p>
<h2 id="case-study">Case study</h2>
<p>Before diving into how the new warnings work let&#8217;s look at a case study.
We tested the analysis on multiple internal projects that did not follow the best practices the lifetime analysis expects. I wanted to share some data regarding one of them. This internal project is a software component from Windows.
The first column represents the baseline before we started to implement any adaptations for legacy code, the after represents the sate of lifetime analysis as of 17.5 Preview 2.</p>
<table>
<thead>
<tr>
<th></th>
<th>Before</th>
<th>After</th>
</tr>
</thead>
<tbody>
<tr>
<td>Compile-time cost</td>
<td>+5.2%</td>
<td>+3.5%</td>
</tr>
<tr>
<td>Lifetime warnings (regular)</td>
<td>2777</td>
<td>2074</td>
</tr>
<tr>
<td>Lifetime warnings (high-confidence)</td>
<td>0</td>
<td>6</td>
</tr>
<tr>
<td>Assertion failures in the analysis</td>
<td>109</td>
<td>1</td>
</tr>
</tbody>
</table>
<p>It takes ~50 minutes to compile and analyze this codebase. Turning on lifetime analysis increased the processing time by 5.2%. After the improvements we could reduce this overhead to 3.5%. If the compilation time cost of turning lifetime analysis on looks reasonable, that is great! One of the design goals of the analysis was to make it efficient enough to run regularly at build time, and we think this implementation is now efficient enough to turn on by default in most projects.</p>
<p>We also managed to fix many assertion failures. Most importantly, the newly introduced high-confidence warnings only emitted a manageable 6 warnings on this project, and all of them happened to uncover real problems!
While on some other projects we still see some noise from the high-confidence warnings, the number of results is definitely much more manageable. So it is our recommendation that you give the high-confidence warnings a try! Don&#8217;t forget to report the bugs you encounter to help us further improve these checks.</p>
<p>Our fixes were focused primarily on reducing noise for high-confidence warnings, they also had the effect of reducing the noise of the lower-confidence warnings by almost 35%!
Note that the high number of regular warnings is expected as the test codebase does not follow the C++ Core Guidelines and does not have any lifetime annotations in place.</p>
<h2 id="adapting-lifetime-analysis-to-arbitrary-coding-styles">Adapting lifetime analysis to arbitrary coding styles</h2>
<p>This section discusses the sources of noise from lifetime analysis on certain code bases and explains how we addressed them.</p>
<h3 id="adapting-flow-sensitivity-to-complex-control-flow">Adapting flow-sensitivity to complex control flow</h3>
<p>Consider the following code snippet:</p>
<pre><code class="language-cpp">void f(bool b) {
    int* p = nullptr;
    int x;
    if (b) {
        p = &amp;x;
    }
    // ...
    if (b) {
       *p = 42;  // Location A.
    }
}</code></pre>
<p>Because the lifetime analysis is flow-sensitive, it warns at location <code>A</code> because <code>nullptr</code> is in the set of potential values of <code>p</code> across all branches. This warning is a false positive as the execution path where the value of <code>p</code> is <code>nullptr</code> and we later dereference <code>p</code> cannot be realized at runtime because of the correlated branches. We call such paths infeasible. Warnings from infeasible execution paths are a common source of noise. This problem can be mitigated using path-sensitive analysis that will reason about the branches and their correlations. Unfortunately, path-sensitive analysis is expensive and far from perfect. Consider the following slightly modified example:</p>
<pre><code class="language-cpp">bool cond();
void f(bool b) {
    int* p = nullptr;
    int x;
    if (cond()) {
        p = &amp;x;
    }
    // ...
    if (cond()) {
       *p = 42;  // Location A.
    }
}</code></pre>
<p>The conditions are now replaced with a call to a function that potentially defined in another library. To check how the two branches are correlated, we would need to do inter-procedural analysis. Inter-procedural, path-sensitive analysis can be really expensive, for instance if the branch correlation depends on a really deep call stack, or outright infeasible if the source code of <code>cond</code> is not available (e.g. from a proprietary library). Instead of path-sensitive analysis, we took a different approach: we only emit high-confidence warnings when the set of potential values for a pointer only contains a single element. This usually means that there is only a single execution path between the creation of the value and the unsafe operation (dereference in this case). As a result, the high-confidence warnings will be inherently less noisy. However, this confidence comes at a cost, since if <code>cond()</code> returns <code>false</code> on the first call, and <code>true</code> on the second, the resultant <code>nullptr</code> dereference will not be caught by the high-confidence warning.</p>
<h3 id="adapting-to-the-lack-of-annotations">Adapting to the lack of annotations</h3>
<p>Let&#8217;s look at the code snippet below:</p>
<pre><code class="language-cpp">int* g(int* a, int* b);
void f() {
    int x;
    int* p = g(&amp;x, nullptr);
    *p = 42; // Location B.
}</code></pre>
<p>In the above code, we pass <code>nullptr</code> as the second input to function <code>g</code>. The naive lifetime analysis would assume that <code>g</code> could return either of its inputs, and so would warn for the case when <code>nullptr</code> is returned. But if <code>g</code> never returns the second argument, the code above is actually safe! Therefore, we upgraded the analysis to only emit a high-confidence warning if we made absolutely no assumptions about the called function. In the future, once <code>g</code>&#8216;s behavior is annotated, the analysis will be able to know more precisely in which cases (if ever) <code>g</code> returns its second argument, and therefore be able to produce more high-confidence warnings.</p>
<p>Our analysis also makes certain assumptions for the role of the arguments. Let&#8217;s consider the following code snippet:</p>
<pre><code class="language-cpp">int* g(int** q);
void f() {
    int* p;
    g(&amp;p);  // Location C.
}</code></pre>
<p>The analysis will emit a warning at location <code>C</code> because we pass an uninitialized value (<code>p</code>) to a function. We have the assumption that <code>p</code> is an in-out argument in this case and <code>g</code> reading this value can result in undefined behavior. However, if <code>p</code> is only an <code>out</code> argument (<code>g</code> populates it before reading it), then the code is perfectly reasonable. Now, on one hand The C++ Core Guidelines is strongly against output arguments. On the other hand, output arguments are still used extensively in production code. As a result, we decided to only emit a high-confidence warning when there is no doubt about the role of the argument. In this particular case, since it is unclear whether <code>p</code> is an <code>out</code> or <code>in-out</code> argument, there will be no high-confidence warning emitted.</p>
<p>We also had to make changes how owner invalidation affects high-confidence warnings. Let&#8217;s look at a typical invalidation problem:</p>
<pre><code class="language-cpp">int&amp; f(std::vector&lt;int&gt;&amp; v) {
    int&amp; before_last = v.back();
    v.push_back(42);
    return before_last; // Location D.
}</code></pre>
<p>Here, the <code>before_last</code> reference is potentially invalidated by the <code>push_back</code> operation. This is dangerous code, so lifetime analysis will warn at location <code>D</code>. Now, while it is possible to teach the analysis that <code>std::vector</code>&#8216;s <code>push_back</code> member is potentially invalidating, and do the same for other owners found in the STL (which we have done for the lower-confidence lifetime warnings), this is not possible to do for the general case of user-written ownership types. One approach for a generic owner class is to treat all of its non-const methods as potentially invalidating, but this is not always accurate, since <code>operator[]</code> has a non-const overload that will never invalidate the references. Moreover, invalidating functions do not always cause lifetime problems. Consider the following modified version of the previous snippet:</p>
<pre><code class="language-cpp">int&amp; f(std::vector&lt;int&gt;&amp; v) {
    v.reserve(v.size()+1);
    int&amp; before_last = v.back();
    v.push_back(42);
    return before_last; // Location D.
}</code></pre>
<p>The code is now safe, but we still get the lifetime analysis warnings. To avoid noisy warnings on this type of source code, currently, we will not emit a high-confidence warning for scenarios involving invalidating functions. While this will eliminate a lot of noise, high-confidence warnings will miss the entire class of lifetime problems caused by owner invalidation. We are planning targeted changes to emit high-confidence warnings in some scenarios that are really unlikely to be correct (e.g., when there is no <code>std::vector::reserve</code> calls in the function). In the future, we might consider looking into providing finer control over what sources of noise should be filtered out.</p>
<h2 id="bug-fixes">Bug fixes</h2>
<p>We also spent significant amount of time fixing bugs in the lifetime analysis. These changes should make both the high-confidence warnings and the older warnings better. This section highlights some of the fixes we made. In addition to the highlighted changes, we also fixed many crashes, assertion failures, and made some performance optimizations.</p>
<ul>
<li>Lifetime analysis should no longer warn when deleting a null pointer</li>
<li>Lifetime analysis used to assume that pointer arithmetic produces an invalid pointer. This is no longer the case, we have a separate dedicated warning to diagnose pointer arithmetic.</li>
<li>No longer attempt to diagnose errors for union members. Unions were a source of false positives as our analysis did not have a good understanding of which member should be considered the active member. The C++ Core Guidelines recommends using abstractions like <code>std::variant</code> over naked unions.</li>
<li>Better modeling for heap allocations</li>
<li>Better modeling for classes with const fields</li>
<li>Tracking the destruction of temporary objects more precisely</li>
<li>Teached lifetime analysis that <code>std::move</code> does not move</li>
<li>No longer attempt to verify the correct use of <code>shared_ptr</code>s. We might end up adding support back in the future after some improvements.</li>
<li>Many other bug fixes, including <a href="https://developercommunity.visualstudio.com/t/Reopen-C26486-false-positive-invalid-/1437949">this one reported on Developer Community</a>.</li>
</ul>
<h2 id="conclusion">Conclusion</h2>
<p>Visual Studio 2022 17.5 Preview 2 features many improvements to the lifetime analysis including a new set of high-confidence warnings. Give these new checks a try and let us know what you think.
The work that we do is heavily influenced by feedback we receive on the <a href="https://developercommunity.visualstudio.com/search?space=62">Developer Community</a> so thank you again for your participation. Please continue to file feedback and let us know if there is a checker or rule that you would like to see added to C++ Core Check. Stay tuned for more C++ static analysis blogs. In the meanwhile, do not hesitate to reach out to us. We can be reached via the comments below or <a href="https://twitter.com/visualc">@VisualC</a> on Twitter.</p>
<p>The post <a rel="nofollow" href="https://devblogs.microsoft.com/cppblog/high-confidence-lifetime-checks-in-visual-studio-version-17-5-preview-2/">High-confidence Lifetime Checks in Visual Studio version 17.5 Preview 2</a> appeared first on <a rel="nofollow" href="https://devblogs.microsoft.com/cppblog">C++ Team Blog</a>.</p>
]]></content:encoded>
					
					<wfw:commentRss>https://devblogs.microsoft.com/cppblog/high-confidence-lifetime-checks-in-visual-studio-version-17-5-preview-2/feed/</wfw:commentRss>
			<slash:comments>1</slash:comments>
		
		
			</item>
		<item>
		<title>C11 Atomics in Visual Studio 2022 version 17.5 Preview 2</title>
		<link>https://devblogs.microsoft.com/cppblog/c11-atomics-in-visual-studio-2022-version-17-5-preview-2/</link>
					<comments>https://devblogs.microsoft.com/cppblog/c11-atomics-in-visual-studio-2022-version-17-5-preview-2/#respond</comments>
		
		<dc:creator><![CDATA[Charlie Barto]]></dc:creator>
		<pubDate>Tue, 13 Dec 2022 17:00:31 +0000</pubDate>
				<category><![CDATA[Announcement]]></category>
		<category><![CDATA[C++]]></category>
		<guid isPermaLink="false">https://devblogs.microsoft.com/cppblog/?p=31434</guid>

					<description><![CDATA[<p>C11 Atomics in Visual Studio 2022 version 17.5 Preview 2</p>
<p>The post <a rel="nofollow" href="https://devblogs.microsoft.com/cppblog/c11-atomics-in-visual-studio-2022-version-17-5-preview-2/">C11 Atomics in Visual Studio 2022 version 17.5 Preview 2</a> appeared first on <a rel="nofollow" href="https://devblogs.microsoft.com/cppblog">C++ Team Blog</a>.</p>
]]></description>
										<content:encoded><![CDATA[<p>MSVC gained support for C11 and C17 back in <a href="https://devblogs.microsoft.com/cppblog/c11-and-c17-standard-support-arriving-in-msvc">Visual Studio 2019 version 16.8</a>, but at the time we left out support for some C11 optional features such as atomics, threads, and complex numbers. We happy to announce that in Visual Studio 2022 17.5 Preview 2 we are adding an experimental implementation of C11 atomics.</p>
<p>Atomics are available in Visual Studio 2022 version 17.5 Preview 2 with the <code>/experimental:c11atomics</code> flag, in <code>/std:c11</code> mode or later. At the moment only lock-free atomics are supported, but in an upcoming release we will extend this support to include locking atomics as well. Atomics of all the usual built-in C types are lock-free, including <code>long long</code> on 32-bit x86. We will continue to define the <code>__STDC_NO_ATOMICS__</code> macro even under <code>/experimental:c11atomics </code>until locking atomics are implemented.</p>
<h2 id="atomics">Atomics</h2>
<p>C11 atomics add the <code>&lt;stdatomic.h&gt;</code> library header, the <code>_Atomic(T)</code> type specifier, and the <code>_Atomic</code> &#8220;qualifier&#8221; (which is more of a shortcut for <code>_Atomic(T)</code> than a real qualifier).</p>
<p><code>_Atomic(T)</code> or <code>_Atomic</code> can be used to declare an atomic:</p>
<pre><code class="language-c">_Atomic(int) a; // using the specifier
_Atomic int a; // using the qualifier</code></pre>
<p>This works for structs as well, for example:</p>
<pre><code class="language-c">struct cat {
   int a;
};

_Atomic struct cat furball;
_Atomic(struct cat) fuzzball;</code></pre>
<p>When you&#8217;re declaring a struct and defining a variable of the same type you can put <code>_Atomic(T)</code> and <code>_Atomic</code> in a number of places:</p>
<pre><code class="language-c">_Atomic(struct {
    int a;
}) meow;

_Atomic(struct cat {
    int a;
}) furball;

_Atomic struct {
    int a;
} purr;

struct {
    int a;
} _Atomic purr1;

_Atomic(struct {
    int a;
}) _Atomic purr2;

_Atomic struct {
    int a;
} _Atomic purr3;</code></pre>
<p>Notice that unlike the <code>_Atomic(T)</code> type specifier you can repeat the <code>_Atomic</code> qualifier as many times as you like, just like other type-qualifiers. The<code> _Atomic</code> qualifier is particularly useful when declaring structs or variables of structure types because it doesn&#8217;t require parentheses. It can also be useful in macros or typedefs because it can be repeated any number of times. In other respects it is identical to the type specifier.</p>
<p>Normal C assignment and compound assignment expressions are atomic on atomic types, and the loads and stores involved are done with sequentially consistent memory ordering. Note that unlike C++&#8217;s <code>std::atomic</code> the <code>/=</code>, <code>%=</code>, and <code>*=</code> operators are provided, and are atomic. The <code>atomic_load_explicit</code> and <code>atomic_store_explicit</code> library functions allow you to specify a memory order for loads and stores explicitly. Normal C initializers also work on atomic objects, and are not atomic. <code>atomic_init</code> can be used to explicitly initialize an atomic, or to later store to the atomic non-atomically.</p>
<p>The library functions above are provided by <code>&lt;stdatomic.h&gt;</code>, along with the remaining &#8220;usual&#8221; atomic operations and types. Notice that we are not providing the <code> ATOMIC_VAR_INIT</code> macro. This macro was deprecated in C17 and removed in C23, and it&#8217;s a bit of a trap for the unaware. If the lack of this macro causes problems in your code please <a href="#send-us-your-feedback">let us know</a>.</p>
<h2 id="c-atomic-compatibility">C++ <code>&lt;atomic&gt;</code> compatibility</h2>
<p>The Microsoft C++ standard library has implemented <a href="https://www.open-std.org/jtc1/sc22/wg21/docs/papers/2020/p0943r6.html">P0943R6: Support C atomics in C++</a> since Visual Studio 2022 17.1, and our C11 atomics implementation has the same
ABI as the STL&#8217;s C++ atomics. You can share headers that use atomics between C and C++ code and any atomic operations will be correctly ordered with respect to one another. If you do share headers be sure to limit yourself to the subset of syntax that&#8217;s valid in both C and C++; no <code>_Atomic</code> qualifier, no calling member functions on <code>_Atomic(T)</code> types, no using atomic <code>/=</code> expressions, etc. Because this level of compatibility requires C11 atomics to use the exact same ABI as C++ atomics they also inherit some of the limitations of our C++ atomics, namely:</p>
<ol>
<li>Our atomics are only lock-free for objects with sizes &lt;= 8 and exactly equal to a power of two. Other implementations allow lock-free operations on non-power of two objects &lt;= 16.</li>
<li>Our locking atomics will have the lock stored <em>inside</em> the atomic object, meaning locking atomic objects are bigger than their non-atomic counterparts, and you can&#8217;t cast a pointer to a non-atomic object to a pointer to its atomic equivalent. On the other hand it means you can share locking atomics between processes (using shared memory segments) and get correct synchronization.</li>
</ol>
<p>Codegen for C11 atomics should be almost exactly equivalent to codegen for C++ atomics in release mode, as basic operations are implemented essentially identically. An exception to this is when using C11 atomics without including the stdatomic.h header, like so:</p>
<pre><code class="language-c">int main(void) {
    _Atomic(int) v = 0;
    v += 3;
    return v;
}</code></pre>
<p>This will generate code containing a <code>call</code> instruction to a support routine implementing atomic increment, even in release mode. Including <code>&lt;stdatomic.h&gt;</code>will allow the code to be inlined, as with C++. Code for the library routines is inside the <code>vcruntime.lib</code> import library, and there&#8217;s no additional runtime components to distribute. C11 atomics should work fine on all the platforms supported by the Visual C++ Runtime, which are currently Windows 7 and newer.</p>
<h2 id="threads">Threads</h2>
<p>We are working on supporting <code>&lt;threads.h&gt;</code> in an upcoming Visual Studio release. Unlike atomics our implementation of threads will not have the same ABI as C++ threads, although it will likely be possible to include <code>&lt;threads.h&gt;</code> from C++ for interoperability. Stay tuned for updates on this feature in calendar year 2023.</p>
<h2 id="try-them-out">Try them out!</h2>
<p>Once you&#8217;ve installed Visual Studio 2022 17.5 Preview 2 you can try out C11 atomics by adding <code>/experimental:c11atomics</code> and <code>/std:c11</code> or <code>/std:c17</code> to your compile options. Note that we still define <code>__STDC_NO_ATOMICS__</code> so if your build system is testing for that you will need to add a special case or change to checking if compiling a translation unit including <code>&lt;stdatomic.h&gt;</code> succeeds.</p>
<h2 id="send-us-your-feedback">Send us your feedback</h2>
<p>If you have any thoughts on this feature, or other ideas on how to improve our tools you can leave a comment below. Additionally you can contact us via email at visualcpp@microsoft.com or report any bugs you encounter using <a href="https://developercommunity.visualstudio.com/">developer community</a>.</p>
<p>The post <a rel="nofollow" href="https://devblogs.microsoft.com/cppblog/c11-atomics-in-visual-studio-2022-version-17-5-preview-2/">C11 Atomics in Visual Studio 2022 version 17.5 Preview 2</a> appeared first on <a rel="nofollow" href="https://devblogs.microsoft.com/cppblog">C++ Team Blog</a>.</p>
]]></content:encoded>
					
					<wfw:commentRss>https://devblogs.microsoft.com/cppblog/c11-atomics-in-visual-studio-2022-version-17-5-preview-2/feed/</wfw:commentRss>
			<slash:comments>0</slash:comments>
		
		
			</item>
		<item>
		<title>Improving the State of Debug Performance in C++</title>
		<link>https://devblogs.microsoft.com/cppblog/improving-the-state-of-debug-performance-in-c/</link>
					<comments>https://devblogs.microsoft.com/cppblog/improving-the-state-of-debug-performance-in-c/#respond</comments>
		
		<dc:creator><![CDATA[Cameron DaCamara]]></dc:creator>
		<pubDate>Tue, 13 Dec 2022 17:00:11 +0000</pubDate>
				<category><![CDATA[Announcement]]></category>
		<category><![CDATA[C++]]></category>
		<category><![CDATA[General C++ Series]]></category>
		<category><![CDATA[New Feature]]></category>
		<category><![CDATA[performance]]></category>
		<category><![CDATA[C++ language]]></category>
		<category><![CDATA[compiler]]></category>
		<category><![CDATA[debugging]]></category>
		<guid isPermaLink="false">https://devblogs.microsoft.com/cppblog/?p=31372</guid>

					<description><![CDATA[<p>In this blog we will explore one change the MSVC compiler has implemented in an effort to improve the codegen quality of applications in debug mode. We will highlight what the change does, and how it could be extended for the future.</p>
<p>The post <a rel="nofollow" href="https://devblogs.microsoft.com/cppblog/improving-the-state-of-debug-performance-in-c/">Improving the State of Debug Performance in C++</a> appeared first on <a rel="nofollow" href="https://devblogs.microsoft.com/cppblog">C++ Team Blog</a>.</p>
]]></description>
										<content:encoded><![CDATA[<p>In this blog we will explore one change the MSVC compiler has implemented in an effort to improve the codegen quality of applications in debug mode. We will highlight what the change does, and how it could be extended for the future. If debug performance is something you care about for your C++ projects, then Visual Studio 2022 version 17.5 is making that experience even better!</p>
<p><em>Please note that this blog will contain some assembly but being an expert in assembly is not required.</em></p>
<h2 id="overview">Overview</h2>
<ul>
<li><a href="#motivation">Motivation: why we care about debugging performance.</a></li>
<li><a href="#show-me-code">Show me some code!: A few simple examples of before and after.</a></li>
<li><a href="#how-we-did-it">How we did it: About our new intrinsic and how you could use it.</a></li>
<li><a href="#looking-ahead">Looking ahead: What else we&#8217;re doing to make the experience better.</a></li>
</ul>
<h2><span id="motivation">Motivation</span></h2>
<p>You might notice that the title of this blog is a play on words based on a recent popular blog post of a similar name,
<a href="https://vittorioromeo.info/index/blog/debug_performance_cpp.html">&#8220;the sad state of debug performance in
c++&#8221;</a>. In the blog Vittorio Romeo highlights some general C++ shortcomings when it comes to debugging performance.
Vittorio also also filed this Developer Community ticket &#8220;<a href="https://developercommunity.visualstudio.com/t/std::move-and-similar-functions-resu/1681875">`std::move` (and
similar functions) result in poor debug performance and worse debugging experience</a>&#8220;; thanks to him and everyone who
voted! Much of the reason for the observed slowdown is the cost of abstraction, with the notable example of
<code>std::move</code> where the following code:</p>
<pre>int i = 0;
std::move(i);</pre>
<p>Would generate a function call when the code is conceptually:</p>
<pre>int i = 0;
static_cast&lt;int&amp;&amp;&gt;(i);</pre>
<p>The function <code>std::move</code> is conceptually a named cast, much like static_cast but with a contextual meaning for code
around it. The penalty for using this named cast is that you get a function call generated in the debug assembly.
Here&#8217;s the assembly of the two examples above:</p>
<style>
.my_collapse {
  display: table-row;
  cursor: pointer;
}
.asm_entry {
  vertical-align: top;
}
</style>
<table border="1">
<tbody>
<tr class="my_collapse">
<td><code>std::move</code> (click to expand)</td>
<td><code>static_cast</code> (click to expand)</td>
</tr>
<tr>
<td class="asm_entry">
<pre>main	PROC
sub	rsp, 56	; 00000038H
mov	DWORD PTR i$[rsp], 0
lea	rcx, QWORD PTR i$[rsp]
call	??$move@AEAH@std@@YA$$QEAHAEAH@Z
xor	eax, eax
add	rsp, 56	; 00000038H
ret	0
main	ENDP</pre>
</td>
<td class="asm_entry">
<pre>main	PROC
sub	rsp, 24
mov	DWORD PTR i$[rsp], 0
xor	eax, eax
add	rsp, 24
ret	0
main	ENDP</pre>
</td>
</tr>
</tbody>
</table>
<p><em>Note to readers: All code samples compiled in this blog were compiled with &#8220;<code>/Od /std:c++latest</code>&#8220;</em></p>
<p>On the surface, the compiler only generated 2 extra instructions in the <code>std::move</code> case, but the &#8216;call&#8217; instruction, in
particular, is both expensive and executes this code in addition to the code above:</p>
<pre class="asm_entry">??$move@AEAH@std@@YA$$QEAHAEAH@Z PROC			; std::move&lt;int &amp;&gt;, COMDAT
mov	QWORD PTR [rsp+8], rcx
mov	rax, QWORD PTR _Arg$[rsp]
ret	0
??$move@AEAH@std@@YA$$QEAHAEAH@Z ENDP			; std::move&lt;int &amp;&gt;</pre>
<p><em>Note: to generate the assembly above, the compiler can be provided with the <a href="https://learn.microsoft.com/en-us/cpp/build/reference/fa-fa-listing-file?view=msvc-170"><code>/Fa</code></a> option. Furthermore, the weird names
like &#8220;<code>??$move@AEAH@std@@YA$$QEAHAEAH@Z</code>&#8221; are a mangled name of the function template specialization of <code>std::move</code>.</em></p>
<p>So really your binary is now at a 5 instruction deficit to the <code>static_cast</code> code, and this cost is multiplied by the
number of times that <code>std::move</code> is used.</p>
<p>Some compilers have already implemented some mechanism to acknowledge meta functions like <code>std::move</code> and <code>std::forward</code> as
compiler intrinsics (as noted in Vittorio&#8217;s blog) and this support is done completely in the <a href="https://en.wikipedia.org/wiki/Compiler#Front_end">compiler front-end</a>. As of
17.5, MSVC is offering better debugging performance by acknowledging these meta functions as well! More on how we do it
later in this blog, but first&#8230;</p>
<h2><span id="show-me-code">Show me some code!</span></h2>
<p><em>Note to readers: to take advantage of the new codegen quality, you will need to provide the <a href="https://learn.microsoft.com/en-us/cpp/build/reference/permissive-standards-conformance?view=msvc-170"><code>/permissive-</code></a> compiler
option. Also worthy to note that <code>/permissive-</code> is implied when <code>/std:c++20</code> or <code>/std:c++latest</code> is used.</em></p>
<p>Let&#8217;s take the simple example above again and make it a full program:</p>
<pre>#include &lt;utility&gt;

int main() {
    int i = 0;
    std::move(i);
    std::forward&lt;int&amp;&gt;(i);
}</pre>
<p>Here&#8217;s the generated assembly difference between 17.4 and 17.5:</p>
<table border="1">
<tbody>
<tr class="my_collapse">
<td>17.4 (click to expand)</td>
<td>17.5 (click to expand)</td>
</tr>
<tr>
<td class="asm_entry">
<pre>_Arg$ = 8
??$forward@AEAH@std@@YAAEAHAEAH@Z PROC
mov	QWORD PTR [rsp+8], rcx
mov	rax, QWORD PTR _Arg$[rsp]
ret	0
??$forward@AEAH@std@@YAAEAHAEAH@Z ENDP
_TEXT	ENDS
_TEXT	SEGMENT
_Arg$ = 8
??$move@AEAH@std@@YA$$QEAHAEAH@Z PROC
mov	QWORD PTR [rsp+8], rcx
mov	rax, QWORD PTR _Arg$[rsp]
ret	0
??$move@AEAH@std@@YA$$QEAHAEAH@Z ENDP
_TEXT	ENDS
_TEXT	SEGMENT
i$ = 32
main	PROC
sub	rsp, 56		; 00000038H
mov	DWORD PTR i$[rsp], 0
lea	rcx, QWORD PTR i$[rsp]
call	??$move@AEAH@std@@YA$$QEAHAEAH@Z
lea	rcx, QWORD PTR i$[rsp]
call	??$forward@AEAH@std@@YAAEAHAEAH@Z
xor	eax, eax
add	rsp, 56		; 00000038H
ret	0
main	ENDP</pre>
</td>
<td class="asm_entry">
<pre>i$ = 0
main	PROC
$LN3:
sub	rsp, 24
mov	DWORD PTR i$[rsp], 0
xor	eax, eax
add	rsp, 24
ret	0
main	ENDP</pre>
</td>
</tr>
</tbody>
</table>
<p>Assembly reading tip: The <code>main PROC</code> above is our <code>main</code> function in the C++ code. The
instructions that follow <code>main PROC</code> are what your CPU will execute when your program is first invoked. In
the case above, it is clear that the code produced by 17.5 is much smaller, which can sometimes be an indication of a
performance win. For the purposes of this blog, the performance win is both in the size of the code produced and the
reduction in indirections due to inlining the &#8216;call&#8217; instruction to <code>std::move</code> and <code>std::forward</code>. For the
purposes of this blog we will rely on the newly generated assembly reduced complexity as an indicator of possible
performance wins.</p>
<p>Yes, you read that right, the generated code in 17.5 doesn&#8217;t even create assembly entries for <code>std::move</code> or
<code>std::forward</code>—which makes sense, they&#8217;re never called.</p>
<p>Let&#8217;s look at a slightly more complicated code example:</p>
<pre>#include &lt;utility&gt;

template &lt;typename T&gt;
void add_1_impl(T&amp;&amp; x) {
    std::forward&lt;T&gt;(x) += std::move(1);
}

template &lt;typename T, int N&gt;
void add_1(T (&amp;arr)[N]) {
    for (auto&amp;&amp; e : arr) {
        add_1_impl(e);
    }
}

int main() {
    int arr[10]{};
    add_1(arr);
}</pre>
<p>In this code all we want to do is add 1 to all elements of the array. Here&#8217;s the table (only showing the <code>add_1_impl</code>
function with <code>std::forward</code> and <code>std::move</code>):</p>
<table border="1">
<tbody>
<tr class="my_collapse">
<td>17.4 (click to expand)</td>
<td>17.5 (click to expand)</td>
</tr>
<tr>
<td class="asm_entry">
<pre>??$add_1_impl@AEAH@@YAXAEAH@Z PROC
$LN3:
mov	QWORD PTR [rsp+8], rcx
sub	rsp, 72	; 00000048H
mov	DWORD PTR $T1[rsp], 1
lea	rcx, QWORD PTR $T1[rsp]
call	??$move@H@std@@YA$$QEAH$$QEAH@Z
mov	eax, DWORD PTR [rax]
mov	DWORD PTR tv72[rsp], eax
mov	rcx, QWORD PTR x$[rsp]
call	??$forward@AEAH@std@@YAAEAHAEAH@Z
mov	QWORD PTR tv68[rsp], rax
mov	rax, QWORD PTR tv68[rsp]
mov	eax, DWORD PTR [rax]
mov	DWORD PTR tv70[rsp], eax
mov	eax, DWORD PTR tv72[rsp]
mov	ecx, DWORD PTR tv70[rsp]
add	ecx, eax
mov	eax, ecx
mov	rcx, QWORD PTR tv68[rsp]
mov	DWORD PTR [rcx], eax
add	rsp, 72	; 00000048H
ret	0
??$add_1_impl@AEAH@@YAXAEAH@Z ENDP</pre>
</td>
<td class="asm_entry">
<pre>??$add_1_impl@AEAH@@YAXAEAH@Z PROC
$LN3:
mov	QWORD PTR [rsp+8], rcx
sub	rsp, 24
mov	DWORD PTR $T1[rsp], 1
mov	rax, QWORD PTR x$[rsp]
mov	eax, DWORD PTR [rax]
add	eax, DWORD PTR $T1[rsp]
mov	rcx, QWORD PTR x$[rsp]
mov	DWORD PTR [rcx], eax
add	rsp, 24
ret	0
??$add_1_impl@AEAH@@YAXAEAH@Z ENDP</pre>
</td>
</tr>
</tbody>
</table>
<p>17.4 has 21 instructions while 17.5 has only 10, but this comparison is made that much more extreme by the fact that we
are calling <code>add_impl_1</code> in a loop so the complexity of executed instructions in 17.4 can ostensibly be significantly
more costly than in 17.5—worse than that, actually, because we&#8217;re not accounting for the instructions executed in the
functions <code>std::forward</code> and <code>std::move</code>.</p>
<p>Let&#8217;s make the code sample even more interesting and extreme to illustrate the visible differences. It might be
observed that if we manually unroll the loop above we can get a performance win, so let&#8217;s do that using templates:</p>
<pre>#include &lt;utility&gt;

template &lt;typename T, int N, std::size_t... Is&gt;
void add_1_impl(std::index_sequence&lt;Is...&gt;, T (&amp;arr)[N]) {
    ((std::forward&lt;T&amp;&gt;(arr[Is]) += std::move(1)), ...);
}

template &lt;typename T, int N&gt;
void add_1(T (&amp;arr)[N]) {
    add_1_impl(std::make_index_sequence&lt;N&gt;{}, arr);
}

int main() {
    int arr[10]{};
    add_1(arr);
}</pre>
<p>The code above replaces the loop in the previous example with a single <a href="https://en.cppreference.com/w/cpp/language/fold">fold expression</a>. Let&#8217;s peek at the codegen
(again only snipping <code>add_1_impl</code> with <code>std::forward</code> and <code>std::move</code>, we also replace the mangled function name with
<code>add_1_impl&lt;...&gt;</code>):</p>
<table border="1">
<tbody>
<tr class="my_collapse">
<td>17.4 (click to expand)</td>
<td>17.5 (click to expand)</td>
</tr>
<tr>
<td class="asm_entry">
<pre>add_1_impl&lt;...&gt; PROC 
$LN3: 
mov	QWORD PTR [rsp+16], rdx 
mov	BYTE PTR [rsp+8], cl 
sub	rsp, 248	; 000000f8H 
mov	DWORD PTR $T1[rsp], 1 
lea	rcx, QWORD PTR $T1[rsp] 
call	??$move@H@std@@YA$$QEAH$$QEAH@Z 
mov	eax, DWORD PTR [rax] 
mov	DWORD PTR tv74[rsp], eax 
mov	eax, 4 
imul	rax, rax, 0 
mov	rcx, QWORD PTR arr$[rsp] 
add	rcx, rax 
mov	rax, rcx 
mov	rcx, rax 
call	??$forward@AEAH@std@@YAAEAHAEAH@Z 
mov	QWORD PTR tv70[rsp], rax 
mov	rax, QWORD PTR tv70[rsp] 
mov	eax, DWORD PTR [rax] 
mov	DWORD PTR tv72[rsp], eax 
mov	eax, DWORD PTR tv74[rsp] 
mov	ecx, DWORD PTR tv72[rsp] 
add	ecx, eax 
mov	eax, ecx 
mov	rcx, QWORD PTR tv70[rsp] 
mov	DWORD PTR [rcx], eax 
mov	DWORD PTR $T2[rsp], 1 
lea	rcx, QWORD PTR $T2[rsp] 
call	??$move@H@std@@YA$$QEAH$$QEAH@Z 
mov	eax, DWORD PTR [rax] 
mov	DWORD PTR tv86[rsp], eax 
mov	eax, 4 
imul	rax, rax, 1 
mov	rcx, QWORD PTR arr$[rsp] 
add	rcx, rax 
mov	rax, rcx 
mov	rcx, rax 
call	??$forward@AEAH@std@@YAAEAHAEAH@Z 
mov	QWORD PTR tv82[rsp], rax 
mov	rax, QWORD PTR tv82[rsp] 
mov	eax, DWORD PTR [rax] 
mov	DWORD PTR tv84[rsp], eax 
mov	eax, DWORD PTR tv86[rsp] 
mov	ecx, DWORD PTR tv84[rsp] 
add	ecx, eax 
mov	eax, ecx 
mov	rcx, QWORD PTR tv82[rsp] 
mov	DWORD PTR [rcx], eax 
mov	DWORD PTR $T3[rsp], 1 
lea	rcx, QWORD PTR $T3[rsp] 
call	??$move@H@std@@YA$$QEAH$$QEAH@Z 
mov	eax, DWORD PTR [rax] 
mov	DWORD PTR tv130[rsp], eax 
mov	eax, 4 
imul	rax, rax, 2 
mov	rcx, QWORD PTR arr$[rsp] 
add	rcx, rax 
mov	rax, rcx 
mov	rcx, rax 
call	??$forward@AEAH@std@@YAAEAHAEAH@Z 
mov	QWORD PTR tv94[rsp], rax 
mov	rax, QWORD PTR tv94[rsp] 
mov	eax, DWORD PTR [rax] 
mov	DWORD PTR tv128[rsp], eax 
mov	eax, DWORD PTR tv130[rsp] 
mov	ecx, DWORD PTR tv128[rsp] 
add	ecx, eax 
mov	eax, ecx 
mov	rcx, QWORD PTR tv94[rsp] 
mov	DWORD PTR [rcx], eax 
mov	DWORD PTR $T4[rsp], 1 
lea	rcx, QWORD PTR $T4[rsp] 
call	??$move@H@std@@YA$$QEAH$$QEAH@Z 
mov	eax, DWORD PTR [rax] 
mov	DWORD PTR tv142[rsp], eax 
mov	eax, 4 
imul	rax, rax, 3 
mov	rcx, QWORD PTR arr$[rsp] 
add	rcx, rax 
mov	rax, rcx 
mov	rcx, rax 
call	??$forward@AEAH@std@@YAAEAHAEAH@Z 
mov	QWORD PTR tv138[rsp], rax 
mov	rax, QWORD PTR tv138[rsp] 
mov	eax, DWORD PTR [rax] 
mov	DWORD PTR tv140[rsp], eax 
mov	eax, DWORD PTR tv142[rsp] 
mov	ecx, DWORD PTR tv140[rsp] 
add	ecx, eax 
mov	eax, ecx 
mov	rcx, QWORD PTR tv138[rsp] 
mov	DWORD PTR [rcx], eax 
mov	DWORD PTR $T5[rsp], 1 
lea	rcx, QWORD PTR $T5[rsp] 
call	??$move@H@std@@YA$$QEAH$$QEAH@Z 
mov	eax, DWORD PTR [rax] 
mov	DWORD PTR tv154[rsp], eax 
mov	eax, 4 
imul	rax, rax, 4 
mov	rcx, QWORD PTR arr$[rsp] 
add	rcx, rax 
mov	rax, rcx 
mov	rcx, rax 
call	??$forward@AEAH@std@@YAAEAHAEAH@Z 
mov	QWORD PTR tv150[rsp], rax 
mov	rax, QWORD PTR tv150[rsp] 
mov	eax, DWORD PTR [rax] 
mov	DWORD PTR tv152[rsp], eax 
mov	eax, DWORD PTR tv154[rsp] 
mov	ecx, DWORD PTR tv152[rsp] 
add	ecx, eax 
mov	eax, ecx 
mov	rcx, QWORD PTR tv150[rsp] 
mov	DWORD PTR [rcx], eax 
mov	DWORD PTR $T6[rsp], 1 
lea	rcx, QWORD PTR $T6[rsp] 
call	??$move@H@std@@YA$$QEAH$$QEAH@Z 
mov	eax, DWORD PTR [rax] 
mov	DWORD PTR tv166[rsp], eax 
mov	eax, 4 
imul	rax, rax, 5 
mov	rcx, QWORD PTR arr$[rsp] 
add	rcx, rax 
mov	rax, rcx 
mov	rcx, rax 
call	??$forward@AEAH@std@@YAAEAHAEAH@Z 
mov	QWORD PTR tv162[rsp], rax 
mov	rax, QWORD PTR tv162[rsp] 
mov	eax, DWORD PTR [rax] 
mov	DWORD PTR tv164[rsp], eax 
mov	eax, DWORD PTR tv166[rsp] 
mov	ecx, DWORD PTR tv164[rsp] 
add	ecx, eax 
mov	eax, ecx 
mov	rcx, QWORD PTR tv162[rsp] 
mov	DWORD PTR [rcx], eax 
mov	DWORD PTR $T7[rsp], 1 
lea	rcx, QWORD PTR $T7[rsp] 
call	??$move@H@std@@YA$$QEAH$$QEAH@Z 
mov	eax, DWORD PTR [rax] 
mov	DWORD PTR tv178[rsp], eax 
mov	eax, 4 
imul	rax, rax, 6 
mov	rcx, QWORD PTR arr$[rsp] 
add	rcx, rax 
mov	rax, rcx 
mov	rcx, rax 
call	??$forward@AEAH@std@@YAAEAHAEAH@Z 
mov	QWORD PTR tv174[rsp], rax 
mov	rax, QWORD PTR tv174[rsp] 
mov	eax, DWORD PTR [rax] 
mov	DWORD PTR tv176[rsp], eax 
mov	eax, DWORD PTR tv178[rsp] 
mov	ecx, DWORD PTR tv176[rsp] 
add	ecx, eax 
mov	eax, ecx 
mov	rcx, QWORD PTR tv174[rsp] 
mov	DWORD PTR [rcx], eax 
mov	DWORD PTR $T8[rsp], 1 
lea	rcx, QWORD PTR $T8[rsp] 
call	??$move@H@std@@YA$$QEAH$$QEAH@Z 
mov	eax, DWORD PTR [rax] 
mov	DWORD PTR tv190[rsp], eax 
mov	eax, 4 
imul	rax, rax, 7 
mov	rcx, QWORD PTR arr$[rsp] 
add	rcx, rax 
mov	rax, rcx 
mov	rcx, rax 
call	??$forward@AEAH@std@@YAAEAHAEAH@Z 
mov	QWORD PTR tv186[rsp], rax 
mov	rax, QWORD PTR tv186[rsp] 
mov	eax, DWORD PTR [rax] 
mov	DWORD PTR tv188[rsp], eax 
mov	eax, DWORD PTR tv190[rsp] 
mov	ecx, DWORD PTR tv188[rsp] 
add	ecx, eax 
mov	eax, ecx 
mov	rcx, QWORD PTR tv186[rsp] 
mov	DWORD PTR [rcx], eax 
mov	DWORD PTR $T9[rsp], 1 
lea	rcx, QWORD PTR $T9[rsp] 
call	??$move@H@std@@YA$$QEAH$$QEAH@Z 
mov	eax, DWORD PTR [rax] 
mov	DWORD PTR tv202[rsp], eax 
mov	eax, 4 
imul	rax, rax, 8 
mov	rcx, QWORD PTR arr$[rsp] 
add	rcx, rax 
mov	rax, rcx 
mov	rcx, rax 
call	??$forward@AEAH@std@@YAAEAHAEAH@Z 
mov	QWORD PTR tv198[rsp], rax 
mov	rax, QWORD PTR tv198[rsp] 
mov	eax, DWORD PTR [rax] 
mov	DWORD PTR tv200[rsp], eax 
mov	eax, DWORD PTR tv202[rsp] 
mov	ecx, DWORD PTR tv200[rsp] 
add	ecx, eax 
mov	eax, ecx 
mov	rcx, QWORD PTR tv198[rsp] 
mov	DWORD PTR [rcx], eax 
mov	DWORD PTR $T10[rsp], 1 
lea	rcx, QWORD PTR $T10[rsp] 
call	??$move@H@std@@YA$$QEAH$$QEAH@Z 
mov	eax, DWORD PTR [rax] 
mov	DWORD PTR tv214[rsp], eax 
mov	eax, 4 
imul	rax, rax, 9 
mov	rcx, QWORD PTR arr$[rsp] 
add	rcx, rax 
mov	rax, rcx 
mov	rcx, rax 
call	??$forward@AEAH@std@@YAAEAHAEAH@Z 
mov	QWORD PTR tv210[rsp], rax 
mov	rax, QWORD PTR tv210[rsp] 
mov	eax, DWORD PTR [rax] 
mov	DWORD PTR tv212[rsp], eax 
mov	eax, DWORD PTR tv214[rsp] 
mov	ecx, DWORD PTR tv212[rsp] 
add	ecx, eax 
mov	eax, ecx 
mov	rcx, QWORD PTR tv210[rsp] 
mov	DWORD PTR [rcx], eax 
add	rsp, 248	; 000000f8H 
ret	0 
add_1_impl&lt;...&gt; ENDP</pre>
</td>
<td class="asm_entry">
<pre>add_1_impl&lt;...&gt; PROC 
$LN3: 
mov	QWORD PTR [rsp+16], rdx 
mov	BYTE PTR [rsp+8], cl 
sub	rsp, 56	; 00000038H 
mov	DWORD PTR $T1[rsp], 1 
mov	eax, 4 
imul	rax, rax, 0 
mov	rcx, QWORD PTR arr$[rsp] 
mov	eax, DWORD PTR [rcx+rax] 
add	eax, DWORD PTR $T1[rsp] 
mov	ecx, 4 
imul	rcx, rcx, 0 
mov	rdx, QWORD PTR arr$[rsp] 
mov	DWORD PTR [rdx+rcx], eax 
mov	DWORD PTR $T2[rsp], 1 
mov	eax, 4 
imul	rax, rax, 1 
mov	rcx, QWORD PTR arr$[rsp] 
mov	eax, DWORD PTR [rcx+rax] 
add	eax, DWORD PTR $T2[rsp] 
mov	ecx, 4 
imul	rcx, rcx, 1 
mov	rdx, QWORD PTR arr$[rsp] 
mov	DWORD PTR [rdx+rcx], eax 
mov	DWORD PTR $T3[rsp], 1 
mov	eax, 4 
imul	rax, rax, 2 
mov	rcx, QWORD PTR arr$[rsp] 
mov	eax, DWORD PTR [rcx+rax] 
add	eax, DWORD PTR $T3[rsp] 
mov	ecx, 4 
imul	rcx, rcx, 2 
mov	rdx, QWORD PTR arr$[rsp] 
mov	DWORD PTR [rdx+rcx], eax 
mov	DWORD PTR $T4[rsp], 1 
mov	eax, 4 
imul	rax, rax, 3 
mov	rcx, QWORD PTR arr$[rsp] 
mov	eax, DWORD PTR [rcx+rax] 
add	eax, DWORD PTR $T4[rsp] 
mov	ecx, 4 
imul	rcx, rcx, 3 
mov	rdx, QWORD PTR arr$[rsp] 
mov	DWORD PTR [rdx+rcx], eax 
mov	DWORD PTR $T5[rsp], 1 
mov	eax, 4 
imul	rax, rax, 4 
mov	rcx, QWORD PTR arr$[rsp] 
mov	eax, DWORD PTR [rcx+rax] 
add	eax, DWORD PTR $T5[rsp] 
mov	ecx, 4 
imul	rcx, rcx, 4 
mov	rdx, QWORD PTR arr$[rsp] 
mov	DWORD PTR [rdx+rcx], eax 
mov	DWORD PTR $T6[rsp], 1 
mov	eax, 4 
imul	rax, rax, 5 
mov	rcx, QWORD PTR arr$[rsp] 
mov	eax, DWORD PTR [rcx+rax] 
add	eax, DWORD PTR $T6[rsp] 
mov	ecx, 4 
imul	rcx, rcx, 5 
mov	rdx, QWORD PTR arr$[rsp] 
mov	DWORD PTR [rdx+rcx], eax 
mov	DWORD PTR $T7[rsp], 1 
mov	eax, 4 
imul	rax, rax, 6 
mov	rcx, QWORD PTR arr$[rsp] 
mov	eax, DWORD PTR [rcx+rax] 
add	eax, DWORD PTR $T7[rsp] 
mov	ecx, 4 
imul	rcx, rcx, 6 
mov	rdx, QWORD PTR arr$[rsp] 
mov	DWORD PTR [rdx+rcx], eax 
mov	DWORD PTR $T8[rsp], 1 
mov	eax, 4 
imul	rax, rax, 7 
mov	rcx, QWORD PTR arr$[rsp] 
mov	eax, DWORD PTR [rcx+rax] 
add	eax, DWORD PTR $T8[rsp] 
mov	ecx, 4 
imul	rcx, rcx, 7 
mov	rdx, QWORD PTR arr$[rsp] 
mov	DWORD PTR [rdx+rcx], eax 
mov	DWORD PTR $T9[rsp], 1 
mov	eax, 4 
imul	rax, rax, 8 
mov	rcx, QWORD PTR arr$[rsp] 
mov	eax, DWORD PTR [rcx+rax] 
add	eax, DWORD PTR $T9[rsp] 
mov	ecx, 4 
imul	rcx, rcx, 8 
mov	rdx, QWORD PTR arr$[rsp] 
mov	DWORD PTR [rdx+rcx], eax 
mov	DWORD PTR $T10[rsp], 1 
mov	eax, 4 
imul	rax, rax, 9 
mov	rcx, QWORD PTR arr$[rsp] 
mov	eax, DWORD PTR [rcx+rax] 
add	eax, DWORD PTR $T10[rsp] 
mov	ecx, 4 
imul	rcx, rcx, 9 
mov	rdx, QWORD PTR arr$[rsp] 
mov	DWORD PTR [rdx+rcx], eax 
add	rsp, 56	; 00000038H 
ret	0 
add_1_impl&lt;...&gt; ENDP</pre>
</td>
</tr>
</tbody>
</table>
<p>Our 17.4 example clocks in at a whopping 226 instructions while our 17.5 example is only 106 and the complexity of the
instructions in 17.4 appears to be far more costly due to the number of call frame setups and &#8216;call&#8217; instructions which
are not present on the 17.5 side.</p>
<p>OK, perhaps the examples above are contrived and it might be far-fetched to think that code like the above would truly
impact performance, but let&#8217;s take some code that is all but guaranteed to have some kind of real world application:</p>
<pre>#include &lt;vector&gt;

int main() {
    std::vector&lt;int&gt; v;
    v.push_back(1); 
}</pre>
<p>I will save you the massive assembly output on this one and simply callout the assembly size difference:</p>
<ul>
<li>17.4: 3136</li>
<li>17.5: 3063</li>
</ul>
<p>Your assembly is 74 instructions shorter just by the compiler eliding these meta functions, and you can all but
guarantee that in the places where <code>std::move</code> and <code>std::forward</code> are used, they may be used in a loop (i.e. resizing the
vector and moving the elements to a new memory block). Furthermore, since these meta functions are never instantiated
the corresponding .obj, .lib, and .pdb will be slightly smaller after upgrading to 17.5.</p>
<h2><span id="how-we-did-it">How we did it</span></h2>
<p>Rather than try to make the compiler aware of meta functions that act as named, no-op casts (i.e. the cast does not
require a pointer adjustment), the compiler took an alternative approach and implemented this new inlining ability using
a C++ attribute: <code>[[msvc::intrinsic]]</code>.</p>
<p>The new attribute will semantically replace a function call with a cast to that function&#8217;s return type if the function
definition is decorated with <code>[[msvc::intrinsic]]</code>. You can see how we applied this new attribute in the STL: <a href="https://github.com/microsoft/STL/pull/3182">GH3182</a>. The
reason the compiler decided to go down the attribute route is that we want to eventually extend the scenarios it can
cover and offer a data-driven approach to selectively decorate code with the new functionality. The latter is important
for users of MSVC as well.</p>
<p>You can read more about the attribute and its constraints and semantics in the <a href="https://learn.microsoft.com/en-us/cpp/cpp/attributes?view=msvc-170#microsoft-specific-attributes">Microsoft-specific attributes</a> section of
our documentation.</p>
<h2><span id="looking-ahead">Looking ahead&#8230;</span></h2>
<p>The compiler front-end is not alone in this story of improving the performance of generated code for debugging purposes,
the compiler back-end is also working very hard on some debug codegen scenarios that they will share in the coming
months.</p>
<p><b>Call to action:</b> what types of debugging optimizations matter to you? What optimizations for debug code would you like
to see MSVC implement?</p>
<p>Especially if you work for a game studio, please help us find out what your debugging workflow looks like by taking this
survey: <a href="https://aka.ms/MSVCDebugSurvey">https://aka.ms/MSVCDebugSurvey</a>. Data like this helps the team
focus on what workflows are important to you.</p>
<p>Onward and upward!</p>
<p><!-- It is important that this script is executed after all the tables are created -->
<script>
var coll = document.getElementsByClassName("my_collapse");
var i = 0;
for (; i < coll.length; i++) {
  var elm = coll[i];
  var content_row = elm.nextElementSibling;
  // Hide them all by default.
  content_row.style.display = "none";
  elm.addEventListener("click", function() {
    var content = this.nextElementSibling;
    if (content.style.display !== "none") {
      content.style.display = "none";
    }
    else {
      content.style.display = "table-row";
    }
  });
}
</script></p>
<h4 id="closing">Closing</h4>
<p>As always, we welcome your feedback. Feel free to send any comments through e-mail at <a href="mailto:visualcpp@microsoft.com">visualcpp@microsoft.com</a> or through <a href="https://twitter.com/visualc">Twitter @visualc</a>. Also, feel free to follow Cameron DaCamara on Twitter <a href="https://twitter.com/starfreakclone">@starfreakclone</a>.</p>
<p>If you encounter other problems with MSVC in VS 2019/2022 please let us know via the <a href="https://docs.microsoft.com/en-us/visualstudio/ide/how-to-report-a-problem-with-visual-studio?view=vs-2019">Report
a Problem</a> option, either from the installer or the Visual Studio IDE itself. For suggestions or bug reports, let us
know through <a href="https://developercommunity.visualstudio.com/">DevComm.</a></p>
<p>The post <a rel="nofollow" href="https://devblogs.microsoft.com/cppblog/improving-the-state-of-debug-performance-in-c/">Improving the State of Debug Performance in C++</a> appeared first on <a rel="nofollow" href="https://devblogs.microsoft.com/cppblog">C++ Team Blog</a>.</p>
]]></content:encoded>
					
					<wfw:commentRss>https://devblogs.microsoft.com/cppblog/improving-the-state-of-debug-performance-in-c/feed/</wfw:commentRss>
			<slash:comments>0</slash:comments>
		
		
			</item>
		<item>
		<title>MSVC OpenMP Update</title>
		<link>https://devblogs.microsoft.com/cppblog/msvc-openmp-update/</link>
					<comments>https://devblogs.microsoft.com/cppblog/msvc-openmp-update/#comments</comments>
		
		<dc:creator><![CDATA[Tanveer Gani]]></dc:creator>
		<pubDate>Tue, 29 Nov 2022 16:00:19 +0000</pubDate>
				<category><![CDATA[C++]]></category>
		<category><![CDATA[OpenMP]]></category>
		<guid isPermaLink="false">https://devblogs.microsoft.com/cppblog/?p=31286</guid>

					<description><![CDATA[<p>Summary of your post, shown on the home page next to the featured image</p>
<p>The post <a rel="nofollow" href="https://devblogs.microsoft.com/cppblog/msvc-openmp-update/">MSVC OpenMP Update</a> appeared first on <a rel="nofollow" href="https://devblogs.microsoft.com/cppblog">C++ Team Blog</a>.</p>
]]></description>
										<content:encoded><![CDATA[<p>In our previous <a href="https://devblogs.microsoft.com/cppblog/openmp-task-support-for-c-in-visual-studio/">blog post</a>, we announced support for OpenMP tasks starting with Visual Studio 17.2. Now, we are pleased to announce we have added further OpenMP features to Visual Studio 17.4, which brings us closer to conformance with OpenMP 3.1.</p>
<h2 id="pragma-atomic-with-openmp-3-1-semantics"><code>#pragma atomic</code> with OpenMP 3.1 semantics</h2>
<p>We added support for <code>#pragma omp atomic</code> a while ago but we now also support the full OpenMP 3.1 syntax and semantics for atomic operations. Specifically, we now support a <code>read</code>, <code>write</code>, <code>update</code> or <code>capture</code> clause in the pragma while the pragma can now apply either to an expression-statement (as before) or a structured block, which has particular restrictions that the compiler will check.</p>
<p>When the compiler encounters the new OpenMP atomic clauses, it will make sure that the LLVM OpenMP runtime (<code>libomp</code>) is being used:</p>
<pre><code class="language-text">example.cpp(14): error C7660: '#pragma omp atomic update': requires '-openmp:llvm' command line option(s)</code></pre>
<p>This is because we support the newer semantics only on the new LLVM-based OpenMP runtime.</p>
<p><code>omp atomic</code> may seem like a duplication of <code>omp critical</code> but it is different in that <code>omp critical</code> is a generalized mutual exclusion mechanism and can wrap any kind of code, while <code>omp atomic</code> limits the kinds of operations that it supports. Based on these restrictions, the compiler can, in principle, generate more optimized code. For example, a critical section always requires acquiring a lock from the underlying operating system, but an atomic operation can use the underlying hardware guarantees to avoid such locking for, say, loads or stores of variables smaller than a register.</p>
<p>Consider this example from the OpenMP 3.1 Specification:</p>
<pre><code class="language-c++">int work1(int i);
int work2(int i);

void atomic_example(int* x, int* y, int* index, int n)
{
    int i;
    #pragma omp parallel for shared(x, y, index, n)
    for (i = 0; i &lt; n; i++) {
        #pragma omp atomic update
        x[index[i]] += work1(i);

        y[i] += work2(i);
    }
}</code></pre>
<p>Compiling the above for x86 with full optimizations, this is what gets generated:</p>
<pre><code class="language-nasm">    push    esi
    call    ?work1@@YAHH@Z              ; work1

; 9    : #pragma omp atomic update
; 10   : x[index[i]] += work1(i);

    mov ecx, DWORD PTR _x$[esp+20]
    push    eax
    mov eax, DWORD PTR _index$[esp+24]
    mov eax, DWORD PTR [eax+edi]
    lea eax, DWORD PTR [ecx+eax*4]
    push    eax
    push    ebx
    push    0
    call    ___kmpc_atomic_fixed4_add

; 11   :         y[i] += work2(i);

    push    esi
    call    ?work2@@YAHH@Z              ; work2
    add DWORD PTR [edi], eax</code></pre>
<p>Note that to update <code>x[index[i]]</code>, the code first calculates the address of that array location, and then calls the <code>libomp</code> API <code>__kpmc_atmoc_fixed4_add</code> to do the actual update atomically, while for the subsequent update of <code>y[i]</code>, the code is just an <code>add</code> instruction.</p>
<p>Given that the OpenMP atomic operations are meant to be an especially efficient form of critical section, it&#8217;s possible to optimize the above code by generating the code for the <code>__kmp_atomic_fixed4_add</code> library call inline and avoid a function call. We don&#8217;t currently do this but this work is planned for future versions of MSVC.</p>
<p>We now also support <code>capture</code> as a clause for <code>omp atomic</code>, with both the expression-statement and structured block syntax. Using the <code>capure</code> clause allows atomic update of an l-value while capturing its initial or final value at the same time. E.g., consider a team of threads which we have to allocate work to. Assume the work is allocated based on &#8220;slots&#8221; which are identified by a variable <code>slot</code>, with the idea being that each thread gets assigned a different value of this variable. This could be implemented using atomic capture in this way:</p>
<pre><code class="language-c++">void assign_work()
{
    int slot = 0;
    int my_slot;
    const int max_slot = 1'000'000;

    #pragma omp parallel private(my_slot)
    while (slot &lt; max_slot)
    {
        // Get the current value of slot and update it.
        // Note that all threads are going through the
        // slots in parallel
        #pragma omp atomic capture
        { my_slot = slot; ++slot; }
        do_work(my_slot);
    }
}</code></pre>
<p>Each parallel thread running the loop body will atomically save the current value of <code>slot</code> into its private variable <code>my_slot</code> and then increment <code>slot</code>, the whole operation being executed atomically with repect to other threads. Consequently, no two threads will get the same value of <code>slot</code> passed to <code>do_work</code> and eventually all values up to <code>max_slot</code> will be allocated.</p>
<p>We could also write the above atomic operation more compactly using the expression-statement version of <code>capture</code>:</p>
<pre><code class="language-c++">#pragma omp atomic capture
my_slot = slot++;</code></pre>
<p>The compiler has added diagnostics for required expression forms for <code>omp atomic</code>. E.g.,:</p>
<pre><code class="language-c++">#pragma omp atomic
{ v = x; +x; }</code></pre>
<p>produces:</p>
<pre><code class="language-text">.\atomic-capture-block.c(14,24): error C3048: '#pragma omp atomic capture': expression or block-statement following pragma does not conform to the OpenMP specification
            v = x; +x;
                   ^</code></pre>
<p>Attempting to use an overloaded operator in a capture block or expression gives:</p>
<pre><code class="language-text">.\atomic_capture_neg.cpp(18,11): error C3943: '#pragma omp atomic': operator '+=' is overloaded; only built-in operators are allowed
    x += s;
      ^</code></pre>
<p>We&#8217;ve added diagnostics to help with the validating the semantics and syntax of <code>#pragma omp atomic</code> but one thing should be borne in mind: because MSVC doesn&#8217;t print expressions in diagnostics, using <code>/diagnostics:caret</code> is helpful in getting the most from the new diagnostics. E.g.,</p>
<pre><code class="language-c++">int test(int initial)
{
    int v, x;
    #pragma omp atomic capture
    {
        v = x; v = v + 1;
    }
    return v;
}</code></pre>
<p>produces</p>
<pre><code class="language-text">.\atomic-capture-block.cpp(6,20): error C5300: '#pragma omp atomic capture': expression mismatch for lvalue being updated
            v = x; v = v + 1;
                   ^
.\atomic-capture-block.cpp(6,17): note: see the lvalue expression here
            v = x; v = v + 1;
                ^</code></pre>
<p>Without <code>/diagnostics:caret</code> we would have just the line numbers which don&#8217;t help in understanding the diagnostic.</p>
<h2 id="min-and-max-reduction-operators"><code>min</code> and <code>max</code> reduction operators</h2>
<p>MSVC has supported reduction operators since implementing OpenMP 2.0, to which we have now added support for <code>min</code> and <code>max</code> operations as well. Consider the simple case of determining the maximum of an array of values. Serial code to do this is given below:</p>
<pre><code class="language-c++">double serial_max(double* A, int size)
{
    int max = INT_MIN;
    for (int i = 0; i &lt; size; ++i)
        if (A[i] &gt; max)
            max = A[i];
    return max;
}</code></pre>
<p>Parallelizing this to run on multiple threads in a naive way requires a critical section to update <code>max</code>:</p>
<pre><code class="language-c++">double parallel_max(double* A, int size)
{
    int maxval = INT_MIN;
    #pragma omp parallel for shared(maxval)
    for (int i = 0; i &lt; size; ++i)
        #pragma omp critical
        if (A[i] &gt; maxval)
            maxval = A[i];
    return maxval;
}</code></pre>
<p>It&#8217;s obvious that the above version has a performance problem: every comparison of <code>max</code> to an array variable is being done in a critical section! To improve this, we can have each parallel thread maintain its own maximum and merge them at the end into one maximum for all of them. This will require maintaining an auxiliary vector of maximum values, one per thread, updating the right ones per thread and finally merging the maximum values into a single one, quite a chore if written out by hand. Instead, we can take advantage of the new <code>max</code> reduction operator and write a simple loop:</p>
<pre><code class="language-c++">double parallel_max(double* A, int size)
{
    int maxval = INT_MIN;
    #pragma omp parallel for reduction(max : maxval)
    for (i = 0; i &lt; size; ++i)
        if (A[i] &gt; maxval) maxval = A[i];
    return maxval;
}</code></pre>
<p>The above version creates a private <code>maxval</code> for each thread, which avoids the need for a critical section in the loop and at the end merges them all into a single maximum. Computing the minimum would use the <code>min</code> reduction operator in an analogous fashion.</p>
<h2 id="pointers-as-loop-index-variables-for-pragma-omp-for">Pointers as loop-index variables for <code>#pragma omp for</code></h2>
<p>MSVC has hitherto restricted loop variables to integral types while the OpenMP specification allowed pointer types as well. We have now implemented this feature and it is now possible to loop over arrays in parallel using either pointers or integer indices. E.g.,</p>
<pre><code class="language-c++">void test()
{
    int a[100];
    int *p, *begin = &amp;a[0], *end = &amp;a[100];
    int k = 0;

    #pragma omp parallel for
    for (p = begin; p &lt; end; ++p) 
        *p = k;
}</code></pre>
<p>As part of a general policy of supporting newer OpenMP features only on the LLVM <code>libomp</code> runtime, pointer loop variables require the compiler option <code>/openmp:llvm</code> to be used.</p>
<p>Note: C++ iterator support is not yet implemented but is planned for the future.</p>
<h2 id="miscellaneous-improvements-diagnostic-messages-and-bug-fixes">Miscellaneous improvements: diagnostic messages and bug fixes</h2>
<p>We&#8217;ve improved the accuracy or user friendliness of OpenMP diagnostic messages in several places. E.g., for loops, we&#8217;ve added checks for loop comparison operators:</p>
<pre><code class="language-c++">    #pragma omp parallel for
    for (p = begin; p &gt; end; ++p) *p = k;  // C5301</code></pre>
<p>produces:</p>
<pre><code class="language-text">.\loop_warnings_ptr.cpp(10,23): warning C5301: '#pragma omp for': 'p' increases while loop condition uses '&gt;'; non-terminating loop?
    for (p = begin; p &gt; end; ++p) *p = k;  // C5301
                      ^</code></pre>
<p>We&#8217;ve also fixed several bugs reported by users or discovered during our testing.</p>
<h2 id="a-note-about-the-llvm-runtime">A note about the LLVM runtime</h2>
<p>Currently, the LLVM runtime matching compiler is based on version 11. We plan to upgrade the runtime to a more recent version in a future release, but meanwhile we&#8217;ve ported a couple of critical bug fixes: <a href="https://reviews.llvm.org/rGb7b498657685d7a305987b9140253523e77fd4e1">rGb7b498657685 (llvm.org)</a> and <a href="https://reviews.llvm.org/rG1b968467c057df980df214a88cddac74dccff15e">rG1b968467c057 (llvm.org)</a>. Many thanks to <a href="https://reviews.llvm.org/p/jlpeyton/">Jonathan Peyton</a> who provided these fixes!</p>
<p>With the help of our colleague <a href="https://reviews.llvm.org/p/vadikp-intel/">Vadim Paretsky</a> from Intel, we&#8217;ve upstreamed changes (<a href="https://github.com/llvm/llvm-project/commit/f58fe2e1865d631b228d0bc78ebd4d95f752c51b">1</a>, <a href="https://github.com/llvm/llvm-project/commit/43d5c4d5394e522be87a9a1dfda24f5ce0e3a855">2</a>) to <code>main</code> that we&#8217;ve made so far to the <code>libomp</code> runtime. The only missing change is for atomics for ARM64.</p>
<p>We&#8217;re interested in hearing from you if you want to build your own <code>libomp</code> for Windows. Please reply in the blog comments in this case.</p>
<p>A word of caution: we had to accept a breaking change where ordinals for the exported symbols were changed in 17.4. Due to this, older <code>libomp140</code> runtime binaries won&#8217;t work with code if it&#8217;s built with newer <code>libomp.lib</code>, or vice versa. The best thing to do is to re-build all code using <code>/openmp:llvm</code>.</p>
<h2 id="summary">Summary</h2>
<p>MSVC continues to improve its OpenMP support and a full, optimized implementation of 3.1 is planned for the future. Based on user feedback, we may consider support for further versions or selected features from newer versions of OpenMP. Please use <a href="https://developercommunity.visualstudio.com/cpp">Developer Community</a> to add your voice to feature requests or report bugs.</p>
<p>The post <a rel="nofollow" href="https://devblogs.microsoft.com/cppblog/msvc-openmp-update/">MSVC OpenMP Update</a> appeared first on <a rel="nofollow" href="https://devblogs.microsoft.com/cppblog">C++ Team Blog</a>.</p>
]]></content:encoded>
					
					<wfw:commentRss>https://devblogs.microsoft.com/cppblog/msvc-openmp-update/feed/</wfw:commentRss>
			<slash:comments>1</slash:comments>
		
		
			</item>
		<item>
		<title>A Tour of 4 MSVC Backend Improvements</title>
		<link>https://devblogs.microsoft.com/cppblog/a-tour-of-4-msvc-backend-improvements/</link>
					<comments>https://devblogs.microsoft.com/cppblog/a-tour-of-4-msvc-backend-improvements/#comments</comments>
		
		<dc:creator><![CDATA[Sy Brand]]></dc:creator>
		<pubDate>Mon, 28 Nov 2022 15:58:27 +0000</pubDate>
				<category><![CDATA[C++]]></category>
		<category><![CDATA[performance]]></category>
		<guid isPermaLink="false">https://devblogs.microsoft.com/cppblog/?p=31340</guid>

					<description><![CDATA[<p>This blog post presents some of the optimizations the backend team has implemented for Visual Studio 2022.</p>
<p>The post <a rel="nofollow" href="https://devblogs.microsoft.com/cppblog/a-tour-of-4-msvc-backend-improvements/">A Tour of 4 MSVC Backend Improvements</a> appeared first on <a rel="nofollow" href="https://devblogs.microsoft.com/cppblog">C++ Team Blog</a>.</p>
]]></description>
										<content:encoded><![CDATA[<p>We hear that many of you would like to see more details of the improvements which the MSVC backend team have been working on recently. This blog post presents some of the optimizations the team has implemented for Visual Studio 2022. It was co-written by one of our backend team leads, Eric Brumer, and our developer advocate, Sy Brand. Keep an eye out for more posts in the future which will dig into other optimizations!</p>
<h2 id="byteswap-identification">Byteswap Identification</h2>
<p>Changing the <a href="https://en.wikipedia.org/wiki/Endianness">endianness</a> of an integer can be an important operation in contexts where data is being transmitted between processors with different byte orders, or over the network. This is often referred to as a &#8220;byteswap&#8221;. C++23 will add a <a href="https://en.cppreference.com/w/cpp/numeric/byteswap"><code>std::byteswap</code></a> function to the standard library (already implemented in VS2022 17.1), but for codebases today it&#8217;s common to see custom implementations, which might look something like this:</p>
<pre><code class="language-c++">int byteswap(int n) {
    return  ((n &amp; 0xff) &lt;&lt; 24u) |
            ((n &amp; 0xff00) &lt;&lt; 8u) |
            ((n &amp; 0xff0000) &gt;&gt; 8u) |
            ((n &amp; 0xff000000) &gt;&gt; 24u);
}</code></pre>
<p>In Visual Studio 2019 16.11, this generated the following code for x64, and a similarly long sequence of instructions for Arm64:</p>
<pre><code class="language-asm">        mov     eax, ecx
        mov     edx, ecx
        and     eax, 65280
        shl     edx, 16
        or      eax, edx
        mov     edx, ecx
        shl     eax, 8
        sar     edx, 8
        and     edx, 65280
        shr     ecx, 24
        or      eax, edx
        or      eax, ecx
        ret     0</code></pre>
<p>x64 and Arm64 both have instructions which carry out a byteswap, which should ideally be used instead. Visual Studio 2022 17.3 introduced automatic byteswap identification, and now outputs the following on x64 with <code>/O2</code>:</p>
<pre><code class="language-asm">        bswap   ecx
        mov     eax, ecx
        ret     0</code></pre>
<p>On Arm64, the results are much the same:</p>
<pre><code class="language-asm">        rev         w0,w0
        ret</code></pre>
<p>This optimization isn&#8217;t just doing a simple pattern match on your code, it&#8217;s a generalized bit tracker. For example, this bit order reverser gets optimized to a single <span style="color: #222222; font-family: Menlo, Monaco, Consolas, Liberation Mono, Courier New, monospace;"><span style="font-size: 14.4px; background-color: #f2f4f5;">rbit</span></span> on Arm64:</p>
<pre><code class="language-c++">unsigned __int64 bitswap(unsigned __int64 x) {
    x = _byteswap_uint64(x);
    x = (x &amp; 0xaaaaaaaaaaaaaaaa) &gt;&gt; 1 | (x &amp; 0x5555555555555555) &lt;&lt; 1;
    x = (x &amp; 0xcccccccccccccccc) &gt;&gt; 2 | (x &amp; 0x3333333333333333) &lt;&lt; 2;
    x = (x &amp; 0xf0f0f0f0f0f0f0f0) &gt;&gt; 4 | (x &amp; 0x0f0f0f0f0f0f0f0f) &lt;&lt; 4;
    return x;
}</code></pre>
<h2 id="loop-unswitching">Loop Unswitching</h2>
<p>For sake of code simplicity, we may choose to write a branch inside a loop whose condition is invariable in each iteration. For example, if we want to pet all our cats, and if it&#8217;s feeding time, we also want to feed them, we could write this:</p>
<pre><code class="language-cpp">void process_cats(std::span&lt;cat&gt; cats, bool is_feeding_time) {
    for (auto&amp;&amp; c : cats) {
        if (is_feeding_time) {
            feed(c);
        }
        pet(c);
    }
}</code></pre>
<p>Since <code>is_feeding_time</code> never changes inside the function and has no side-effects, it may be wasteful to carry out that check every iteration. Better hardware <a href="https://en.wikipedia.org/wiki/Branch_predictor">branch predictors</a> will minimize this impact, but in many cases we can see performance wins by carrying out <a href="https://en.wikipedia.org/wiki/Loop_unswitching">loop unswitching</a>. This hoists the branch outside of the loop, generating code similar to this C++:</p>
<pre><code class="language-cpp">void process_cats(std::span&lt;cat&gt; cats, bool is_feeding_time) {
    if (is_feeding_time) {
        for (auto&amp;&amp; c : cats) {
            feed(c);
            pet(c);
        }
    }
    else {
        for (auto&amp;&amp; c : cats) {
            pet(c);
        }
    }
}</code></pre>
<p>As of Visual Studio 2022 version 17.1, MSVC may carry out loop unswitching at <code>/O2</code>. This is a <a href="https://en.wikipedia.org/wiki/Heuristic_(computer_science)">heuristic</a>-driven optimization which may or may not be carried out depending on analysis results. This is because loop unswitching duplicates the loop body, which may affect instruction cache performance. You may pass the <code>/Qvec-report:1</code> flag to see a report on which loops were unswitched.</p>
<p>Here is the x64 generated by Visual Studio 2019 version 16.11 with <code>/O2</code>:</p>
<pre><code class="language-asm">$LN15:
        mov     QWORD PTR [rsp+8], rbx
        mov     QWORD PTR [rsp+16], rsi
        push    rdi
        sub     rsp, 32   
        mov     rbx, QWORD PTR [rcx]
        movzx   esi, dl
        mov     rax, QWORD PTR [rcx+8]
        lea     rdi, QWORD PTR [rbx+rax*4]
        cmp     rbx, rdi
        je      SHORT $LN3@process_ca
$LL4@process_ca:
        test    sil, sil
        je      SHORT $LN5@process_ca
        mov     ecx, DWORD PTR [rbx]
        call    void feed(cat)              
$LN5@process_ca:
        mov     ecx, DWORD PTR [rbx]
        call    void pet(cat)               
        add     rbx, 4
        cmp     rbx, rdi
        jne     SHORT $LL4@process_ca
$LN3@process_ca:
        mov     rbx, QWORD PTR [rsp+48]
        mov     rsi, QWORD PTR [rsp+56]
        add     rsp, 32   
        pop     rdi
        ret     0</code></pre>
<p>The key part to note here are the lines directly under the <code>$LL4@process_ca</code> label, which carry out the test on <code>is_feeding_time</code> and branch on the result, all inside the loop.</p>
<p>Here is the code generated now with <code>/O2</code>:</p>
<pre><code class="language-asm">$LN22:
        mov     QWORD PTR [rsp+8], rbx
        push    rdi
        sub     rsp, 32  
        mov     rbx, QWORD PTR [rcx]
        mov     rax, QWORD PTR [rcx+8]
        lea     rdi, QWORD PTR [rbx+rax*4]
        cmp     rbx, rdi
        je      SHORT $LN14@process_ca
        test    dl, dl
        je      SHORT $LL11@process_ca
        npad    2
$LL4@process_ca:
        mov     ecx, DWORD PTR [rbx]
        call    void feed(cat)
        mov     ecx, DWORD PTR [rbx]
        call    void pet(cat)     
        add     rbx, 4
        cmp     rbx, rdi
        jne     SHORT $LL4@process_ca
        mov     rbx, QWORD PTR [rsp+48]
        add     rsp, 32      
        pop     rdi
        ret     0
$LL11@process_ca:
        mov     ecx, DWORD PTR [rbx]
        call    void pet(cat)
        add     rbx, 4
        cmp     rbx, rdi
        jne     SHORT $LL11@process_ca
$LN14@process_ca:
        mov     rbx, QWORD PTR [rsp+48]
        add     rsp, 32    
        pop     rdi
        ret     0</code></pre>
<p>The code is now longer because two versions of the loop body are now generated, under the <code>$LL4@process_ca</code> and <code>$LL11@process_ca</code> labels. But also note that the branch occurs in the entry block of the function and selects between the two loop body versions:</p>
<pre><code class="language-asm">        cmp     rbx, rdi
        je      SHORT $LN14@process_ca
        test    dl, dl
        je      SHORT $LL11@process_ca</code></pre>
<h2 id="min-max-chains">Min/Max Chains</h2>
<p>We have improved optimization of chains of <code>std::min</code> and <code>std::max</code> as of Visual Studio 2022 version 17.0.</p>
<p>Say we have three blankets and we want to give one to our cat. The one we pick shouldn&#8217;t be too hard. It shouldn&#8217;t be too soft. It should be just right.</p>
<p>We could write a function to give us the Just Right blanket from three, by picking the middle one. It could look something like this:</p>
<pre><code class="language-c++">using softness = float;
softness just_right_blanket(softness a, softness b, softness c) {
    return std::max(std::min(a,b), std::min(std::max(a,b),c));
}</code></pre>
<p>In VS2019, this code was generated for x64 with <code>/O2 /fp:fast</code>:</p>
<pre><code class="language-asm">        comiss  xmm1, xmm0
        lea     rcx, QWORD PTR a$[rsp]
        lea     rax, QWORD PTR b$[rsp]
        lea     rdx, QWORD PTR a$[rsp]
        movss   DWORD PTR [rsp+16], xmm1
        movss   DWORD PTR [rsp+8], xmm0
        cmovbe  rax, rcx
        movss   DWORD PTR [rsp+24], xmm2
        lea     rcx, QWORD PTR c$[rsp]
        comiss  xmm2, DWORD PTR [rax]
        cmovae  rcx, rax
        lea     rax, QWORD PTR b$[rsp]
        comiss  xmm0, xmm1
        cmovbe  rax, rdx
        movss   xmm1, DWORD PTR [rax]
        comiss  xmm1, DWORD PTR [rcx]
        cmovb   rax, rcx
        movss   xmm0, DWORD PTR [rax]
        ret     0</code></pre>
<p>Arm64 codegen is similarly inefficient. Both x64 and Arm64 have single instructions for scalar floating point min and max, which we now use in VS2022 at <code>/O2</code> and above with <code>/fp:fast</code>. Here is the x64 code now:</p>
<pre><code class="language-asm">        movaps  xmm3, xmm0
        maxss   xmm0, xmm1
        minss   xmm3, xmm1
        minss   xmm0, xmm2
        maxss   xmm0, xmm3
        ret     0</code></pre>
<p>And for Arm64:</p>
<pre><code class="language-asm">        fmax        s16,s0,s1
        fmin        s17,s0,s1
        fmin        s18,s16,s2
        fmax        s0,s18,s17
        ret</code></pre>
<h2 id="backwards-loop-vectorization">Backwards Loop Vectorization</h2>
<p>Say I run a cat shelter with 32 cats and want to count how many crunchies they leave behind in their bowls after mealtime. So I write a function which takes a pointer to the first bowl, and sum it like so (yes, I know I could use <code>std::accumulate</code>):</p>
<pre><code class="language-c++">int count_leftovers(int* bowl_ptr) {
    int result = 0;

    for (int i = 0; i &lt; 32; ++i, ++bowl_ptr) {
        result += *bowl_ptr;
    }
    return result;
}</code></pre>
<p>This all works and generates good code! But then I realize that my desk is actually at the far end of the room, so I need to walk all the way to the start of the line to begin counting. I decide to instead take a pointer to the <em>last</em> bowl and work backwards:</p>
<pre><code class="language-c++">int count_leftovers(int* bowl_ptr) {
    int result = 0;

    // change ++bowl_ptr to --bowl_ptr
    for (int i = 0; i &lt; 32; ++i, --bowl_ptr) {
        result += *bowl_ptr;
    }
    return result;
}</code></pre>
<p>Unfortunately, if I was using VS2019, this loop would not be <a href="https://en.wikipedia.org/wiki/Automatic_vectorization">vectorized</a>. Here is the code generated with <code>/O2</code>:</p>
<pre><code class="language-asm">        xor     eax, eax
        mov     edx, eax
        mov     r8d, eax
        mov     r9d, eax
        add     rcx, -8
        lea     r10d, QWORD PTR [rax+8]
$LL4@count_left:
        add     eax, DWORD PTR [rcx+8]
        add     r9d, DWORD PTR [rcx+4]
        add     r8d, DWORD PTR [rcx]
        add     edx, DWORD PTR [rcx-4]
        lea     rcx, QWORD PTR [rcx-16]
        sub     r10, 1
        jne     SHORT $LL4@count_left
        lea     ecx, DWORD PTR [rdx+r8]
        add     ecx, r9d
        add     eax, ecx
        ret     0</code></pre>
<p>The loop is <a href="https://en.wikipedia.org/wiki/Loop_unrolling">unrolled</a> but it is not vectorized.</p>
<p>We enabled vectorization for backwards-strided loops in VS2022 17.1. The code generated will depend a lot on the flags you use, particularly the <a href="https://learn.microsoft.com/cpp/build/reference/arch-x64?view=msvc-170"><code>/arch</code></a> flag for enabling use of <a href="https://en.wikipedia.org/wiki/Advanced_Vector_Extensions">AVX</a> instructions instead of the default <a href="https://en.wikipedia.org/wiki/SSE2">SSE2</a> ones.</p>
<p>Here is the code generated for <code>/O2 /arch:AVX2</code>:</p>
<pre><code class="language-asm">        vpxor   xmm2, xmm2, xmm2
        vpxor   xmm3, xmm3, xmm3
        mov     eax, 2
        npad    3
$LL4@count_left:
        vmovd   xmm1, DWORD PTR [rcx]
        vpinsrd xmm1, xmm1, DWORD PTR [rcx-4], 1
        vpinsrd xmm1, xmm1, DWORD PTR [rcx-8], 2
        vpinsrd xmm1, xmm1, DWORD PTR [rcx-12], 3
        vmovd   xmm0, DWORD PTR [rcx-16]
        vpinsrd xmm0, xmm0, DWORD PTR [rcx-20], 1
        vpinsrd xmm0, xmm0, DWORD PTR [rcx-24], 2
        vpinsrd xmm0, xmm0, DWORD PTR [rcx-28], 3
        lea     rcx, QWORD PTR [rcx-64]
        vinsertf128 ymm0, ymm1, xmm0, 1
        vmovd   xmm1, DWORD PTR [rcx+32]
        vpinsrd xmm1, xmm1, DWORD PTR [rcx+28], 1
        vpinsrd xmm1, xmm1, DWORD PTR [rcx+24], 2
        vpinsrd xmm1, xmm1, DWORD PTR [rcx+20], 3
        vpaddd  ymm2, ymm0, ymm2
        vmovd   xmm0, DWORD PTR [rcx+16]
        vpinsrd xmm0, xmm0, DWORD PTR [rcx+12], 1
        vpinsrd xmm0, xmm0, DWORD PTR [rcx+8], 2
        vpinsrd xmm0, xmm0, DWORD PTR [rcx+4], 3
        vinsertf128 ymm0, ymm1, xmm0, 1
        vpaddd  ymm3, ymm0, ymm3
        sub     rax, 1
        jne     $LL4@count_left
        vpaddd  ymm0, ymm3, ymm2
        vphaddd ymm1, ymm0, ymm0
        vphaddd ymm2, ymm1, ymm1
        vextracti128 xmm0, ymm2, 1
        vpaddd  xmm0, xmm2, xmm0
        vmovd   eax, xmm0
        vzeroupper
        ret     0</code></pre>
<p>This both unrolls and vectorizes the loop. Fully explaining AVX2 vector instructions is a job for a different blog post (maybe check out <a href="https://www.codeproject.com/Articles/874396/Crunching-Numbers-with-AVX-and-AVX">this one</a>), but the basic idea is that all those <a href="https://www.felixcloutier.com/x86/pinsrb:pinsrd:pinsrq"><code>vpinsrd</code></a> instructions are loading the data from memory into vector registers, then the <a href="https://www.felixcloutier.com/x86/paddb:paddw:paddd:paddq"><code>vpaddd</code></a>/<a href="https://www.felixcloutier.com/x86/phaddw:phaddd"><code>vphaddd</code></a> instructions carry out addition on big chunks of data all at the same time.</p>
<h2 id="send-us-your-feedback">Send us your feedback</h2>
<p>We hope you found these details interesting! If you have ideas for similar posts you&#8217;d like to see, please let us know. We are also interested in your feedback to continue to improve our tools. The comments below are open. Feedback can also be shared through <a href="https://developercommunity.visualstudio.com/cpp">Developer Community</a>. You can also reach us on Twitter (<a href="https://twitter.com/visualc">@VisualC</a>), or via email at <a href="mailto:visualcpp@microsoft.com">visualcpp@microsoft.com</a>.</p>
<p>The post <a rel="nofollow" href="https://devblogs.microsoft.com/cppblog/a-tour-of-4-msvc-backend-improvements/">A Tour of 4 MSVC Backend Improvements</a> appeared first on <a rel="nofollow" href="https://devblogs.microsoft.com/cppblog">C++ Team Blog</a>.</p>
]]></content:encoded>
					
					<wfw:commentRss>https://devblogs.microsoft.com/cppblog/a-tour-of-4-msvc-backend-improvements/feed/</wfw:commentRss>
			<slash:comments>4</slash:comments>
		
		
			</item>
		<item>
		<title>vcpkg 2022.11.14 and 2022.10.19 Releases: Localization for 14 Languages, Overlay Ports/Triplets in Manifests, acquire-project Command, and More…</title>
		<link>https://devblogs.microsoft.com/cppblog/vcpkg-2022-11-14-and-2022-10-19-releases-localization-for-14-languages-overlay-ports-triplets-in-manifests-acquire-project-command-and-more/</link>
					<comments>https://devblogs.microsoft.com/cppblog/vcpkg-2022-11-14-and-2022-10-19-releases-localization-for-14-languages-overlay-ports-triplets-in-manifests-acquire-project-command-and-more/#comments</comments>
		
		<dc:creator><![CDATA[Augustin Popa]]></dc:creator>
		<pubDate>Wed, 16 Nov 2022 01:29:51 +0000</pubDate>
				<category><![CDATA[C++]]></category>
		<guid isPermaLink="false">https://devblogs.microsoft.com/cppblog/?p=31329</guid>

					<description><![CDATA[<p>The 2022.11.14 release of the vcpkg package manager is available. This blog post summarizes changes from September 27th, 2022 to November 13th, 2022 for the Microsoft/vcpkg and Microsoft/vcpkg-tool GitHub repos.<br />
Some stats for this period:</p>
<p>47 new ports were added to the open-source registry.</p>
<p>The post <a rel="nofollow" href="https://devblogs.microsoft.com/cppblog/vcpkg-2022-11-14-and-2022-10-19-releases-localization-for-14-languages-overlay-ports-triplets-in-manifests-acquire-project-command-and-more/">vcpkg 2022.11.14 and 2022.10.19 Releases: Localization for 14 Languages, Overlay Ports/Triplets in Manifests, acquire-project Command, and More…</a> appeared first on <a rel="nofollow" href="https://devblogs.microsoft.com/cppblog">C++ Team Blog</a>.</p>
]]></description>
										<content:encoded><![CDATA[<p>The <a href="https://github.com/microsoft/vcpkg/releases/tag/2022.11.14">2022.11.14 release of the vcpkg package manager is available</a>. This blog post summarizes changes from September 27<sup>th</sup>, 2022 to November 13<sup>th</sup>, 2022 for the <a href="https://github.com/microsoft/vcpkg">Microsoft/vcpkg</a> and <a href="https://github.com/microsoft/vcpkg-tool/">Microsoft/vcpkg-tool</a> GitHub repos.</p>
<p>Some stats for this period:</p>
<ul>
<li><strong>47 new ports</strong> were added to the open-source registry. If you are unfamiliar with the term ‘port’, they are packages that are built from source and are typically C/C++ libraries.</li>
<li><strong>519 updates</strong> were made to existing ports. As always, we validate each change to a port by building all other ports that depend on or are depended by the library that is being updated for our nine main triplets.</li>
<li>There are now <strong>2,069 total libraries</strong> available in the vcpkg public registry. There are a total of <strong>10,964</strong> ports if each library version is counted uniquely.</li>
<li>The <a href="https://github.com/microsoft/vcpkg/releases/tag/2022.11.14">2022.11.14 release of the main vcpkg repo</a> includes <strong>65 commits</strong>.</li>
<li><strong>68 contributors</strong> submitted PRs, issues, or participated in discussions in the repo.</li>
<li>The main vcpkg repo has over <strong>4,900 forks</strong> and <strong>17,100 stars</strong> on GitHub.</li>
</ul>
<p>&nbsp;</p>
<h3 id="notable-changes">Notable Changes</h3>
<p>Notable changes for this release are summarized below:</p>
<p>&nbsp;</p>
<h4 id="localized-vcpkg-output-is-now-available">Localized vcpkg output is now available</h4>
<p>One of the steps required for us to ship vcpkg in Visual Studio was to localize its output to a variety of languages. This experience is now enabled in the tool for 14 languages – the same languages available for Visual Studio. You can change the language of vcpkg’s output (even if you’re not using Visual Studio) by setting an environment variable called VSLANG to a 4-digit LCID (locale identifier) code. For example, setting this variable to 1033 sets the language to English. For more details, including a list of available LCIDs, <a href="https://github.com/microsoft/vcpkg-tool/blob/main/docs/localization.md">see our documentation</a> on this.</p>
<p>&nbsp;</p>
<h4 id="configuring-overlay-ports-and-triplets-in-a-manifest-file">Configuring overlay ports and triplets in a manifest file</h4>
<p><strong>Overlay ports</strong> is a feature of vcpkg that allows the user to override the default port vcpkg would have installed with a custom one. This can be useful when the user needs to patch a library and deviate from the default experience. Note: this is very different from installing a different version of a library, which does not require creating a custom port.</p>
<p><strong>Overlay triplets</strong> work similarly by overriding default vcpkg triplets with customized ones. A use case for this can be if you require additional compile flags for your build over what vcpkg would run by default.</p>
<p>Historically, it was only possible to set overlay ports and triplets on the command line, via environment variables, or through the build system. Now, it is possible to configure these in a vcpkg-configuration.json file by enabling an optional object to the schema which receives a path or list of paths. This provides a better experience when a user wants to provide multiple additional paths for one install. Ports are resolved from top to bottom. Here is an example:</p>
<pre class="prettyprint">{
    "default-registry": {
    "kind": "git",
    "repository": "&lt;https://internal/mirror/of/github.com/Microsoft/vcpkg&gt;",
    "baseline": "eefee7408133f3a0fef711ef9c6a3677b7e06fd7"
    },
    "registries": [{
        "kind": "git",
        "repository": "&lt;https://github.com/my-repository/vcpkg-registry&gt;",
        "baseline": "xxxxxxx000000000000000000000000000000000",
        "packages": [ "my", "packages" ]
    }],
    "overlay-ports": [
    "./my-ports/fmt",
    "custom-ports",
    "../share/team-ports"
    ],
    "overlay-triplets" : [ "./my-triplets" ]
}</pre>
<p><strong>Note:</strong> if overlay ports are configured in multiple ways, we prioritize them in the following order:</p>
<ol>
<li>Command line</li>
<li>Manifest (vcpkg-configuration.json)</li>
<li>Environment variables</li>
</ol>
<p>In other words, a port configured in the command line will always override the same port being configured in a manifest or an environment variable, and ports configured in the manifest override the same ports being configured as environment variables.</p>
<p>See our <a href="https://github.com/microsoft/vcpkg/blob/master/docs/users/registries.md">article on registries</a> for additional documentation on this feature.</p>
<p>&nbsp;</p>
<h4 id="new-artifact-command-acquire-project">New artifact command: acquire-project</h4>
<p>A new command for managing vcpkg artifacts has been added: acquire-project. Like the activate command, it affects all artifact dependencies listed in the manifest, but it only downloads and extracts them without activating them in the environment. Functionally like running vcpkg acquire once for each dependency.</p>
<p>&nbsp;</p>
<h4 id="console-output-less-verbose-in-manifest-mode">Console output less verbose in manifest mode</h4>
<p>The option &#8211;no-print-usage now supports manifest mode (by @demianmnave-pti in <a href="https://github.com/microsoft/vcpkg-tool/pull/721">Microsoft/vcpkg-tool#721</a>). This switch suppresses the printing of usage text at the end of a port installation.</p>
<p>&nbsp;</p>
<h4 id="get-current-port-version-in-portfile-cmake">Get current port version in portfile.cmake</h4>
<p>It is now possible to reference a port’s current version when authoring ports in their portfile.cmake using a variable called VERSION. Implemented by @autoantwort.</p>
<p>&nbsp;</p>
<h4 id="ignore-the-vcpkg_root-environment-variable-when-we-already-detected-a-vcpkg-root">Ignore the VCPKG_ROOT environment variable when we already detected a vcpkg root</h4>
<p>The VCPKG_ROOT environment variable can be used to point to the location of a vcpkg instance. This is useful for example in pre-configured CI systems so the user can run vcpkg commands without having to go looking for vcpkg first. However, this can be problematic if the user is consuming vcpkg as a git submodule and doesn’t want to use the default machine-wide instance. Now, if a vcpkg root directory is detected, we will no longer override it with the VCPKG_ROOT environment variable. vcpkg will output a warning when the environment variable is ignored.</p>
<p>&nbsp;</p>
<h4 id="documentation-changes">Documentation Changes</h4>
<p>We are continuing to improve our vcpkg documentation:</p>
<ol>
<li><a href="https://github.com/microsoft/vcpkg/blob/master/docs/commands/list.md">Added reference documentation for vcpkg list command</a>.</li>
<li><a href="https://github.com/microsoft/vcpkg/blob/master/docs/commands/version.md">Added reference documentation for vcpkg version command</a>.</li>
<li>Added reference documentation for three topics:
<ol>
<li><a href="https://github.com/microsoft/vcpkg/blob/master/docs/users/manifests.md">Embedding vcpkg-configuration.json contents in vcpkg.json</a></li>
<li><a href="https://github.com/microsoft/vcpkg/blob/master/docs/users/registries.md">Overlay ports in vcpkg-configuration.json</a></li>
<li><a href="https://github.com/microsoft/vcpkg/blob/master/docs/users/registries.md">Overlay triplets in vcpkg-configuration.json</a></li>
</ol>
</li>
</ol>
<p>&nbsp;</p>
<h3 id="total-ports-available-for-tested-triplets">Total Ports Available for Tested Triplets</h3>
<table>
<tbody>
<tr>
<td><strong>triplet</strong></td>
<td><strong>ports available</strong></td>
</tr>
<tr>
<td>x86-windows</td>
<td>1,860</td>
</tr>
<tr>
<td>x64-windows</td>
<td>1,924</td>
</tr>
<tr>
<td>x64-windows-static</td>
<td>1,826</td>
</tr>
<tr>
<td>x64-windows-static-md</td>
<td>1,839</td>
</tr>
<tr>
<td>x64-uwp</td>
<td>971</td>
</tr>
<tr>
<td>arm64-windows</td>
<td>1,497</td>
</tr>
<tr>
<td>arm-uwp</td>
<td>924</td>
</tr>
<tr>
<td>x64-osx</td>
<td>1,791</td>
</tr>
<tr>
<td>x64-linux</td>
<td>1,867</td>
</tr>
</tbody>
</table>
<p>While vcpkg supports a much larger variety of target platforms and architectures, the list above is validated exhaustively to ensure updated ports don’t break other ports in the catalog.</p>
<p>&nbsp;</p>
<h3 id="thank-you-to-our-contributors">Thank You to Our Contributors</h3>
<p>vcpkg couldn’t be where it is today without contributions from our open-source community. Thank you for your continued support! The following people contributed to the vcpkg and vcpkg-tool repos in this release:</p>
<ul>
<li>autoantwort (54 commits)</li>
<li>dg0yt (35 commits)</li>
<li>Neumann-A (17 commits)</li>
<li>AtariDreams (10 commits)</li>
<li>Honeybunch (9 commits)</li>
<li>Thomas1664 (9 commits)</li>
<li>SchaichAlonso (8 commits)</li>
<li>Tradias (7 commits)</li>
<li>RT222 (6 commits)</li>
<li>Osyotr (3 commits)</li>
<li>m-kuhn (4 commits)</li>
<li>chausner (4 commits)</li>
<li>luncliff (4 commits)</li>
<li>gjasny (3 commits)</li>
<li>past-due (3 commit)</li>
<li>AenBleidd (3 commits)</li>
<li>coryan (2 commit)</li>
<li>wrobelda (1 commit)</li>
<li>daschuer (1 commit)</li>
<li>longnguyen2004 (1 commit)</li>
<li>an-tao (1 commit)</li>
<li>klalumiere (1 commit)</li>
</ul>
<p>&nbsp;</p>
<h3 id="learn-more">Learn More</h3>
<p>You can find the <a href="https://github.com/microsoft/vcpkg/releases/tag/2022.11.14">full 2022.11.14 release notes on GitHub</a> for the main repo. Recent updates to the vcpkg tool can be viewed on the <a href="https://github.com/microsoft/vcpkg-tool/releases">vcpkg-tool Releases page</a>. If you’re new to vcpkg or curious about how a package manager can make your life easier as a C/C++ developer, check out the <a href="https://vcpkg.io/en/index.html">vcpkg website – vcpkg.io</a>.</p>
<p>If you would like to contribute to vcpkg and its library catalog, or want to give us feedback on anything, check out our <a href="https://github.com/microsoft/vcpkg/releases">GitHub repo</a>. Please report bugs or request updates to ports in our <a href="https://github.com/microsoft/vcpkg/issues">issue tracker</a>, or join more general discussion in our <a href="https://github.com/microsoft/vcpkg/discussions">discussion forum</a>. For an overview of our top priorities and backlog, take a look at our <a href="https://github.com/microsoft/vcpkg/wiki/Roadmap">roadmap page</a>.</p>
<p>&nbsp;</p>
<h3 id="interested-in-vcpkg-but-not-sure-where-to-start">Interested in vcpkg but not sure where to start?</h3>
<p>Is your company experiencing challenges managing C/C++ libraries? Perhaps you’re curious if a package manager is the right choice to you? Please reach out to <a href="mailto:vcpkg@microsoft.com">vcpkg@microsoft.com</a> and we’d be happy to help!</p>
<p>The post <a rel="nofollow" href="https://devblogs.microsoft.com/cppblog/vcpkg-2022-11-14-and-2022-10-19-releases-localization-for-14-languages-overlay-ports-triplets-in-manifests-acquire-project-command-and-more/">vcpkg 2022.11.14 and 2022.10.19 Releases: Localization for 14 Languages, Overlay Ports/Triplets in Manifests, acquire-project Command, and More…</a> appeared first on <a rel="nofollow" href="https://devblogs.microsoft.com/cppblog">C++ Team Blog</a>.</p>
]]></content:encoded>
					
					<wfw:commentRss>https://devblogs.microsoft.com/cppblog/vcpkg-2022-11-14-and-2022-10-19-releases-localization-for-14-languages-overlay-ports-triplets-in-manifests-acquire-project-command-and-more/feed/</wfw:commentRss>
			<slash:comments>2</slash:comments>
		
		
			</item>
		<item>
		<title>Visual Studio 2022 Performance: Faster C++ Source Code Indexing</title>
		<link>https://devblogs.microsoft.com/cppblog/faster-cpp-source-code-indexing/</link>
					<comments>https://devblogs.microsoft.com/cppblog/faster-cpp-source-code-indexing/#respond</comments>
		
		<dc:creator><![CDATA[Victor Ciura]]></dc:creator>
		<pubDate>Tue, 15 Nov 2022 16:00:21 +0000</pubDate>
				<category><![CDATA[C++]]></category>
		<category><![CDATA[performance]]></category>
		<guid isPermaLink="false">https://devblogs.microsoft.com/cppblog/?p=31318</guid>

					<description><![CDATA[<p>Building on top of our performance wins in Visual Studio 2022 version 17.3, we are excited to announce additional improvements in version 17.4.<br />
Whether you are a game developer, work with large codebases, or have solutions with many C++ projects, your development experience in Visual Studio 2022 17.4 will feel even faster.</p>
<p>The post <a rel="nofollow" href="https://devblogs.microsoft.com/cppblog/faster-cpp-source-code-indexing/">Visual Studio 2022 Performance: Faster C++ Source Code Indexing</a> appeared first on <a rel="nofollow" href="https://devblogs.microsoft.com/cppblog">C++ Team Blog</a>.</p>
]]></description>
										<content:encoded><![CDATA[<p>Building on top of <a id="post-31318-_Int_H4uFQVnC"></a>our <a href="https://devblogs.microsoft.com/cppblog/vs2022-performance-enhancements-faster-c-development/">performance wins</a> in Visual Studio 2022 version 17.3, we are excited to announce additional improvements in version 17.4.</p>
<p>Whether you are a game developer, work with large codebases, or have solutions with many C++ projects, your development experience in Visual Studio 2022 17.4 will feel <em>even faster</em>.</p>
<p>In 17.4 we significantly reduced the time it takes to open a C++ project for the first time (cold load).</p>
<p>While working on these improvements, we constantly check our performance against real-life large projects, including some of our own, as well as several C++ codebases for popular games from our partner game studios.</p>
<p>Large C++ projects could see a 20-36% speed improvement over 17.3 when populating the source code database used for browsing and navigation.</p>
<p>When compared to VS 2019, the cumulative performance gains for this scenario should be between 2X-6X depending on the project structure and size.</p>
<p>In this post, we want to highlight the C++ project indexing scenario for the <a href="https://en.wikipedia.org/wiki/Gears_of_War">Gears of War</a> source code and a generic Unreal Engine 5 starter project.</p>
<h2 id="testing-methodology">Testing Methodology</h2>
<p>Hardware: AMD Ryzen PRO 3945WX 12/24, 128GB RAM, 2.5TB SSD, RTX 3080</p>
<p>Projects/source code: Gears of War, Unreal Engine 5 starter project, Chromium</p>
<p>Visual Studio: VS2019 v16.11 and VS2022 v17.4</p>
<p>For all scenarios, we used VS system events/logs to track the duration of the operations.</p>
<h3 id="results">Results</h3>
<p>Let’s see the cumulative effect of all the improvements we made in this area for C++ projects, for the past year.</p>
<p><img decoding="async" width="1431" height="1080" class="wp-image-31319" src="https://devblogs.microsoft.com/cppblog/wp-content/uploads/sites/9/2022/11/chart-bar-chart-description-automatically-genera-1.png" alt="Chart, bar chart Description automatically generated" srcset="https://devblogs.microsoft.com/cppblog/wp-content/uploads/sites/9/2022/11/chart-bar-chart-description-automatically-genera-1.png 1431w, https://devblogs.microsoft.com/cppblog/wp-content/uploads/sites/9/2022/11/chart-bar-chart-description-automatically-genera-1-300x226.png 300w, https://devblogs.microsoft.com/cppblog/wp-content/uploads/sites/9/2022/11/chart-bar-chart-description-automatically-genera-1-1024x773.png 1024w, https://devblogs.microsoft.com/cppblog/wp-content/uploads/sites/9/2022/11/chart-bar-chart-description-automatically-genera-1-768x580.png 768w" sizes="(max-width: 1431px) 100vw, 1431px" /></p>
<p>In Visual Studio 2019 16.11, it takes roughly <a id="post-31318-OLE_LINK1"></a>6½ minutes for Gears of War to fully index. In Visual Studio 2022 17.4, waiting for indexing to finish will only take a bit over <a id="post-31318-OLE_LINK2"></a>2½ minutes, resulting in a <strong>2.5X</strong> speed up.</p>
<p><img decoding="async" width="1431" height="1080" class="wp-image-31320" src="https://devblogs.microsoft.com/cppblog/wp-content/uploads/sites/9/2022/11/word-image-31318-2.png" srcset="https://devblogs.microsoft.com/cppblog/wp-content/uploads/sites/9/2022/11/word-image-31318-2.png 1431w, https://devblogs.microsoft.com/cppblog/wp-content/uploads/sites/9/2022/11/word-image-31318-2-300x226.png 300w, https://devblogs.microsoft.com/cppblog/wp-content/uploads/sites/9/2022/11/word-image-31318-2-1024x773.png 1024w, https://devblogs.microsoft.com/cppblog/wp-content/uploads/sites/9/2022/11/word-image-31318-2-768x580.png 768w" sizes="(max-width: 1431px) 100vw, 1431px" /></p>
<p>When getting to code in a new Unreal Engine 5 solution, you will see a huge improvement in the latest version of VS2022 versus VS2019. In VS2019 16.11, fully indexing a brand-new C++ UE5 solution took a bit over 2½ minutes. When using VS2022 17.4, fully indexing the same UE5 solution is now <strong>2.7X</strong> faster at just 1 minute. Whether you are creating a new UE5 project or cloning from an existing repo, your code will index much faster in 17.4.</p>
<h3 id="pushing-the-limits">Pushing the limits</h3>
<p>Few open-source projects reach the scale of <a href="https://chromium.googlesource.com/chromium/src.git">Chromium</a> with over 12,000 projects in one single Visual Studio solution, so naturally it’s an irresistible target for stress testing the components we’re improving. Let’s see how we did.</p>
<p><img decoding="async" width="1431" height="1080" class="wp-image-31321" src="https://devblogs.microsoft.com/cppblog/wp-content/uploads/sites/9/2022/11/word-image-31318-3.png" srcset="https://devblogs.microsoft.com/cppblog/wp-content/uploads/sites/9/2022/11/word-image-31318-3.png 1431w, https://devblogs.microsoft.com/cppblog/wp-content/uploads/sites/9/2022/11/word-image-31318-3-300x226.png 300w, https://devblogs.microsoft.com/cppblog/wp-content/uploads/sites/9/2022/11/word-image-31318-3-1024x773.png 1024w, https://devblogs.microsoft.com/cppblog/wp-content/uploads/sites/9/2022/11/word-image-31318-3-768x580.png 768w" sizes="(max-width: 1431px) 100vw, 1431px" /></p>
<p>In Visual Studio 2019 16.11, it takes roughly 31 minutes for the Chromium repo to fully index. In Visual Studio 2022 17.4, waiting for indexing to finish will only take just 5 minutes, a <strong>6X</strong> speed up. When indexing a large solution like the Chromium repo for the first time, you will save up to 26 minutes with the latest version of Visual Studio.</p>
<h3 id="try-it-out">Try it out</h3>
<p>Although everyone should see considerable improvements for these scenarios, the magnitude of the gains is dependent on your source code, project layout, include graph, etc. So, try it out on your codebase and let us know about your project load/parsing gains for IntelliSense start-up.</p>
<h2 id="feedback-wanted">Feedback Wanted!</h2>
<p>Your feedback through <a href="https://developercommunity.visualstudio.com/" target="_blank" rel="noopener">Developer Community</a>, surveys, and social media channels has made these improvements possible. We thank you for your valuable comments. These enhancements are a continuation of our focus on improving productivity for game developers. Throughout the Visual Studio 2022 development cycle, we will continue to make improvements like ones detailed in this blogpost. If you are a game developer, <a href="http://aka.ms/VSGameDevSurvey" target="_blank" rel="noopener">let us know your thoughts in our 2022 Visual Studio Game Developer Survey</a>.</p>
<p>In addition, please continue to help shape the development of Visual Studio by talking to us in the comments below, on Twitter (<a href="https://twitter.com/visualc" target="_blank" rel="noopener">@VisualC</a>), or via email at <a href="mailto:visualcpp@microsoft.com">visualcpp@microsoft.com</a></p>
<h2 id="upgrade-to-visual-studio-2022">Upgrade to Visual Studio 2022</h2>
<p><a href="https://visualstudio.microsoft.com/downloads/" target="_blank" rel="noopener">Download the latest version of Visual Studio 2022</a> to take advantage of these productivity benefits today!</p>
<p>&nbsp;</p>
<p>&nbsp;</p>
<p>The post <a rel="nofollow" href="https://devblogs.microsoft.com/cppblog/faster-cpp-source-code-indexing/">Visual Studio 2022 Performance: Faster C++ Source Code Indexing</a> appeared first on <a rel="nofollow" href="https://devblogs.microsoft.com/cppblog">C++ Team Blog</a>.</p>
]]></content:encoded>
					
					<wfw:commentRss>https://devblogs.microsoft.com/cppblog/faster-cpp-source-code-indexing/feed/</wfw:commentRss>
			<slash:comments>0</slash:comments>
		
		
			</item>
		<item>
		<title>What’s New for C++ Developers in Visual Studio 2022 17.4</title>
		<link>https://devblogs.microsoft.com/cppblog/whats-new-for-cpp-developers-in-visual-studio-2022-17-4/</link>
					<comments>https://devblogs.microsoft.com/cppblog/whats-new-for-cpp-developers-in-visual-studio-2022-17-4/#respond</comments>
		
		<dc:creator><![CDATA[Sy Brand]]></dc:creator>
		<pubDate>Tue, 08 Nov 2022 10:30:45 +0000</pubDate>
				<category><![CDATA[Announcement]]></category>
		<category><![CDATA[C++]]></category>
		<guid isPermaLink="false">https://devblogs.microsoft.com/cppblog/?p=31267</guid>

					<description><![CDATA[<p>We are happy to announce that Visual Studio 2022 version 17.4 is now generally available! This post summarizes the new features you can find in this release for C++. You can download Visual Studio 2022 from the Visual Studio downloads page or upgrade your existing installation by following the Update Visual Studio Learn page.</p>
<p>The post <a rel="nofollow" href="https://devblogs.microsoft.com/cppblog/whats-new-for-cpp-developers-in-visual-studio-2022-17-4/">What’s New for C++ Developers in Visual Studio 2022 17.4</a> appeared first on <a rel="nofollow" href="https://devblogs.microsoft.com/cppblog">C++ Team Blog</a>.</p>
]]></description>
										<content:encoded><![CDATA[<p>We are happy to announce that Visual Studio 2022 version 17.4 is now generally available! This post summarizes the new features you can find in this release for C++. You can download Visual Studio 2022 from the <a href="https://visualstudio.microsoft.com/downloads/">Visual Studio downloads page </a>or upgrade your existing installation by following the <a href="https://learn.microsoft.com/en-us/visualstudio/install/update-visual-studio?view=vs-2022">Update Visual Studio Learn page</a>.</p>
<h1 id="arm64">Arm64</h1>
<p>In 17.3, Visual Studio became available as a native Arm64 application. We have continued work on supporting more development scenarios and are pleased to announce that the native Arm64 toolchain is now ready for production use!</p>
<p>The “Desktop development with C++” and “Game development with C++” workloads are enabled for native Arm64 development. Please give them a try and let us know your feedback!</p>
<h1 id="msvc">MSVC</h1>
<p>One of our major investments for this release has been in improved compiler diagnostics. New C++ features like concepts and ranges present the opportunity for more expressive code and better-defined APIs. However, to make the most of them, better diagnostics are required from tooling so that constraint failures can be pinpointed and resolved. See Xiang Fan’s blog post on <a href="https://devblogs.microsoft.com/cppblog/the-future-of-c-compiler-diagnostics-in-msvc-and-visual-studio/">The Future of C++ Compiler Diagnostics in MSVC and Visual Studio</a> for all the details, but here’s a quick example of the improvement, showing more complete information on overload resolution failures, and information on why a given constraint failed:</p>
<pre class="prettyprint language-cpp"><code class="language-cpp">struct cat {};
struct dog {};

// can pet cats and dogs
void pet(cat);
void pet(dog);

template &lt;class T&gt;
concept has_member_pettable = requires (T t) { t.pet(); };

// allow calling as a non-member
template &lt;has_member_pettable T&gt;
void pet(T);

int main() {
    pet(0); //oh no
}</code></pre>
<p><strong>Error in 17.3</strong></p>
<pre class="prettyprint language-default"><code class="language-default">&lt;source&gt;(16,10): error C2665: 'pet': none of the 2 overloads could convert all the argument types
    pet(0); //oh no
         ^
&lt;source&gt;(6,6): note: could be 'void pet(dog)'
void pet(dog);
     ^
&lt;source&gt;(5,6): note: or 'void pet(cat)'
void pet(cat);
     ^
&lt;source&gt;(16,5): note: 'void pet(cat)': cannot convert argument 1 from 'int' to 'cat'
    pet(0); //oh no
    ^
&lt;source&gt;(16,10): note: No constructor could take the source type, or constructor overload resolution was ambiguous
    pet(0); //oh no
         ^
&lt;source&gt;(5,6): note: see declaration of 'pet'
void pet(cat);
     ^
&lt;source&gt;(16,10): note: while trying to match the argument list '(int)'
    pet(0); //oh no</code></pre>
<p><strong>Error in 17.4</strong></p>
<pre>&lt;source&gt;(16,5): error C2665: 'pet': no overloaded function could convert all the argument types
    pet(0); //oh no
    ^
&lt;source&gt;(6,6): note: could be 'void pet(dog)'
void pet(dog);
     ^
&lt;source&gt;(16,5): note: 'void pet(dog)': cannot convert argument 1 from 'int' to 'dog'
    pet(0); //oh no
    ^
&lt;source&gt;(16,9): note: No constructor could take the source type, or constructor overload resolution was ambiguous
    pet(0); //oh no
        ^
&lt;source&gt;(5,6): note: or 'void pet(cat)'
void pet(cat);
     ^
&lt;source&gt;(16,5): note: 'void pet(cat)': cannot convert argument 1 from 'int' to 'cat'
    pet(0); //oh no
    ^
&lt;source&gt;(16,9): note: No constructor could take the source type, or constructor overload resolution was ambiguous
    pet(0); //oh no
        ^
&lt;source&gt;(13,6): note: or 'void pet(T)'
void pet(T);
     ^
&lt;source&gt;(16,5): note: the associated constraints are not satisfied
    pet(0); //oh no
    ^
&lt;source&gt;(12,11): note: the concept 'has_member_pettable&lt;int&gt;' evaluated to false
template &lt;has_member_pettable T&gt;
          ^
&lt;source&gt;(9,48): note: the expression is invalid
concept has_member_pettable = requires (T t) { t.pet(); };
                                               ^
&lt;source&gt;(16,5): note: while trying to match the argument list '(int)'
    pet(0); //oh no
    ^</pre>
<p>Here is a <a href="https://godbolt.org/z/a85z9d5qd">Compiler Explorer link</a> to see the difference.</p>
<p>As part of this work, we’ve also added experimental support for outputting compiler diagnostics as <a href="https://sarifweb.azurewebsites.net/">SARIF</a>. This is accessible with the experimental flag /experimental:log&lt;directory&gt;.</p>
<p>In addition to improved diagnostics, we’ve expanded the compiler’s Named Return Value Optimization (NRVO) capabilities. See Bran Hagger’s blog post <a href="https://devblogs.microsoft.com/cppblog/improving-copy-and-move-elision/">Improving Copy and Move Elision</a> for details. The main improvements are in enabling NRVO for cases which involve exception handling or loops. For example, in 17.3, the copy/move of result when returning it would not be elided, but now will be.</p>
<pre class="prettyprint language-cpp"><code class="language-cpp">Foo ReturnInALoop(int iterations) {
    for (int i = 0; i &lt; iterations; ++i) {
        Foo result;
        if (i == (iterations / 2)) {
            return result; //copy/move elided
        }
    }
}</code></pre>
<p>You can see the difference in generated assembly at <a href="https://godbolt.org/z/jrP4jcz3G">this Compiler Explorer link</a>.</p>
<h1 id="cmake-cross-platform">CMake &amp; Cross Platform</h1>
<p>Containers are a great way to package up everything for running an application. Through a Dockerfile, all prerequisites are captured so that there is a consistent runtime environment anywhere the container is deployed and run. Dev Containers expand this concept to capture everything necessary for developing and building an application in the container. You can now use Dev Containers for your C++ projects in Visual Studio. You can learn more about this feature in our <a href="https://devblogs.microsoft.com/cppblog/dev-containers-for-c-in-visual-studio/" target="_blank" rel="noopener">Dev Containers for C++ blog post</a>.</p>
<p><img decoding="async" class="alignnone wp-image-31268" src="https://devblogs.microsoft.com/cppblog/wp-content/uploads/sites/9/2022/11/word-image-31267-1.png" alt="Alert box saying &quot;Folder contains a dev container configuration file&quot; Options are &quot;Reopen folder in container&quot;, &quot;Settings&quot;, and &quot;Learn more&quot;" width="744" height="40" srcset="https://devblogs.microsoft.com/cppblog/wp-content/uploads/sites/9/2022/11/word-image-31267-1.png 744w, https://devblogs.microsoft.com/cppblog/wp-content/uploads/sites/9/2022/11/word-image-31267-1-300x16.png 300w" sizes="(max-width: 744px) 100vw, 744px" /></p>
<p>Connecting to remote systems with the <a href="https://learn.microsoft.com/en-us/cpp/linux/connect-to-your-remote-linux-computer?view=msvc-170" target="_blank" rel="noopener">Connection Manager</a> now supports SSH ProxyJump, which is used to access a SSH host via another SSH host (for example, to access a host behind a firewall).</p>
<p>Test Explorer used to expose internal prefixes of CTest tests, making the list harder to read and navigate. We’ve improved this, grouping all of them under a single header. Here is the before and after:</p>
<p><img decoding="async" class="alignnone wp-image-31269" src="https://devblogs.microsoft.com/cppblog/wp-content/uploads/sites/9/2022/11/word-image-31267-2.png" alt="List from test explorer showing the weird prefixes " width="251" height="201" /> <img decoding="async" class="alignnone wp-image-31270" src="https://devblogs.microsoft.com/cppblog/wp-content/uploads/sites/9/2022/11/word-image-31267-3.png" alt="Cleaner list under a ctest header" width="170" height="124" /></p>
<h2 id="bundled-tools">Bundled tools</h2>
<p>We made several updates to the additional tools which are shipped with Visual Studio in some workloads.</p>
<p>If you’re using Visual Studio on Arm64 machines, you will now get Arm64 builds of CMake and Ninja through the CMake components in the Visual Studio installer.</p>
<p>We’ve updated the version of CMake which we ship to version 3.24.1. This release comes with many new features, including a &#8211;fresh CLI flag for removing the CMake cache, path comparison in if expressions, and version 5 of CMakePresets.json. We’ll be adding support for CMakePresets.json version 5 in our 17.5 release of Visual Studio 2022, but 17.4 comes with added support for version 4. See the <a href="https://cmake.org/cmake/help/latest/release/3.24.html">CMake release notes</a> for all the new goodies.</p>
<p>We also updated the version of LLVM which we ship to version 15.0.1. See the <a href="https://releases.llvm.org/15.0.0/docs/ReleaseNotes.html" target="_blank" rel="noopener">LLVM</a> and <a href="https://releases.llvm.org/15.0.0/tools/clang/docs/ReleaseNotes.html" target="_blank" rel="noopener">Clang</a> release notes for what is available.</p>
<h1 id="productivity">Productivity</h1>
<p>When using the “Create Declaration/Definition” feature, it used to be that the new code would open up in a small window to give you a “peek”. This is now configurable: you can select between peeking (the default), or opening the document,, or no navigation. The setting is under Options &gt; Text Editor &gt; C/C++ &gt; Advanced &gt; Refactoring.</p>
<p><img decoding="async" class="alignnone wp-image-31271" src="https://devblogs.microsoft.com/cppblog/wp-content/uploads/sites/9/2022/11/word-image-31267-4.png" alt="Options pane showing &quot;None&quot;, &quot;Peek document&quot;, and &quot;Open document&quot; as the options for the setting &quot;Navigation after create declaration/definition&quot;" width="749" height="161" srcset="https://devblogs.microsoft.com/cppblog/wp-content/uploads/sites/9/2022/11/word-image-31267-4.png 749w, https://devblogs.microsoft.com/cppblog/wp-content/uploads/sites/9/2022/11/word-image-31267-4-300x64.png 300w" sizes="(max-width: 749px) 100vw, 749px" /></p>
<p>We fixed a consistency gap between IntelliSense and MSBuild for pre-compiled headers. It used to be that, when a PCH was used via /Yu and force-included via /FI, IntelliSense would always process it first, before any other headers included via /FI. This did not match the build behavior, so with this change /FI headers are processed in the order they are specified.</p>
<h1 id="ide-performance">IDE Performance</h1>
<p>We are also continuing to improve the performance of the IDE. In this release, we improved indexing performance when opening a new solution. Large projects could see a 20-35% improvement from 17.3. Read more in Victor Ciura&#8217;s blog post, <a href="https://devblogs.microsoft.com/cppblog/faster-cpp-source-code-indexing/">Visual Studio 2022 Performance: Faster C++ Source Code Indexing</a>.</p>
<h1 id="code-safety">Code Safety</h1>
<p>We enrich some of our code analysis warnings with “key events” information which describes how the result of the analysis was arrived at. We improved and expanded this feature by adding this information to more analyses and giving you new ways to visualize it in Visual Studio.</p>
<p>For example, when the <a href="https://marketplace.visualstudio.com/items?itemName=WDGIS.MicrosoftSarifViewer">SARIF Viewer extension</a> is installed, the key event information will now be used to annotate the source directly.</p>
<p><img decoding="async" class="alignnone wp-image-31272" src="https://devblogs.microsoft.com/cppblog/wp-content/uploads/sites/9/2022/11/word-image-31267-5.png" alt="Code annotated with reasoning behind an initialization code analysis warning" width="920" height="199" srcset="https://devblogs.microsoft.com/cppblog/wp-content/uploads/sites/9/2022/11/word-image-31267-5.png 920w, https://devblogs.microsoft.com/cppblog/wp-content/uploads/sites/9/2022/11/word-image-31267-5-300x65.png 300w, https://devblogs.microsoft.com/cppblog/wp-content/uploads/sites/9/2022/11/word-image-31267-5-768x166.png 768w" sizes="(max-width: 920px) 100vw, 920px" /></p>
<p>See the <a href="https://devblogs.microsoft.com/cppblog/microsoft-cpp-code-analysis-warnings-with-key-events/">Microsoft C++ Code Analysis Warnings with Key Events </a>blog post for all the details.</p>
<h1 id="conformance">Conformance</h1>
<p>We’re continuing to track the latest developments in C++ standardization. You can see the latest and upcoming STL features in our <a href="https://github.com/microsoft/STL/wiki/Changelog">Changelog on GitHub</a>, but here are some of the ones I’m most excited about:</p>
<ul>
<li><a href="https://www.open-std.org/jtc1/sc22/wg21/docs/papers/2020/p0881r7.html" target="_blank" rel="noopener">P0881R7</a>  &lt;stacktrace&gt;</li>
<li><a href="https://www.open-std.org/jtc1/sc22/wg21/docs/papers/2021/p1328r1.html" target="_blank" rel="noopener">P1328R1</a>  constexpr type_info::operator==()</li>
<li><a href="https://www.open-std.org/jtc1/sc22/wg21/docs/papers/2021/p2440r1.html" target="_blank" rel="noopener">P2440R1</a>  ranges::iota, ranges::shift_left, ranges::shift_right</li>
<li><a href="https://www.open-std.org/jtc1/sc22/wg21/docs/papers/2022/p2441r2.html" target="_blank" rel="noopener">P2441R2</a>  views::join_with</li>
<li><a href="https://www.open-std.org/jtc1/sc22/wg21/docs/papers/2022/p2302r4.html">P2302R4</a>  ranges::contains, ranges::contains_subrange</li>
<li style="list-style-type: none;"></li>
</ul>
<p>Conformance work also extends to IntelliSense, which now has support for C23 attributes, and we are continuing to improve the support for C++20 modules.</p>
<h1 id="vcpkg">vcpkg</h1>
<p>vcpkg is now 6 years old and has over 2000 open-source libraries available!</p>
<p>We’re continuing to add new features both to vcpkg itself, and to Visual Studio to improve integration. For example, vcpkg artifacts is a feature which allows you to describe the tools and environment necessary to build your application. We have now added support to Visual Studio for vcpkg artifacts with CMake projects, such that if your project includes a vcpkg manifest, the environment will be activated automatically on project open. You can learn more about this in the <a href="https://devblogs.microsoft.com/cppblog/vcpkg-environment-activation-in-visual-studio/">vcpkg environment activation in Visual Studio blog post</a>.</p>
<p><img decoding="async" class="alignnone wp-image-31273" src="https://devblogs.microsoft.com/cppblog/wp-content/uploads/sites/9/2022/11/text-description-automatically-generated.png" alt="Popup saying &quot;vcpkg environment activation. vcpkg activated successfully. C/C++ development actions will now run in the vcpkg environment.&quot;" width="383" height="202" srcset="https://devblogs.microsoft.com/cppblog/wp-content/uploads/sites/9/2022/11/text-description-automatically-generated.png 383w, https://devblogs.microsoft.com/cppblog/wp-content/uploads/sites/9/2022/11/text-description-automatically-generated-300x158.png 300w" sizes="(max-width: 383px) 100vw, 383px" /></p>
<p>Other notable improvements since the last release are making the “name” and “version” fields in vcpkg.json optional, adding schemata for all vcpkg json formats, and improving cross-compilation for macOS. You can read more details about these and more in our monthly blog posts from <a href="https://devblogs.microsoft.com/cppblog/vcpkg-august-2022-release-is-now-available-cmake-version-update-updated-faq-cross-compilation-fix-for-apple-silicon/">August</a> and <a href="https://devblogs.microsoft.com/cppblog/vcpkg-september-2022-release-is-now-available-celebrating-6-years-with-over-2000-libraries/">September</a>.</p>
<h1 id="game-development">Game Development</h1>
<p>We’re working hard on the Unreal Engine integration into Visual Studio. As of 17.4, you can now see which Unreal Engine Blueprints reference, use, and inherit from C++ classes, directly in the IDE. To enable this feature, ensure that the “IDE support for Unreal Engine” component is enabled in the VS Installer, and download <a href="https://www.unrealengine.com/marketplace/en-US/product/362651520df94e4fa65492dbcba44ae2">the Visual Studio Integration Tool</a> from the Unreal Marketplace.</p>
<p><img decoding="async" class="alignnone wp-image-31274" src="https://devblogs.microsoft.com/cppblog/wp-content/uploads/sites/9/2022/11/word-image-31267-7.png" alt="Popup showing the references to a given blueprint" width="837" height="271" srcset="https://devblogs.microsoft.com/cppblog/wp-content/uploads/sites/9/2022/11/word-image-31267-7.png 837w, https://devblogs.microsoft.com/cppblog/wp-content/uploads/sites/9/2022/11/word-image-31267-7-300x97.png 300w, https://devblogs.microsoft.com/cppblog/wp-content/uploads/sites/9/2022/11/word-image-31267-7-768x249.png 768w" sizes="(max-width: 837px) 100vw, 837px" /></p>
<p>Keep an eye out for more new features in 17.5, and please let us know what you think of the Blueprints integration!</p>
<h1 id="send-us-your-feedback">Send us your feedback</h1>
<p>We are very much interested in your feedback to continue to improve this experience. The comments below are open. Feedback can also be shared through the <a href="https://developercommunity.visualstudio.com/cpp">Developer Community</a>. You can also reach us on Twitter (<a href="https://twitter.com/visualc">@VisualC</a>), or via email at <a href="mailto:visualcpp@microsoft.com">visualcpp@microsoft.com</a>.</p>
<p>The post <a rel="nofollow" href="https://devblogs.microsoft.com/cppblog/whats-new-for-cpp-developers-in-visual-studio-2022-17-4/">What’s New for C++ Developers in Visual Studio 2022 17.4</a> appeared first on <a rel="nofollow" href="https://devblogs.microsoft.com/cppblog">C++ Team Blog</a>.</p>
]]></content:encoded>
					
					<wfw:commentRss>https://devblogs.microsoft.com/cppblog/whats-new-for-cpp-developers-in-visual-studio-2022-17-4/feed/</wfw:commentRss>
			<slash:comments>0</slash:comments>
		
		
			</item>
		<item>
		<title>Fix for High Risk OpenSSL Security Vulnerabilities Announced – Guidance for vcpkg Users</title>
		<link>https://devblogs.microsoft.com/cppblog/fix-for-high-risk-openssl-security-vulnerabilities-announced-guidance-for-vcpkg-users/</link>
					<comments>https://devblogs.microsoft.com/cppblog/fix-for-high-risk-openssl-security-vulnerabilities-announced-guidance-for-vcpkg-users/#respond</comments>
		
		<dc:creator><![CDATA[Augustin Popa]]></dc:creator>
		<pubDate>Wed, 02 Nov 2022 23:27:22 +0000</pubDate>
				<category><![CDATA[C++]]></category>
		<guid isPermaLink="false">https://devblogs.microsoft.com/cppblog/?p=31246</guid>

					<description><![CDATA[<p>OpenSSL.org announced the release of OpenSSL 3.0.7 to address two security vulnerabilities rated as high risk. This patch is now available, including via vcpkg. The vulnerabilities impact users of OpenSSL 3.0.0 &#8211; 3.0.6. If you are relying on a version of OpenSSL in this range,</p>
<p>The post <a rel="nofollow" href="https://devblogs.microsoft.com/cppblog/fix-for-high-risk-openssl-security-vulnerabilities-announced-guidance-for-vcpkg-users/">Fix for High Risk OpenSSL Security Vulnerabilities Announced – Guidance for vcpkg Users</a> appeared first on <a rel="nofollow" href="https://devblogs.microsoft.com/cppblog">C++ Team Blog</a>.</p>
]]></description>
										<content:encoded><![CDATA[<p><a href="https://www.openssl.org/blog/blog/2022/11/01/email-address-overflows/">OpenSSL.org announced the release of OpenSSL 3.0.7</a> to address two security vulnerabilities rated as high risk. This patch is now available, including via vcpkg. The vulnerabilities impact users of OpenSSL 3.0.0 &#8211; 3.0.6. If you are relying on a version of OpenSSL in this range, it is <strong>strongly recommended</strong> to upgrade to 3.0.7 as soon as possible. We also recommend reviewing Microsoft Security Response Center&#8217;s central blog post on awareness and guidance related to these two CVEs: <a href="https://msrc-blog.microsoft.com/2022/11/02/microsoft-guidance-related-to-openssl-risk-cve-2022-3786-and-cve-2202-3602/">Awareness and guidance related to OpenSSL 3.0 – 3.0.6 risk (CVE-2022-3786 and CVE-2202-3602) – Microsoft Security Response Center</a>.</p>
<p>If you are a vcpkg user or port author depending on the OpenSSL vcpkg port, below are instructions on how to upgrade to the new version.</p>
<p>&nbsp;</p>
<h3 id="vcpkg-users-check-if-you-are-using-a-vulnerable-version-of-openssl">vcpkg users: check if you are using a vulnerable version of OpenSSL</h3>
<p><strong>WARNING: </strong>It is possible that OpenSSL is a part of your dependency graph even if your project does not directly depend on it. This is because other vcpkg ports may transitively depend on OpenSSL and thus vcpkg will install it for you. For example, users of the <a href="https://azure.github.io/azure-sdk-for-cpp/index.html">Azure C++ SDK</a> port transitively depend on OpenSSL and should verify the version of OpenSSL installed on their system.</p>
<p>There are several methods that can help you identify the version of OpenSSL installed by vcpkg (if it exists), depending on your scenario:</p>
<ol>
<li>If you install your libraries via the command line, use <code>vcpkg list openssl</code>​ to list all installed versions of OpenSSL.</li>
<li>If you use a <em>vcpkg.json</em> manifest that installs dependencies during your build, use <code>vcpkg install --dry-run</code>​ to list the versions of every library that will be installed.</li>
<li>Finally, you can also directly verify the installed version of OpenSSL from an installed tree by looking at the version macros in the header &#8220;<em>openssl/opensslv.h</em>&#8220;.
<ul>
<li>These are the macros, denoting the major, minor, and patch versions (3.0.5 in this case):</li>
<li><code># define OPENSSL_VERSION_MAJOR 3</code></li>
<li><code># define OPENSSL_VERSION_MINOR 0</code></li>
<li><code># define OPENSSL_VERSION_PATCH 5</code></li>
</ul>
</li>
</ol>
<p>If you find that you are using a vulnerable version of OpenSSL, read on to find out how to upgrade.</p>
<p>&nbsp;</p>
<h3 id="classic-mode-command-line-users">Classic Mode (Command Line) Users</h3>
<p>If you are consuming vcpkg dependencies and don’t use a <em>vcpkg.json</em> manifest, you are using classic mode, which involves running commands of the nature <code>vcpkg install &lt;library_name&gt;</code>. To get the latest version of OpenSSL, you have several options. Pick the one that works best for you:</p>
<p>&nbsp;</p>
<h4 id="classic-mode-option-1-upgrade-all-dependencies-at-once">Classic Mode Option 1: Upgrade all dependencies at once</h4>
<p>If you are using classic mode and are okay with updating all your vcpkg dependencies at once, the fastest solution is to update your local copy of the vcpkg git repo to a newer version. Just open a terminal to your copy of vcpkg and run the following commands:</p>
<pre class="prettyprint">git fetch https://github.com/microsoft/vcpkg 09adfdc8cdad76345b7cc7f3305899e1cbd66297
git checkout 09adfdc8cdad76345b7cc7f3305899e1cbd66297
vcpkg upgrade
vcpkg upgrade --no-dry-run</pre>
<p><strong>Notes: </strong></p>
<ul>
<li><code>09adfdc8cdad76345b7cc7f3305899e1cbd66297</code> is a vcpkg commit ID containing the patched version of OpenSSL. You can also use a newer commit ID than this.</li>
<li>After running the git checkout line with that commit ID, you should see <code>HEAD</code> is now at <code>09adfdc8c [OpenSSL] Update to 3.0.7. (#27594)</code></li>
<li>After running <code>vcpkg upgrade</code>, you should see that OpenSSL will be updated to 3.0.7, along with other affected dependencies.</li>
<li>The last line with <code>--no-dry-run</code> will update your dependencies for real.</li>
<li>If you are not bothered about which commit to update to, you can just run a general git pull to get the very latest version of vcpkg and skip having to provide a commit ID altogether. You will still need to run <code>vcpkg upgrade</code> after.</li>
</ul>
<p>&nbsp;</p>
<h4 id="classic-mode-option-2-update-your-local-openssl-port-files-to-the-new-version">Classic Mode Option 2: Update your local OpenSSL port files to the new version</h4>
<p>If you want to update just OpenSSL and nothing else, open a terminal to your copy of vcpkg and run the following commands:</p>
<pre class="prettyprint">git fetch https://github.com/microsoft/vcpkg 09adfdc8cdad76345b7cc7f3305899e1cbd66297
git checkout 09adfdc8cdad76345b7cc7f3305899e1cbd66297 -- ports/openssl
vcpkg upgrade
vcpkg upgrade --no-dry-run</pre>
<p><strong>Notes: </strong></p>
<ul>
<li><code>09adfdc8cdad76345b7cc7f3305899e1cbd66297</code> is a vcpkg commit ID containing the patched version of OpenSSL. You can also use a newer commit ID than this.</li>
<li>In contrast to the previous example, this approach lets you update just the OpenSSL portion of the vcpkg repo while leaving everything else alone.</li>
<li>After running <code>vcpkg upgrade</code>, you should see that OpenSSL will be updated to 3.0.7, along with other affected dependencies.</li>
<li>The last line with <code>--no-dry-run</code> will update your dependencies for real.</li>
</ul>
<p>This approach will only update the OpenSSL port, but keep in mind that future general git fetches on the repo will apply a new commit ID globally, so you’ll need to make sure you don’t accidentally pull a version of OpenSSL within the 3.0.0 &#8211; 3.0.6 range.</p>
<p>&nbsp;</p>
<h3 id="manifest-mode-users">Manifest Mode Users</h3>
<p>If you are consuming vcpkg dependencies via a manifest file (recommended for any advanced users and professional projects), you just need to update your <em>vcpkg.json</em> file to set a different OpenSSL version.</p>
<p>&nbsp;</p>
<h4 id="manifest-mode-option-1-upgrade-all-dependencies-at-once">Manifest Mode Option 1: Upgrade all dependencies at once</h4>
<p>In general, we recommend updating all open-source dependencies at once rather than one at a time since that allows you to benefit from vcpkg’s version conflict resolution to avoid things like diamond dependencies in your dependency graph.</p>
<p>If this works for you, open a terminal to your vcpkg install location and run the following command:</p>
<p><code>git pull origin 09adfdc8cdad76345b7cc7f3305899e1cbd66297</code></p>
<p>Then (still in your terminal), navigate to your project containing the vcpkg.json, and run:</p>
<p><code>vcpkg x-update-baseline</code></p>
<p>You can git pull to a newer commit ID if you prefer (or just not specify a commit ID and get the latest), but the commit ID in the example above is the earlier one with the patch applied.</p>
<p>The <a href="https://vcpkg.io/en/docs/commands/update-baseline.html">x-update-baseline</a> command moves your registry baseline forward to the baseline set for the vcpkg repo. This is why you must run git pull on the main repo to sync it to the baseline you need.</p>
<p>You can alternatively go into your <em>vcpkg.json</em> and <em>vcpkg-configuration.json</em> files to set baselines manually if you’re having trouble running <code>x-update-baseline</code>:</p>
<h5 id="example-with-baseline-field">Example with baseline field</h5>
<pre class="prettyprint"><strong>vcpkg.json:
</strong>{
    "name": "example",
    "version": "1.0.0",
    "dependencies": [
        "curl"
    ]
}

<strong>vcpkg-configuration.json:
</strong>{
    "default-registry": {
        "kind": "git",
        "baseline": "09adfdc8cdad76345b7cc7f3305899e1cbd66297",
        "repository": "https://github.com/microsoft/vcpkg"
    }
}</pre>
<p>The baseline field is used when the registry location is defined in a separate <em>vcpkg-configuration.json</em> file. This is common for custom registries, though you can configure the public registry this way as well. If you just want to use the default registry and don’t have it separately configured in <em>vcpkg-configuration.json</em>, follow the next example instead using the builtin-baseline field.</p>
<h5 id="example-with-builtin-baseline-field">Example with builtin-baseline field</h5>
<pre class="prettyprint"><strong>vcpkg.json:
</strong>{
    "name": "example",
    "version": "1.0.0",
    "builtin-baseline": "09adfdc8cdad76345b7cc7f3305899e1cbd66297",
    "dependencies": [
        "curl"
    ]
}</pre>
<p>See the <a href="https://vcpkg.io/en/docs/users/versioning.html&quot; \l &quot;baselines">vcpkg versioning documentation</a> for details on how baselines work.</p>
<p>&nbsp;</p>
<h4 id="manifest-mode-option-2-upgrade-openssl-using-an-override">Manifest Mode Option 2: Upgrade OpenSSL using an override</h4>
<p>If you need fine-grained control over the versions of your libraries, you can</p>
<p>set the version of OpenSSL to stay at exactly 3.0.7 using the overrides field. The limitations of this approach are that you won’t get the automatic version conflict resolution (as you would with baselines) and must manually track the package version. In addition, if your project that consumes OpenSSL will itself be packaged as a vcpkg port, your downstream consumers will <strong>not</strong> automatically get the version of OpenSSL you specify. Your downstream consumers must also update their version of OpenSSL.</p>
<h5 id="registries-example-with-overrides">Registries example with overrides</h5>
<pre class="prettyprint"><strong>vcpkg.json:
</strong>{
    "name": "example",
    "version": "1.0.0",
    "dependencies": [
        "curl"
    ],
    "overrides": [
    {
        "name": "openssl",
        "version": "3.0.7"
    }]
}
<strong>vcpkg-configuration.json:
</strong>{
    "default-registry": {
        "kind": "git",
        "baseline": "fcfda3c78c474aec7187299b684258855259a7a6",
        "repository": "https://github.com/microsoft/vcpkg"
    }
}</pre>
<p>Please see our <a href="https://vcpkg.io/en/docs/users/versioning.html">versioning documentation</a> if you need a refresher on these vcpkg features.</p>
<p>&nbsp;</p>
<h3 id="questions">Questions?</h3>
<p>We will monitor this blog post for comments in case there are any questions. Please also feel free to email us at <a href="mailto:vcpkg@microsoft.com">vcpkg@microsoft.com</a> if you need additional guidance.</p>
<p>&nbsp;</p>
<p>The post <a rel="nofollow" href="https://devblogs.microsoft.com/cppblog/fix-for-high-risk-openssl-security-vulnerabilities-announced-guidance-for-vcpkg-users/">Fix for High Risk OpenSSL Security Vulnerabilities Announced – Guidance for vcpkg Users</a> appeared first on <a rel="nofollow" href="https://devblogs.microsoft.com/cppblog">C++ Team Blog</a>.</p>
]]></content:encoded>
					
					<wfw:commentRss>https://devblogs.microsoft.com/cppblog/fix-for-high-risk-openssl-security-vulnerabilities-announced-guidance-for-vcpkg-users/feed/</wfw:commentRss>
			<slash:comments>0</slash:comments>
		
		
			</item>
	</channel>
</rss>
