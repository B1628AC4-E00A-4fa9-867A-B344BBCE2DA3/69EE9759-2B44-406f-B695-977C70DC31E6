<?xml version="1.0" encoding="UTF-8"?><rss version="2.0"
	xmlns:content="http://purl.org/rss/1.0/modules/content/"
	xmlns:wfw="http://wellformedweb.org/CommentAPI/"
	xmlns:dc="http://purl.org/dc/elements/1.1/"
	xmlns:atom="http://www.w3.org/2005/Atom"
	xmlns:sy="http://purl.org/rss/1.0/modules/syndication/"
	xmlns:slash="http://purl.org/rss/1.0/modules/slash/"
	>

<channel>
	<title>Windows Developer Blog</title>
	<atom:link href="https://blogs.windows.com/windowsdeveloper/feed/" rel="self" type="application/rss+xml" />
	<link>https://blogs.windows.com/windowsdeveloper/</link>
	<description></description>
	<lastBuildDate>Fri, 24 May 2024 16:00:14 +0000</lastBuildDate>
	<language>en-US</language>
	<sy:updatePeriod>
	hourly	</sy:updatePeriod>
	<sy:updateFrequency>
	1	</sy:updateFrequency>
	<generator>https://wordpress.org/?v=6.4.4</generator>

<image>
	<url>https://blogs.windows.com/wp-content/uploads/prod/sites/3/2021/06/cropped-browser-icon-logo-32x32.jpg</url>
	<title>Windows Developer Blog</title>
	<link>https://blogs.windows.com/windowsdeveloper/</link>
	<width>32</width>
	<height>32</height>
</image> 
	<item>
		<title>Build the next wave of AI on Windows with DirectML support for PyTorch 2.2</title>
		<link>https://blogs.windows.com/windowsdeveloper/2024/05/24/build-the-next-wave-of-ai-on-windows-with-directml-support-for-pytorch-2-2/</link>
		
		<dc:creator><![CDATA[Sheil Kumar]]></dc:creator>
		<pubDate>Fri, 24 May 2024 16:00:14 +0000</pubDate>
				<category><![CDATA[Uncategorized]]></category>
		<guid isPermaLink="false">https://blogs.windows.com/windowsdeveloper/?p=56997</guid>

					<description><![CDATA[<p>Today, Windows developers can leverage PyTorch to run inference on the latest models across the breadth of GPUs in the Windows ecosystem, thanks to DirectML. We’ve updated  <a href="https://pypi.org/project/torch-directml/">Torch-DirectML</a> to u</p>
<p>The post <a href="https://blogs.windows.com/windowsdeveloper/2024/05/24/build-the-next-wave-of-ai-on-windows-with-directml-support-for-pytorch-2-2/">Build the next wave of AI on Windows with DirectML support for PyTorch 2.2</a> appeared first on <a href="https://blogs.windows.com/windowsdeveloper">Windows Developer Blog</a>.</p>
]]></description>
										<content:encoded><![CDATA[Today, Windows developers can leverage PyTorch to run inference on the latest models across the breadth of GPUs in the Windows ecosystem, thanks to DirectML. We’ve updated  <a href="https://pypi.org/project/torch-directml/">Torch-DirectML</a> to use DirectML 1.13 for acceleration and support PyTorch 2.2. PyTorch with DirectML simplifies the setup process, through a one-package install, making it easy to try out AI powered experiences and supporting your ability to scale AI to your customers across Windows.

To see these updates in action, check out our Build session <a href="https://build.microsoft.com/en-US/sessions/65c11f47-56d8-442b-ae52-48df62b7b542?source=sessions">Bring AI experiences to all your Windows Devices</a>.

See here to learn how our hardware vendor partners are making this experience great:
<ul>
 	<li><strong>AMD:</strong> AMD is glad PyTorch with DirectML is enabling even more developers to run LLMs locally. <a href="https://community.amd.com/t5/ai/reduce-memory-footprint-and-improve-performance-running-llms-on/ba-p/686157">Learn more</a> about where else AMD is investing with DirectML.</li>
 	<li><strong>Intel:</strong> Intel is excited to support Microsoft’s PyTorch with DirectML goals – see our <a href="https://community.intel.com/t5/Blogs/Tech-Innovation/Artificial-Intelligence-AI/Accelerating-PyTorch-on-Intel-with-DirectML-support/post/1597989">blog</a> to learn more about the full support that’s available today.</li>
 	<li><strong>NVIDIA:</strong> NVIDIA looks forward to developers using the torch-directml package accelerated by RTX GPUs. Check out all the NVIDIA related Microsoft Build announcements around <a href="https://blogs.nvidia.com/blog/rtx-advanced-ai-windows-pc-build/">RTX AI PCs</a> and their <a href="https://blogs.nvidia.com/blog/microsoft-build-optimized-ai-developers/">expanded collaboration</a> with Microsoft.</li>
</ul>
<h2>PyTorch with DirectML is easy-to-use with the latest Generative AI models</h2>
PyTorch with DirectML provides an easy-to-use way for developers to try out the latest and greatest AI models on their Windows machine. This update builds on DirectML’s world class inferencing platform ensuring these optimizations provide a scalable and performant experience across the latest Generative AI models. Our aim in this update is to ensure a seamless experience with relevant Gen AI models, such as Llama 2, Llama 3, Mistral, Phi 2, and Phi 3 Mini, and we’ll expand our coverage even more in the coming months!

The best part is using the latest Torch-DirectML package with your Windows GPU is as simple as running:
<pre>pip install torch-directml</pre>
Once installed, check out our <a href="https://github.com/microsoft/DirectML/tree/master/PyTorch/llm">language model sample</a> that will get you running a language model locally in no time! Start by installing a few requirements and logging into the Hugging Face CLI:
<pre>pip install –r requirements.txt 
huggingface-cli login</pre>
Next, run the following command, which downloads the specified Hugging Face model, optimizes it for DirectML, and runs the model in an interactive chat-based Gradio session!
<pre>python app.py --model_repo “microsoft/Phi-3-mini-4k-instruct”</pre>
<img class="alignnone wp-image-56987 size-full" src="https://blogs.windows.com/wp-content/uploads/prod/sites/3/2024/05/pyt_phi3_emailprompt_notitle_noloop.gif" alt="" width="904" height="655" />

<em>Phi 3 Mini 4K running locally using DirectML through the Gradio Chatbot interface.</em>

These latest PyTorch with DirectML samples work across a range of machines and perform best on recent GPUs equipped with the newest drivers. Check out the <a href="https://github.com/microsoft/DirectML/tree/master/PyTorch/llm#supported-models">Supported Models</a> section of the sample for more info on the GPU memory requirements for each model.

This seamless inferencing experience is powered by our close co-engineering relationships with our hardware partners to make sure you get the most of your Windows GPU when leveraging DirectML.
<h2>Try out PyTorch with DirectML today</h2>
Trying out this update is truly as simple as running <em>“pip install torch-directml”</em> in your existing Python environment and following the instructions in one of <a href="https://github.com/microsoft/DirectML/tree/master/PyTorch#samples">our samples</a>. For more guidance on getting setup visit the <a href="https://learn.microsoft.com/en-us/windows/ai/directml/pytorch-windows">Enable PyTorch with DirectML on Windows</a> page on Microsoft Learn.

This is only the beginning of the next chapter with DirectML and PyTorch! Stay tuned for broader use case coverage, expansion to other local accelerators, like NPUs, and more. Our goal is to meet developers where they’re at, so they can use the right tools to build the next wave of AI innovation.

We’re excited for developers to continue innovating with cutting edge Generative AI on Windows and build the AI apps of the future!]]></content:encoded>
					
		
		
			</item>
		<item>
		<title>Quantization with DirectML helps you scale further on Windows</title>
		<link>https://blogs.windows.com/windowsdeveloper/2024/05/24/quantization-with-directml-helps-you-scale-further-on-windows/</link>
		
		<dc:creator><![CDATA[Patrice Vignola]]></dc:creator>
		<pubDate>Fri, 24 May 2024 16:00:09 +0000</pubDate>
				<category><![CDATA[Uncategorized]]></category>
		<guid isPermaLink="false">https://blogs.windows.com/windowsdeveloper/?p=56998</guid>

					<description><![CDATA[<p>DirectML support for Phi 3 mini launched last month and we’ve since made several improvements, unlocking more models and even better performance!</p>
<p>Developers can grab already quantized versions of Phi-3 mini (with variants for the <a href="https://
</p>
<p>The post <a href="https://blogs.windows.com/windowsdeveloper/2024/05/24/quantization-with-directml-helps-you-scale-further-on-windows/">Quantization with DirectML helps you scale further on Windows</a> appeared first on <a href="https://blogs.windows.com/windowsdeveloper">Windows Developer Blog</a>.</p>
]]></description>
										<content:encoded><![CDATA[DirectML support for Phi 3 mini launched last month and we’ve since made several improvements, unlocking more models and even better performance!

Developers can grab already quantized versions of Phi-3 mini (with variants for the <a href="https://huggingface.co/microsoft/Phi-3-mini-4k-instruct-onnx">4k</a> and <a href="https://huggingface.co/microsoft/Phi-3-mini-128k-instruct-onnx">128k</a> versions). They can now also get Phi 3 medium (<a href="https://huggingface.co/microsoft/Phi-3-medium-4k-instruct-onnx-directml">4k</a> and <a href="https://huggingface.co/microsoft/Phi-3-medium-128k-instruct-onnx-directml">128k</a>)  and <a href="https://huggingface.co/microsoft/mistral-7b-instruct-v0.2-ONNX">Mistral v0.2</a>. Stay tuned for additional pre-quantized models! We’ve also shipped a gradio interface to make easier to test these models with the new ONNX Runtime Generate() API. <a href="https://github.com/microsoft/onnxruntime-genai/tree/main/examples/chat_app">Learn more</a>.

Be sure to check out our Build sessions to learn more. See below for details.

See here to learn what our hardware vendor partners have to say:
<ul>
 	<li><strong>AMD: </strong><a href="https://community.amd.com/t5/ai/reduce-memory-footprint-and-improve-performance-running-llms-on/ba-p/686157"><strong>https://community.amd.com/t5/ai/reduce-memory-footprint-and-improve-performance-running-llms-on/ba-p/686157</strong></a></li>
 	<li><strong>Intel: </strong><a href="https://community.intel.com/t5/Blogs/Tech-Innovation/Artificial-Intelligence-AI/Accelerating-Language-Models-Intel-and-Microsoft-Collaborate-to/post/1598013"><strong>https://community.intel.com/t5/Blogs/Tech-Innovation/Artificial-Intelligence-AI/Accelerating-Language-Models-Intel-and-Microsoft-Collaborate-to/post/1598013</strong></a></li>
 	<li><strong>NVIDIA: </strong><a href="https://blogs.nvidia.com/blog/microsoft-build-optimized-ai-developers"><strong>https://blogs.nvidia.com/blog/microsoft-build-optimized-ai-developers</strong></a></li>
</ul>
<h2>What is quantization?</h2>
Memory bandwidth is often a bottleneck for getting models to run on entry-level and older hardware, especially when it comes to language models. This means that making language models smaller directly translates to increasing the breadth of devices developers can target.

There’s been a lot of research into reducing model size through quantization, a process that reduces the precision and therefore size of model weights.

Our goal is to ensure scalability, while also maintaining model accuracy, so we integrated support for models that have had <a href="https://arxiv.org/abs/2306.00978">Activation-Aware Quantization</a> (AWQ) applied to them. AWQ is a technique that lets us reap the memory savings from quantization with only a minimal impact on accuracy. AWQ achieves this by identifying the top 1% of salient weights that are needed for maintaining model accuracy and then quantizes the remaining 99% of weights. This leads to much less accuracy loss with AWQ compared to other techniques.

The average person reads up to <a href="https://wordsrated.com/reading-speed-statistics/">5 words/second</a>. Thanks to the significant memory wins from AWQ, Phi-3-mini runs at this speed or faster on older discrete GPUs and even laptop integrated GPUs. This translates into being able to run Phi-3-mini on hundreds of millions of devices!

Check out our Build talk below to see this in action!
<h2>Perplexity measurements</h2>
Perplexity is a measure used to quantify how well a model predicts a sample. Without getting into the math of it all, a lower perplexity score means the model is more certain about its predictions and suggests that the model's probability distribution is closer to the true distribution of the data.

Perplexity can be thought of as a way to quantify the average number of branches in front of a model at each decision point. At each step, a lower perplexity would mean that the model has fewer, more confident choices to make, which reflects a more refined understanding of the topic. A higher perplexity would mean more, less confident choices and therefore choices that are less predictable, relevant, and/or varied in quality.

As you can see below our data shows that AWQ leads to a small loss in model accuracy with only a small increase in perplexity. In return, using AWQ means 4x smaller model weights, leading to a dramatic increase in the number of devices that can run Phi-3-mini!
<table style="margin: 0 auto;" data-tablestyle="MsoNormalTable" data-tablelook="1184">
<tbody>
<tr>
<td width="113">Model variant</td>
<td width="96">Dataset</td>
<td width="162">Base model perplexity</td>
<td width="122">AWQ perplexity</td>
<td width="96"><strong>Difference</strong></td>
</tr>
<tr>
<td width="113">Phi3 mini 128k</td>
<td width="96"><a href="https://paperswithcode.com/dataset/wikitext-2">wikitext2</a></td>
<td width="162">14.42</td>
<td width="122">14.81</td>
<td width="96"><strong>0.39</strong></td>
</tr>
<tr>
<td width="113">Phi3 mini 128k</td>
<td width="96"><a href="https://paperswithcode.com/dataset/penn-treebank">ptb</a></td>
<td width="162">31.39</td>
<td width="122">33.63</td>
<td width="96"><strong>2.24</strong></td>
</tr>
<tr>
<td width="113">Phi3 mini 4k</td>
<td width="96"><a href="https://paperswithcode.com/dataset/wikitext-2">wikitext2</a></td>
<td width="162">15.83</td>
<td width="122">16.52</td>
<td width="96"><strong>0.69</strong></td>
</tr>
<tr>
<td width="113">Phi3 mini 4k</td>
<td width="96"><a href="https://paperswithcode.com/dataset/penn-treebank">ptb</a></td>
<td width="162">31.98</td>
<td width="122">34.3</td>
<td width="96"><strong>2.32</strong></td>
</tr>
</tbody>
</table>
<h2>Learn more</h2>
Be sure check out the these sessions at Build to learn more:
<ul>
 	<li>BRK240: <a href="https://build.microsoft.com/en-US/sessions/65c11f47-56d8-442b-ae52-48df62b7b542?source=sessions">Bring AI experiences to all your Windows Devices</a></li>
 	<li>BRK247: <a href="https://build.microsoft.com/en-US/sessions/e6d21a49-2efb-4a39-8c26-f6eef1410c7a?source=sessions">Create Generative AI experiences using Phi</a></li>
 	<li>LAB371: <a href="https://build.microsoft.com/en-US/sessions/b4ddb175-c775-4bb2-abd9-fbe313391b14?source=sessions">Test Drive AI on Windows with DirectML, ONNX Runtime, and Olive </a></li>
</ul>
<h2>Get Started</h2>
Check out the ONNX Runtime Generate() API repo to get started today: <a href="https://github.com/microsoft/onnxruntime-genai">https://github.com/microsoft/onnxruntime-genai</a>

See here for our chat app with a handy gradio interface: <a href="https://github.com/microsoft/onnxruntime-genai/tree/main/examples/chat_app">https://github.com/microsoft/onnxruntime-genai/tree/main/examples/chat_app</a>

This lets developers choose from different types of language models that work best for their specific use case. Stay tuned for more!
<h2>Drivers</h2>
We recommend upgrading to the latest drivers for the best performance.
<ul>
 	<li><strong>AMD: </strong>improved driver acceleration for generative AI including large language models (<a href="https://www.amd.com/en/resources/support-articles/release-notes/RN-RAD-WIN-23-40-27-06-DIRECTML.html">AMD Software: Adrenalin Edition 23.40.27.06 for DirectML</a>)</li>
 	<li><strong>Intel </strong>is excited to partner with Microsoft and provide a driver optimized for these AWQ scenarios across a wide range of hardware – please download our publicly available WHQL certified driver with full support today, <a href="https://www.intel.com/content/www/us/en/download/785597/intel-arc-iris-xe-graphics-windows.html">available here</a></li>
 	<li><strong>NVIDIA: </strong><a href="https://www.nvidia.com/download/index.aspx">R555 </a><a href="https://www.nvidia.com/download/index.aspx">Game Ready, Studio or NVIDIA RTX Enterprise </a></li>
</ul>]]></content:encoded>
					
		
		
			</item>
		<item>
		<title>Introducing the WebNN Developer Preview with DirectML</title>
		<link>https://blogs.windows.com/windowsdeveloper/2024/05/24/introducing-the-webnn-developer-preview-with-directml/</link>
		
		<dc:creator><![CDATA[Adele Parsons]]></dc:creator>
		<pubDate>Fri, 24 May 2024 16:00:03 +0000</pubDate>
				<category><![CDATA[Uncategorized]]></category>
		<guid isPermaLink="false">https://blogs.windows.com/windowsdeveloper/?p=57000</guid>

					<description><![CDATA[<p>We are excited to announce the availability of the developer preview for WebNN, a web standard for cross-platform and hardware-accelerated neural network inference in the browser, using <a href="https://learn.microsoft.com/en-us/windows/ai/directml/d
</p>
<p>The post <a href="https://blogs.windows.com/windowsdeveloper/2024/05/24/introducing-the-webnn-developer-preview-with-directml/">Introducing the WebNN Developer Preview with DirectML</a> appeared first on <a href="https://blogs.windows.com/windowsdeveloper">Windows Developer Blog</a>.</p>
]]></description>
										<content:encoded><![CDATA[We are excited to announce the availability of the developer preview for WebNN, a web standard for cross-platform and hardware-accelerated neural network inference in the browser, using <a href="https://learn.microsoft.com/en-us/windows/ai/directml/dml">DirectML</a> and <a href="https://onnxruntime.ai/docs/tutorials/web/">ONNX Runtime Web</a>. This preview enables web developers to leverage the power and performance of DirectML across GPUs with support coming soon for Intel’s® Core™ Ultra processors with Intel® AI Boost and the Copilot+ PC, powered by Qualcomm® Hexagon™ NPUs.

<img class="alignnone size-medium wp-image-57016" src="https://blogs.windows.com/wp-content/uploads/prod/sites/3/2024/05/WebNNDiagram-300x294.png" alt="Diagram showing how WebNN fits in the architechture" width="300" height="294" />

WebNN is a game-changer for web development. It’s an emerging web standard that defines how to run machine learning models in the browser, using the hardware acceleration of your local device’s GPU or NPU. This way, you can enjoy web applications that use machine learning without any extra software or plugins, and without compromising your privacy or security. WebNN opens up new possibilities for web applications, such as generative AI, object recognition, natural language processing, and more.

WebNN is a web standard that defines how to interface with different backends for hardware accelerated ML inference. One of the backends that WebNN can use is DirectML, which provides performant, cross-hardware ML acceleration across Windows devices. By leveraging DirectML, WebNN can benefit from the hardware scale, performance, and reliability of DirectML.

With WebNN, you can unleash the power of ML models in your web app. It offers you the core elements of ML, such as tensors, operators, and graphs. You can also combine it with ONNX Runtime Web, a JavaScript library that enables you to run ONNX models in the browser. ONNX Runtime Web includes a WebNN Execution Provider that simplifies your use of WebNN.

To learn more or to see this in action, be sure to check out our various Build sessions. See below for details.

See here to learn what our hardware vendor partners have to say:
<ul>
 	<li><strong>AMD:</strong> AMD is excited about the launch of WebNN with DirectML enabling local execution of generative AI machine learning models on AMD hardware. <a href="https://community.amd.com/t5/ai/reduce-memory-footprint-and-improve-performance-running-llms-on/ba-p/686157">Learn more</a> about where else AMD is investing with DirectML.</li>
 	<li><strong>Intel:</strong> Intel looks forward to the new possibilities WebNN and DirectML bring to web developers – <a href="https://www.intel.com/content/www/us/en/developer/articles/news/announcing-webnn-developer-preview-for-the-ai-pc.html">learn more here</a> about our investments in WebNN. Please <a href="https://www.intel.com/content/www/us/en/download/785597/intel-arc-iris-xe-graphics-windows.html">download the latest driver</a> for best performance.</li>
 	<li><strong>NVIDIA</strong>: NVIDIA is excited to see DirectML powering WebNN to bring even more ways for web apps to leverage hardware acceleration on RTX GPUs. Check out all the NVIDIA related Microsoft Build announcements around <a href="https://blogs.nvidia.com/blog/rtx-advanced-ai-windows-pc-build/">RTX AI PCs</a> and their <a href="https://blogs.nvidia.com/blog/microsoft-build-optimized-ai-developers/">expanded collaboration</a> with Microsoft.</li>
</ul>
<h2>Getting Started with the WebNN Developer Preview</h2>
With the WebNN Developer Preview, powered by DirectML and ONNX Runtime Web, you can run ONNX models in the browser with hardware acceleration and minimal code changes.

To get started with WebNN on DirectX 12 compatible GPUs you will need:
<ul>
 	<li>Window 11, version 21H2 or newer</li>
 	<li>ONNX Runtime Web minimum version 1.18</li>
 	<li><a href="https://www.microsoft.com/en-us/edge/download/insider?form=MA13FJ">Microsoft Edge Canary channel</a>, with the WebNN flag enabled in about:flags</li>
</ul>
For more instructions and information about supported models and operators, please visit our <a href="https://learn.microsoft.com/en-us/windows/ai/directml/webnn-overview">documentation</a>. To try out samples, please visit the <a href="https://microsoft.github.io/webnn-developer-preview/">WebNN Developer Preview</a> page.
<h2>Learn more</h2>
Be sure to check out these sessions at Microsoft’s Build Conference to learn more about WebNN:
<ul>
 	<li>BRK240: <a href="https://build.microsoft.com/en-US/sessions/65c11f47-56d8-442b-ae52-48df62b7b542?source=sessions">Bring AI experiences to all your Windows Devices</a></li>
 	<li>StudioFP126: <a href="https://build.microsoft.com/en-US/sessions/fe8f0c03-6f31-400a-8954-4e37c935e6e9?source=sessions">The Web is AI Ready—maximize your AI web development with WebNN </a></li>
</ul>
<h2>Additional WebNN documentation and samples:</h2>
<ul>
 	<li><a href="https://microsoft.github.io/webnn-developer-preview/">WebNN Developer Preview samples</a></li>
 	<li><a href="https://learn.microsoft.com/en-us/windows/ai/directml/webnn-overview">WebNN Developer Preview documentation</a></li>
 	<li><a href="https://webmachinelearning.github.io/webnn-intro/">WebNN API</a></li>
</ul>]]></content:encoded>
					
		
		
			</item>
		<item>
		<title>Unlock a new era of innovation with Windows Copilot Runtime and Copilot+ PCs</title>
		<link>https://blogs.windows.com/windowsdeveloper/2024/05/21/unlock-a-new-era-of-innovation-with-windows-copilot-runtime-and-copilot-pcs/</link>
		
		<dc:creator><![CDATA[Pavan Davuluri]]></dc:creator>
		<pubDate>Tue, 21 May 2024 15:30:06 +0000</pubDate>
				<category><![CDATA[Uncategorized]]></category>
		<guid isPermaLink="false">https://blogs.windows.com/windowsdeveloper/?p=56958</guid>

					<description><![CDATA[<p><span data-contrast="none">I am excited to be back at </span><a href="https://build.microsoft.com/"><span data-contrast="none">Build</span></a><span data-contrast="none"> with the developer community this year. </span><span data-ccp-props="{&#34;20
</p>
<p>The post <a href="https://blogs.windows.com/windowsdeveloper/2024/05/21/unlock-a-new-era-of-innovation-with-windows-copilot-runtime-and-copilot-pcs/">Unlock a new era of innovation with Windows Copilot Runtime and Copilot+ PCs</a> appeared first on <a href="https://blogs.windows.com/windowsdeveloper">Windows Developer Blog</a>.</p>
]]></description>
										<content:encoded><![CDATA[<span data-contrast="none">I am excited to be back at </span><a href="https://build.microsoft.com/"><span data-contrast="none">Build</span></a><span data-contrast="none"> with the developer community this year. </span><span data-ccp-props="{&quot;201341983&quot;:0,&quot;335559739&quot;:160,&quot;335559740&quot;:279}"> </span>

<span data-contrast="none">Over the last year, we have worked on reimagining </span> <span data-contrast="none">Windows PCs and yesterday, we introduced the world to a new category of Windows PCs called </span><b><span data-contrast="none">Copilot+ PCs.</span></b><span data-contrast="auto"> </span><span data-ccp-props="{&quot;201341983&quot;:0,&quot;335559739&quot;:160,&quot;335559740&quot;:279}"> </span>

<span data-contrast="none">Copilot+ PCs are the fastest, most intelligent Windows PCs ever with AI infused at every layer, starting with the world’s most powerful PC Neural Processing Units (NPUs) capable of delivering 40+ TOPS of compute. The new class of PCs is up to 20 times more </span><span data-contrast="none">powerful</span><span data-contrast="none"><sup>1</sup></span><span data-contrast="none"> and up to 100 times as efficient</span><span data-contrast="none"><sup>2</sup></span><span data-contrast="none"> for running AI workloads compared to traditional PCs. This is a quantum leap in performance, made possible by a quantum leap in efficiency. The NPU is part of a new System on Chip (SoC) that enables the most powerful and efficient Windows PCs ever built, with outstanding performance, incredible all day battery life, and great app experiences. Copilot+ PCs will be available in June, starting with Qualcomm’s Snapdragon X Series processors. Later this year we will have more devices in this category from Intel and AMD. </span><span data-ccp-props="{&quot;201341983&quot;:0,&quot;335559739&quot;:160,&quot;335559740&quot;:262}"> </span>

<span data-contrast="none">I am also excited that Qualcomm announced this morning its </span><b><span data-contrast="none">Snapdragon Dev Kit for Windows </span></b><span data-contrast="none">which has a special developer edition Snapdragon X Elite SoC. Featuring the NPU that powers the Copilot+ PCs, the Snapdragon Dev Kit for Windows has a form factor that is easily stackable and is designed specifically to be a developer’s everyday dev box, providing the maximum power and flexibility developers need. It is powered by a 3.8 GHz 12 Core Oryon CPU with dual core boost up to 4.3GHz, comes with 32 GB LPDDR5x memory, 512GB M2 storage, 80 Watt system architecture, support for up to 3 concurrent external displays and uses 20% ocean-bound-plastic. </span><a href="https://aka.ms/SDDevKitBlog"><span data-contrast="none">Learn more</span></a><span data-contrast="none">. </span>

<span data-ccp-props="{&quot;201341983&quot;:0,&quot;335559739&quot;:160,&quot;335559740&quot;:262}"><img class="aligncenter wp-image-56988 size-large" src="https://blogs.windows.com/wp-content/uploads/prod/sites/3/2024/05/Snapdragon-Dev-Kit-for-Windows-Front-Transparent-1-1024x576.png" alt="Snapdragon Dev Kit for Windows " width="1024" height="576" /></span>

<span data-contrast="none">This new class of powerful next generation AI devices is an invitation to app developers to deliver differentiated AI experiences that run on the edge, taking advantage of NPUs that offer the benefits of minimal latency, cost efficiency, data privacy, and more.  </span><span data-ccp-props="{&quot;201341983&quot;:0,&quot;335559738&quot;:120,&quot;335559739&quot;:120,&quot;335559740&quot;:240}"> </span>

<span data-contrast="auto">As we continue our journey into the AI era of computing, we want to give Developers who are at the forefront of this AI transformation the right software tools in addition to these powerful NPU powered devices to accelerate the creation of differentiated AI experiences to over 1 billion users. Today, I’m thrilled to share some of the great capabilities coming to Windows, making Windows the best place for your development needs.  </span><span data-ccp-props="{&quot;201341983&quot;:0,&quot;335559739&quot;:160,&quot;335559740&quot;:279}"> </span>
<ul>
 	<li data-leveltext="" data-font="Symbol" data-listid="10" data-list-defn-props="{&quot;335552541&quot;:1,&quot;335559685&quot;:720,&quot;335559991&quot;:360,&quot;469769226&quot;:&quot;Symbol&quot;,&quot;469769242&quot;:[8226],&quot;469777803&quot;:&quot;left&quot;,&quot;469777804&quot;:&quot;&quot;,&quot;469777815&quot;:&quot;hybridMultilevel&quot;}" data-aria-posinset="1" data-aria-level="1"><span data-contrast="none">We are excited to extend the Microsoft Copilot stack to Windows with Windows Copilot Runtime. We have infused AI into every layer of Windows, including a fundamental transformation of the OS itself to enable developers to accelerate AI development on Windows.  </span><span data-ccp-props="{&quot;201341983&quot;:0,&quot;335559739&quot;:160,&quot;335559740&quot;:279}"> </span></li>
 	<li data-leveltext="" data-font="Symbol" data-listid="10" data-list-defn-props="{&quot;335552541&quot;:1,&quot;335559685&quot;:720,&quot;335559991&quot;:360,&quot;469769226&quot;:&quot;Symbol&quot;,&quot;469769242&quot;:[8226],&quot;469777803&quot;:&quot;left&quot;,&quot;469777804&quot;:&quot;&quot;,&quot;469777815&quot;:&quot;hybridMultilevel&quot;}" data-aria-posinset="2" data-aria-level="1"><span data-contrast="none">Windows Copilot Runtime has everything you need to build great AI experiences regardless of where you are on your AI journey – whether you are just getting started or already have your own models. Windows Copilot Runtime includes Windows Copilot Library which is a set of APIs that are powered by the 40+ on-device AI models that ship with Windows. It also includes AI frameworks and toolchains to help developers bring their own on-device models to Windows. This is built on the foundation of powerful client silicon, including GPUs and NPUs. </span><span data-ccp-props="{&quot;201341983&quot;:0,&quot;335559739&quot;:160,&quot;335559740&quot;:279}"> </span></li>
 	<li data-leveltext="" data-font="Symbol" data-listid="10" data-list-defn-props="{&quot;335552541&quot;:1,&quot;335559685&quot;:720,&quot;335559991&quot;:360,&quot;469769226&quot;:&quot;Symbol&quot;,&quot;469769242&quot;:[8226],&quot;469777803&quot;:&quot;left&quot;,&quot;469777804&quot;:&quot;&quot;,&quot;469777815&quot;:&quot;hybridMultilevel&quot;}" data-aria-posinset="3" data-aria-level="1"><span data-contrast="none">We are introducing Windows Semantic Index, a new OS capability which redefines search on Windows and powers new experiences like Recall. Later, we will make this capability available for developers with Vector Embeddings API to build their own vector store and RAG within their applications and with their app data. </span><span data-ccp-props="{&quot;201341983&quot;:0,&quot;335559739&quot;:160,&quot;335559740&quot;:279}"> </span></li>
 	<li data-leveltext="" data-font="Symbol" data-listid="10" data-list-defn-props="{&quot;335552541&quot;:1,&quot;335559685&quot;:720,&quot;335559991&quot;:360,&quot;469769226&quot;:&quot;Symbol&quot;,&quot;469769242&quot;:[8226],&quot;469777803&quot;:&quot;left&quot;,&quot;469777804&quot;:&quot;&quot;,&quot;469777815&quot;:&quot;hybridMultilevel&quot;}" data-aria-posinset="4" data-aria-level="1"><span data-contrast="none">We are introducing Phi Silica which is built from the Phi series of models and is designed specifically for the NPUs in Copilot+ PCs. Windows is the first platform to have a state-of-the-art small language model (SLM) custom built for the NPU and shipping inbox.  </span><span data-ccp-props="{&quot;201341983&quot;:0,&quot;335559739&quot;:160,&quot;335559740&quot;:279}"> </span></li>
 	<li data-leveltext="" data-font="Symbol" data-listid="10" data-list-defn-props="{&quot;335552541&quot;:1,&quot;335559685&quot;:720,&quot;335559991&quot;:360,&quot;469769226&quot;:&quot;Symbol&quot;,&quot;469769242&quot;:[8226],&quot;469777803&quot;:&quot;left&quot;,&quot;469777804&quot;:&quot;&quot;,&quot;469777815&quot;:&quot;hybridMultilevel&quot;}" data-aria-posinset="5" data-aria-level="1"><span data-contrast="none">Phi Silica API along with OCR, Studio Effects, Live Captions, Recall User Activity APIs will be available in Windows Copilot Library in June. More APIs like Vector Embedding, RAG API, Text Summarization will be coming later. </span><span data-ccp-props="{&quot;201341983&quot;:0,&quot;335559739&quot;:160,&quot;335559740&quot;:279}"> </span></li>
 	<li data-leveltext="" data-font="Symbol" data-listid="10" data-list-defn-props="{&quot;335552541&quot;:1,&quot;335559685&quot;:720,&quot;335559991&quot;:360,&quot;469769226&quot;:&quot;Symbol&quot;,&quot;469769242&quot;:[8226],&quot;469777803&quot;:&quot;left&quot;,&quot;469777804&quot;:&quot;&quot;,&quot;469777815&quot;:&quot;hybridMultilevel&quot;}" data-aria-posinset="6" data-aria-level="1"><span data-contrast="none">We are introducing native support for PyTorch on Windows with DirectML which allows for thousands of Hugging Face models to just work on Windows.  </span><span data-ccp-props="{&quot;201341983&quot;:0,&quot;335559739&quot;:160,&quot;335559740&quot;:279}"> </span></li>
 	<li data-leveltext="" data-font="Symbol" data-listid="10" data-list-defn-props="{&quot;335552541&quot;:1,&quot;335559685&quot;:720,&quot;335559991&quot;:360,&quot;469769226&quot;:&quot;Symbol&quot;,&quot;469769242&quot;:[8226],&quot;469777803&quot;:&quot;left&quot;,&quot;469777804&quot;:&quot;&quot;,&quot;469777815&quot;:&quot;hybridMultilevel&quot;}" data-aria-posinset="7" data-aria-level="1"><span data-contrast="none">We are introducing Web Neural Network (WebNN) Developer Preview to Windows through DirectML. This allows web developers to take advantage of the silicon to deliver performant AI features in their web apps and can scale their AI investments across the breadth of the Windows ecosystem.</span><span data-ccp-props="{&quot;201341983&quot;:0,&quot;335559739&quot;:160,&quot;335559740&quot;:279}"> </span></li>
</ul>
<ul>
 	<li data-leveltext="" data-font="Symbol" data-listid="10" data-list-defn-props="{&quot;335552541&quot;:1,&quot;335559685&quot;:720,&quot;335559991&quot;:360,&quot;469769226&quot;:&quot;Symbol&quot;,&quot;469769242&quot;:[8226],&quot;469777803&quot;:&quot;left&quot;,&quot;469777804&quot;:&quot;&quot;,&quot;469777815&quot;:&quot;hybridMultilevel&quot;}" data-aria-posinset="1" data-aria-level="1"><span data-contrast="none">We are introducing new productivity features in Dev Home like Environments, improvements to WSL, DevDrive and new updates to WinUI3 and WPF to help every developer become more productive on Windows.</span><span data-ccp-props="{&quot;201341983&quot;:0,&quot;335559739&quot;:160,&quot;335559740&quot;:279}"> </span></li>
</ul>
<span data-contrast="none">I can’t wait to share more with you during our keynote today, </span><a href="https://build.microsoft.com/sessions/8aab36d1-d27d-46dd-81ec-eb3f49cfee6a?source=sessions"><span data-contrast="none">be sure to register for Build and tune in</span></a><span data-contrast="none">!</span><span data-ccp-props="{&quot;201341983&quot;:0,&quot;335559739&quot;:160,&quot;335559740&quot;:279}"> </span>
<h3><b><span data-contrast="none">Introducing Windows Copilot Runtime to provide a powerful AI platform for developers</span></b><span data-ccp-props="{&quot;201341983&quot;:0,&quot;335559739&quot;:160,&quot;335559740&quot;:262}"> </span></h3>
<span data-contrast="none">We want to democratize the ability to experiment, to build, and to reach people with breakthrough AI experiences. That’s why we’re committed to making Windows the most open platform for AI development. Building a powerful AI platform takes more than a new chip or model, it takes reimagining the entire system, from top to bottom. The new Windows Copilot Runtime is that system. Developers can take advantage of Windows Copilot Runtime in a variety of ways, from higher level APIs that can be accessed via simple settings toggle, all the way to bringing your own machine learning models. It represents the end-to-end Windows ecosystem:  </span><span data-ccp-props="{&quot;201341983&quot;:0,&quot;335559739&quot;:0,&quot;335559740&quot;:262}"> </span>
<ol>
 	<li data-leveltext="%1." data-font="Segoe UI" data-listid="27" data-list-defn-props="{&quot;335552541&quot;:0,&quot;335559685&quot;:720,&quot;335559991&quot;:360,&quot;469769242&quot;:[65533,0],&quot;469777803&quot;:&quot;left&quot;,&quot;469777804&quot;:&quot;%1.&quot;,&quot;469777815&quot;:&quot;multilevel&quot;,&quot;469778510&quot;:&quot;default&quot;}" data-aria-posinset="1" data-aria-level="1"><b><span data-contrast="none">Applications and Experiences</span></b><span data-contrast="none"> created by Microsoft and developers like you across Windows shell, Win32 Apps and Web apps. </span><span data-ccp-props="{&quot;201341983&quot;:0,&quot;335559739&quot;:0,&quot;335559740&quot;:262}"> </span></li>
 	<li data-leveltext="%1." data-font="Segoe UI" data-listid="27" data-list-defn-props="{&quot;335552541&quot;:0,&quot;335559685&quot;:720,&quot;335559991&quot;:360,&quot;469769242&quot;:[65533,0],&quot;469777803&quot;:&quot;left&quot;,&quot;469777804&quot;:&quot;%1.&quot;,&quot;469777815&quot;:&quot;multilevel&quot;,&quot;469778510&quot;:&quot;default&quot;}" data-aria-posinset="2" data-aria-level="1"><b><span data-contrast="none">Windows Copilot Library</span></b><span data-contrast="none"> is the set of APIs powered by the 40+ </span><b><span data-contrast="none">on-device models</span></b><span data-contrast="none"> that ship with Windows. This includes APIs and algorithms that power Windows experiences and are available for developers to tap into.</span><span data-ccp-props="{&quot;201341983&quot;:0,&quot;335559739&quot;:0,&quot;335559740&quot;:262}"> </span></li>
 	<li data-leveltext="%1." data-font="Segoe UI" data-listid="27" data-list-defn-props="{&quot;335552541&quot;:0,&quot;335559685&quot;:720,&quot;335559991&quot;:360,&quot;469769242&quot;:[65533,0],&quot;469777803&quot;:&quot;left&quot;,&quot;469777804&quot;:&quot;%1.&quot;,&quot;469777815&quot;:&quot;multilevel&quot;,&quot;469778510&quot;:&quot;default&quot;}" data-aria-posinset="3" data-aria-level="1"><b><span data-contrast="none">AI frameworks</span></b><span data-contrast="none"> like DirectML, ONNX Runtime, PyTorch, WebNN  and </span><b><span data-contrast="none">toolchains</span></b><span data-contrast="none"> like</span> <span data-contrast="auto">Olive, </span><span data-contrast="none">AI Toolkit for Visual Studio Code and more to help developers bring their own models and scale their AI apps across the breadth of the Windows hardware ecosystem. </span><span data-ccp-props="{&quot;201341983&quot;:0,&quot;335559739&quot;:0,&quot;335559740&quot;:262}"> </span></li>
 	<li data-leveltext="%1." data-font="Segoe UI" data-listid="27" data-list-defn-props="{&quot;335552541&quot;:0,&quot;335559685&quot;:720,&quot;335559991&quot;:360,&quot;469769242&quot;:[65533,0],&quot;469777803&quot;:&quot;left&quot;,&quot;469777804&quot;:&quot;%1.&quot;,&quot;469777815&quot;:&quot;multilevel&quot;,&quot;469778510&quot;:&quot;default&quot;}" data-aria-posinset="4" data-aria-level="1"><span data-contrast="none">Windows Copilot Runtime is built on the foundation of powerful client </span><b><span data-contrast="none">silicon</span></b><span data-contrast="none">, including GPUs and NPUs. </span><span data-contrast="auto"> </span><span data-contrast="auto">             </span><span data-ccp-props="{&quot;201341983&quot;:0,&quot;335559739&quot;:0,&quot;335559740&quot;:262}"> </span></li>
</ol>
<span data-ccp-props="{&quot;201341983&quot;:0,&quot;335559739&quot;:0,&quot;335559740&quot;:262}"> <img class="aligncenter wp-image-56976 size-large" src="https://blogs.windows.com/wp-content/uploads/prod/sites/3/2024/05/Windows-Copilot-Runtime-image-1-1024x533.jpg" alt="Windows Copilot Runtime content" width="1024" height="533" /></span>
<h3><b><span data-contrast="none">New experiences built using the Windows Copilot Runtime </span></b><span data-ccp-props="{&quot;201341983&quot;:0,&quot;335559739&quot;:0,&quot;335559740&quot;:279}"> </span></h3>
<span data-contrast="none">Windows Copilot Runtime powers the creation of all experiences you build, and what we - Windows - build for our end-users. Using </span><span data-contrast="auto">a </span><span data-contrast="none">suite of APIs and on-device models in Windows </span><span data-contrast="none">Copilot</span><span data-contrast="none"> Library,</span><span data-contrast="none"> we have built incredible first-party experiences like </span><span data-ccp-props="{&quot;201341983&quot;:0,&quot;335559738&quot;:120,&quot;335559739&quot;:120,&quot;335559740&quot;:240}"> </span>
<ul>
 	<li data-leveltext="" data-font="Symbol" data-listid="35" data-list-defn-props="{&quot;335552541&quot;:1,&quot;335559685&quot;:720,&quot;335559991&quot;:360,&quot;469769226&quot;:&quot;Symbol&quot;,&quot;469769242&quot;:[8226],&quot;469777803&quot;:&quot;left&quot;,&quot;469777804&quot;:&quot;&quot;,&quot;469777815&quot;:&quot;hybridMultilevel&quot;}" data-aria-posinset="2" data-aria-level="1"><span data-contrast="none">Recall that helps users instantly find almost anything</span><span data-contrast="none"><sup>3</sup></span><span data-contrast="none"> they’ve seen on their PC</span><span data-contrast="auto"> </span><span data-ccp-props="{&quot;201341983&quot;:0,&quot;335559738&quot;:120,&quot;335559739&quot;:120,&quot;335559740&quot;:240}"> </span></li>
 	<li data-leveltext="" data-font="Symbol" data-listid="35" data-list-defn-props="{&quot;335552541&quot;:1,&quot;335559685&quot;:720,&quot;335559991&quot;:360,&quot;469769226&quot;:&quot;Symbol&quot;,&quot;469769242&quot;:[8226],&quot;469777803&quot;:&quot;left&quot;,&quot;469777804&quot;:&quot;&quot;,&quot;469777815&quot;:&quot;hybridMultilevel&quot;}" data-aria-posinset="3" data-aria-level="1"><span data-contrast="auto">Cocreator</span><span data-contrast="none"><sup>4</sup></span> <span data-contrast="none">a collaborative AI image generator that helps users bring their ideas to life using natural language and ink strokes locally on the device</span><span data-ccp-props="{&quot;201341983&quot;:0,&quot;335559738&quot;:120,&quot;335559739&quot;:120,&quot;335559740&quot;:240}"> </span></li>
 	<li data-leveltext="" data-font="Symbol" data-listid="35" data-list-defn-props="{&quot;335552541&quot;:1,&quot;335559685&quot;:720,&quot;335559991&quot;:360,&quot;469769226&quot;:&quot;Symbol&quot;,&quot;469769242&quot;:[8226],&quot;469777803&quot;:&quot;left&quot;,&quot;469777804&quot;:&quot;&quot;,&quot;469777815&quot;:&quot;hybridMultilevel&quot;}" data-aria-posinset="4" data-aria-level="1"><span data-contrast="none">Restyle Image, helps users reimagine their personal photos with a new style combining image generation and photo editing in Photos </span> <span data-ccp-props="{&quot;201341983&quot;:0,&quot;335559738&quot;:120,&quot;335559739&quot;:120,&quot;335559740&quot;:240}"> </span></li>
 	<li data-leveltext="" data-font="Symbol" data-listid="35" data-list-defn-props="{&quot;335552541&quot;:1,&quot;335559685&quot;:720,&quot;335559991&quot;:360,&quot;469769226&quot;:&quot;Symbol&quot;,&quot;469769242&quot;:[8226],&quot;469777803&quot;:&quot;left&quot;,&quot;469777804&quot;:&quot;&quot;,&quot;469777815&quot;:&quot;hybridMultilevel&quot;}" data-aria-posinset="5" data-aria-level="1"><span data-contrast="auto">Others like Windows Studio Effects, and </span><span data-contrast="none">Live captions, with real-time translation from video and audio in 40+ languages into English subtitles </span><span data-ccp-props="{&quot;201341983&quot;:0,&quot;335559738&quot;:120,&quot;335559739&quot;:120,&quot;335559740&quot;:240}"> </span></li>
</ul>
<span data-contrast="none">We are also partnering with several third-party developers on apps like Davinci Resolve, CapCut, WhatsApp, Camo Studio, djay Pro, Cephable, LiquidText, Luminar Neo and many more that are leveraging the NPU to deliver innovative AI experiences with reduced latency, faster task completion, enhanced privacy and lower cloud compute costs. We’re excited for developers to take advantage of the NPU and Windows Copilot Runtime and invent new experiences.</span><span data-ccp-props="{&quot;201341983&quot;:0,&quot;335559738&quot;:120,&quot;335559739&quot;:120,&quot;335559740&quot;:240}"> </span>
<h3><b><span data-contrast="none">Windows </span></b><b><span data-contrast="none">Copilot</span></b><b><span data-contrast="none"> Library offers a set of APIs helping developers to accelerate local AI development </span></b><span data-ccp-props="{&quot;201341983&quot;:0,&quot;335559739&quot;:160,&quot;335559740&quot;:262}"> </span></h3>
<b><span data-contrast="none">Windows </span></b><b><span data-contrast="none">Copilot</span></b><b><span data-contrast="none"> Library</span></b> <b><span data-contrast="none">has a set of APIs</span></b><span data-contrast="none"> that are powered by the </span><b><span data-contrast="none">40+ on-device AI models </span></b><span data-contrast="none">and state-of-the-art algorithms like</span> <span data-contrast="none">DiskANN</span><b><span data-contrast="none">,</span></b><span data-contrast="none"> built into Windows.</span><span data-contrast="none"> Windows Copilot Library consists of ready-to-use AI APIs like Studio Effects, Live captions translations, OCR, Recall with User Activity, and Phi Silica, which will be available to developers in June. Vector Embeddings, Retrieval Augmented Generation (RAG), Text Summarization </span><span data-contrast="none">along with other</span><span data-contrast="none"> APIs will be</span> <span data-contrast="none">coming later to Windows Copilot Library</span><span data-contrast="none">. </span><span data-contrast="none">Developers will be able to access these APIs as part of the </span><a href="https://learn.microsoft.com/en-us/windows/apps/windows-app-sdk/"><span data-contrast="auto">Windows App SDK</span></a><span data-contrast="auto"> release. </span><span data-ccp-props="{&quot;201341983&quot;:0,&quot;335559739&quot;:160,&quot;335559740&quot;:259}"> </span>

<span data-contrast="auto">Developers can take advantage of the Windows </span><span data-contrast="none">Copilot</span><span data-contrast="auto"> Library with no-code effort to integrate Studio Effects into their apps like Creative filters, Portrait light, Eye contact teleprompter, Portrait blur, and Voice focus. WhatsApp among others has already upgraded their user experience adding Windows Studio Effects controls directly into the UI. </span><a href="https://learn.microsoft.com/windows/ai/studio-effects/"><span data-contrast="none">Learn more.</span></a><span data-ccp-props="{&quot;201341983&quot;:0,&quot;335559739&quot;:160,&quot;335559740&quot;:262}"> </span>

<span data-contrast="auto">With a similar no-code effort, developers can take advantage of Live captions, the translation feature in Windows to caption audio and video in real time and translate into preferred language in apps. </span><span data-ccp-props="{&quot;201341983&quot;:0,&quot;335559739&quot;:160,&quot;335559740&quot;:262}"> </span>

<span data-contrast="none">Developers can tap into the newly announced Recall feature on Copilot+ PCs. Enhance the user’s Recall experience with your app by adding contextual information to the underlying vector database via the </span><span data-contrast="auto">User Activity API. This integration helps users pick up where they left off in your app, improving app engagement and user's seamless flow between Windows and your app. E</span><span data-contrast="auto">dge and M365 apps like Outlook, PowerPoint and Teams have already extended their apps with Recall.</span> <a href="https://www.microsoft.com/store/productId/9NGQM8FPH9WQ?ocid=pdpshare"><span data-contrast="none">Concepts</span><span data-contrast="none">, a 3rd party sketching app </span></a><span data-contrast="none">is an early example – if launched from Recall, it brings users immediately to the exact canvas location in the right document, and even the same zoom level seen in the Recall timeline.</span><span data-ccp-props="{&quot;201341983&quot;:0,&quot;335559739&quot;:160,&quot;335559740&quot;:262}"> </span>
<h3><b><span data-contrast="auto">Introducing Windows Semantic Index that redefines search on Windows. Vector Embeddings API offers the capability for developers to build their own vector store with their app data</span></b><span data-ccp-props="{&quot;201341983&quot;:0,&quot;335559739&quot;:160,&quot;335559740&quot;:262}"> </span></h3>
<span data-contrast="auto">Recall database is powered by Windows Semantic Index, a new OS capability that redefines search on Windows. Recall is grounded in several state-of-the-art AI models, including multi-modal SLMs, running concurrently and integrated into the OS itself. These models understand different kinds of content and work across several languages, to organize a vast sea of information from text to image to videos, in Windows. This data is transformed and stored in a vector store called Windows Semantic Index. The semantic index is stored entirely on the user’s local device and accessible through natural language search. This deep integration allows a uniquely robust approach to privacy as the data does not leave the local device.  </span><span data-ccp-props="{&quot;201341983&quot;:0,&quot;335559739&quot;:120,&quot;335559740&quot;:262}"> </span>

<span data-contrast="auto">To help developers bring the same natural language search capability in their apps, we are making Vector Embeddings and RAG API available in Windows </span><span data-contrast="none">Copilot</span><span data-contrast="auto"> Library later. This will enable developers to build their own semantic index store with their own app data and this combined with Retrieval Augmented Generation (RAG) API, developers can bring natural language search capability in their apps. This is a great example of how we are building new features using the models and APIs in Windows Copilot Runtime and offering the same capability for developers to do so in their apps.   </span><span data-ccp-props="{&quot;201341983&quot;:0,&quot;335559738&quot;:20,&quot;335559739&quot;:120,&quot;335559740&quot;:240}"> </span>

<span data-contrast="auto">The APIs in the Windows Copilot Library cover the full spectrum from low-code APIs to sophisticated pipelines to fully multi-modal models. </span><span data-ccp-props="{&quot;201341983&quot;:0,&quot;335559738&quot;:20,&quot;335559739&quot;:120,&quot;335559740&quot;:240}"> </span>
<h3><b><span data-contrast="none">Windows is the first platform to have a state-of-the-art SLM shipping inbox and Phi Silica is custom built for the NPUs in Copilot+ PCs </span></b><span data-ccp-props="{&quot;201341983&quot;:0,&quot;335559738&quot;:20,&quot;335559739&quot;:120,&quot;335559740&quot;:240}"> </span></h3>
<span data-contrast="none">We recently </span><a href="https://azure.microsoft.com/en-us/blog/introducing-phi-3-redefining-whats-possible-with-slms/"><span data-contrast="none">introduced</span></a><span data-contrast="none"> Phi-3 the most capable and cost-effective SLM. Phi-3-mini does better than models twice its size on key benchmarks. Today we are introducing Phi Silica, built from the Phi series of models. Phi Silica is the SOTA (state of the art) SLM included out of the box and is custom built for the NPUs in Copilot+ PCs. With full NPU offload of prompt processing, the first token latency is at 650 tokens/second - and only costs about 1.5 Watts of power while leaving your CPU and GPU free for other computations. Token generation reuses the KV cache from the NPU and runs on the CPU producing about 27 tokens/second.</span><span data-ccp-props="{&quot;201341983&quot;:0,&quot;335559738&quot;:20,&quot;335559739&quot;:120,&quot;335559740&quot;:240}"> </span>

<img class="alignnone wp-image-56987 size-full" src="https://blogs.windows.com/wp-content/uploads/prod/sites/3/2024/05/Phi_npu.gif" alt="" width="1280" height="622" />

<span data-contrast="auto">These are just a few examples of the APIs available to developers in the Windows </span><span data-contrast="none">Copilot</span><span data-contrast="auto"> Library. As new models and new libraries come to Windows, the possibilities will only grow. We want to make it easy for developers to bring powerful AI features into their apps, and Windows </span><span data-contrast="none">Copilot</span><span data-contrast="auto"> Library is the perfect place to start. </span><span data-ccp-props="{&quot;201341983&quot;:0,&quot;335559738&quot;:20,&quot;335559739&quot;:120,&quot;335559740&quot;:240}"> </span>

<span data-contrast="none">We consistently ensure Windows AI experiences are safe, fair, and trustworthy, following our Microsoft Responsible AI principles. When developers extend their apps with Windows Copilot Library, they automatically inherit those Responsible AI guardrails. </span><span data-ccp-props="{&quot;201341983&quot;:0,&quot;335559738&quot;:20,&quot;335559739&quot;:0,&quot;335559740&quot;:240}"> </span>
<h3><b><span data-contrast="none">Developers can bring their own models and scale across breadth of Windows hardware powered by DirectML</span></b><span data-ccp-props="{&quot;201341983&quot;:0,&quot;335559739&quot;:160,&quot;335559740&quot;:279}"> </span></h3>
<span data-contrast="none">While the models that ship with Windows 11 power a wide range of AI experiences, many developers will want to bring their own models to Windows to power their applications. As an open platform, Windows supports a diverse silicon ecosystem, and Windows has simplified optimizing models across silicon with DirectML. Just like DirectX is for Graphics, DirectML is the high-performance low-level API for machine learning in Windows. </span><span data-ccp-props="{&quot;201341983&quot;:0,&quot;335559739&quot;:160,&quot;335559740&quot;:279}"> </span>

<span data-contrast="auto">DirectML abstracts across the different hardware options our Independent Hardware Vendor (IHV) partners bring to the Windows ecosystem, and supports across GPUs and NPUs, with CPU integration coming soon. It integrates with relevant frameworks, such as the ONNX Runtime, PyTorch and WebNN. </span><span data-ccp-props="{&quot;201341983&quot;:0,&quot;335559739&quot;:160,&quot;335559740&quot;:279}"> </span>
<h3><b><span data-contrast="none">PyTorch is now natively supported on Windows with DirectML </span></b><span data-ccp-props="{&quot;201341983&quot;:0,&quot;335559739&quot;:160,&quot;335559740&quot;:259}"> </span></h3>
<span data-contrast="none">We know that a lot of developers do their PyTorch development on Windows. So, we’re thrilled to announce that Windows now natively supports PyTorch through DirectML. Native PyTorch support means that thousands of Hugging Face models will just work on Windows. Not just that - we're collaborating with Nvidia to scale these development workflows to over 100M RTX AI GPUs. </span><span data-ccp-props="{&quot;201341983&quot;:0,&quot;335559739&quot;:160,&quot;335559740&quot;:259}"> </span>

<span data-contrast="none">PyTorch support on GPUs is available starting today, with NPU support coming soon. </span><a href="https://learn.microsoft.com/windows/ai/directml/pytorch-windows"><span data-contrast="none">Learn more</span></a><span data-ccp-props="{&quot;201341983&quot;:0,&quot;335559739&quot;:160,&quot;335559740&quot;:259}"> </span>

<span data-ccp-props="{&quot;201341983&quot;:0,&quot;335559739&quot;:160,&quot;335559740&quot;:279}"> <img class="alignnone wp-image-56980 size-full" src="https://blogs.windows.com/wp-content/uploads/prod/sites/3/2024/05/pyt_phi3_emailprompt_notitle_noloop.gif" alt="" width="904" height="655" /></span>

<span data-ccp-props="{&quot;201341983&quot;:0,&quot;335559739&quot;:160,&quot;335559740&quot;:279}"> </span>

<span data-contrast="none">We recognize that many developers start with web apps today. Web apps should also be able to take advantage of silicon on local devices to deliver AI experiences to users.</span><b><span data-contrast="none"> </span></b><span data-ccp-props="{&quot;201341983&quot;:0,&quot;335559739&quot;:160,&quot;335559740&quot;:279}"> </span>
<h3><b><span data-contrast="none">DirectML now supports web apps that can take advantage of silicon to deliver AI experiences powered by WebNN</span></b><span data-ccp-props="{&quot;201341983&quot;:0,&quot;335559739&quot;:160,&quot;335559740&quot;:279}"> </span></h3>
<span data-contrast="auto">From native to web applications, DirectML now brings local AI scale across Windows for the web through the new WebNN Developer Preview. WebNN, an emerging web standard for machine learning, powered by DirectML and ONNX Runtime Web, simplifies how developers can leverage the underlying hardware on their user’s device for their web apps to deliver AI experiences at near native performance for tasks such as generative AI, image processing, natural language processing, computer vision and more. This WebNN Developer Preview supports GPUs with broader accelerator coverage to include NPU coming soon. </span><a href="https://learn.microsoft.com/windows/ai/directml/webnn-overview"><span data-contrast="none">Learn more</span></a><span data-contrast="auto"> about how to get started with WebNN.</span><span data-ccp-props="{&quot;201341983&quot;:0,&quot;335559739&quot;:160,&quot;335559740&quot;:279}"> </span>
<h3><b><span data-contrast="none">High-performance inferencing on Windows with ONNX Runtime and DirectML</span></b><span data-ccp-props="{&quot;201341983&quot;:0,&quot;335559739&quot;:160,&quot;335559740&quot;:279}"> </span></h3>
<span data-contrast="none">Microsoft's ONNX Runtime builds on the power of the open-source community to enable developers to ship their AI models to production with the performance and cross-platform support they need. ONNX Runtime with DirectML applies state-of-the-art optimizations to get the best performance for all generative AI models like Phi, Llama, Mistral, and Stable Diffusion. With ONNX Runtime, developers can extend their Windows applications to other platforms like web, cloud or mobile, wherever they need to ship their application on. ONNX Runtime is how Microsoft apps like Office, Visual Studio Code, and even Windows itself ship their AI to run on-device. </span><a href="https://onnxruntime.ai/blogs/accelerating-phi-2"><span data-contrast="none">Learn More.</span></a><span data-ccp-props="{&quot;201341983&quot;:0,&quot;335559739&quot;:160,&quot;335559740&quot;:279}"> </span>

<span data-contrast="none">DirectML helps scale your efforts across the Windows ecosystem – whether you are building your own models or you want to bring an open-source model from Hugging Face, and whether you are building a native Windows app or a web app.</span><span data-ccp-props="{&quot;201341983&quot;:0,&quot;335559739&quot;:160,&quot;335559740&quot;:279}"> </span>

<span data-contrast="auto">DirectML is generally available across all Windows GPUs. DirectML support on Intel® Core™ Ultra processors with Intel® AI Boost is available as a Developer Preview with GA coming soon, and Qualcomm® Hexagon™ NPU in the Snapdragon X Elite SoC is coming soon. Stay tuned for more DirectML features that will simplify how developers can differentiate with AI and scale their innovations across Windows. Grab your favorite model and get started with DirectML today at </span><a href="https://learn.microsoft.com/en-us/windows/ai/directml/dml"><span data-contrast="none">DirectML Overview</span></a><span data-contrast="auto"> or </span><a href="https://developer.microsoft.com/en-us/windows/ai/"><span data-contrast="none">Windows AI Dev Center | Microsoft Developer</span></a><span data-ccp-props="{&quot;201341983&quot;:0,&quot;335559739&quot;:160,&quot;335559740&quot;:279}"> </span>
<p data-wp-editing="1"><span data-ccp-props="{&quot;201341983&quot;:0,&quot;335559738&quot;:20,&quot;335559739&quot;:0,&quot;335559740&quot;:262}"> <img class="aligncenter wp-image-56978 size-large" src="https://blogs.windows.com/wp-content/uploads/prod/sites/3/2024/05/DirectMLSystem-Architecture-Diagram-Build-2024-1024x643.png" alt="DirectMLSystem architecture diagram" width="1024" height="643" /></span><span data-ccp-props="{&quot;201341983&quot;:0,&quot;335559738&quot;:20,&quot;335559739&quot;:0,&quot;335559740&quot;:262}"> </span></p>
<b><span data-contrast="auto">Windows Subsystem for Linux (WSL) </span></b><span data-contrast="auto">offers a robust platform for AI development on Windows by making it easy to run Windows and Linux workloads simultaneously.  Developers can easily share files, GUI apps, GPU and more between environments with no additional setup. WSL is now enhanced to meet the enterprise grade security requirements so enterprise customers can confidently deploy WSL for their developers to take advantage of both Windows and Linux operating systems on the same Windows device and accelerate AI development efficiently. </span><span data-ccp-props="{&quot;201341983&quot;:0,&quot;335559739&quot;:160,&quot;335559740&quot;:259}"> </span>

<span data-contrast="auto">WSL now incorporates two new Zero Trust features, Linux Intune Agent and Integration with Microsoft Entra ID, to enable system administrators to enhance enterprise security. With Linux Intune agent integration, IT admins and administrators can determine compliance based on WSL distro versions and more, using custom scripts. Microsoft Entra ID integration provides a zero trust experience to access protected enterprise resources from within a WSL distro by providing a secure channel to acquire and utilize tokens bound to the host device. The Linux Intune agent integration is currently in public preview, and Microsoft Entra ID integration will be in public preview this summer. </span><span data-ccp-props="{&quot;201341983&quot;:0,&quot;335559739&quot;:160,&quot;335559740&quot;:257}"> </span>
<h3><b><span data-contrast="auto">New experiences designed to help every developer become more productive on Windows 11 </span></b><span data-ccp-props="{&quot;201341983&quot;:0,&quot;335559739&quot;:160,&quot;335559740&quot;:257}"> </span></h3>
<span data-contrast="auto">We know building great AI experiences starts with developer productivity. That’s why we are excited to announce new features in Dev Home, performance improvements to DevDrive and improvements to your favorite tool PowerToys.</span><span data-ccp-props="{&quot;201341983&quot;:0,&quot;335559739&quot;:160,&quot;335559740&quot;:257}"> </span>

<span data-contrast="auto">At Build last year, we announced Dev Home and since then we have been evolving Dev Home to be the one-stop-shop for setting up your Windows machine for development. We have made some key improvements to Dev Home to further boost developer productivity. Dev Home is now installed on every Windows machine making it easy to get started. We are introducing Environments, Windows Customization and welcoming WSL and a subset of PowerToys utilities to Dev Home. </span><span data-ccp-props="{&quot;201341983&quot;:0,&quot;335559739&quot;:160,&quot;335559740&quot;:257}"> </span>
<h3><b><span data-contrast="auto">Environments in Dev Home help centralize your interactions with all remote environments. Create, manage, launch and configure dev environments in a snap from Dev Home</span></b><span data-contrast="auto"> </span><span data-ccp-props="{&quot;201341983&quot;:0,&quot;335559739&quot;:160,&quot;335559740&quot;:257}"> </span></h3>
<span data-contrast="auto">For developers who often use virtual machines and remote environments, Environments in Dev Home is for you. With support for Hyper-V VMs and cloud Microsoft Dev Boxes, you can create new environments, set up environments with repositories, apps, and packages. You can perform quick actions such as taking snapshots, starting, and stopping, and even pin environments to the Start Menu and taskbar, all from Environments in Dev Home. To make this experience even more powerful, it’s all extensible and open source so you can add your own environments. Environments in Dev Home is available now in preview.</span><span data-ccp-props="{&quot;201341983&quot;:0,&quot;335559739&quot;:160,&quot;335559740&quot;:257}"> </span>

<img class="aligncenter wp-image-56975 size-large" src="https://blogs.windows.com/wp-content/uploads/prod/sites/3/2024/05/Dev-Home-Environments-1024x669.png" alt="Dev home Environments screen" width="1024" height="669" />

<span data-contrast="auto">We know developers want zero distractions when coding, and customizing your dev machine to the ideal state is critical for productivity. We also know developers want more control and agency on their device. That’s why we are releasing Windows Customization feature in Dev Home</span><b><span data-contrast="auto">. </span></b><span data-ccp-props="{&quot;201341983&quot;:0,&quot;335559739&quot;:160,&quot;335559740&quot;:257}"> </span>
<h3><b><span data-contrast="auto">Windows Customization in Dev Home allows developers to customize their device to an ideal state with fewest clicks</span></b><span data-contrast="auto"> </span><span data-ccp-props="{&quot;201341983&quot;:0,&quot;335559739&quot;:160,&quot;335559740&quot;:257}"> </span></h3>
<span data-contrast="auto">Windows Customization gives developers access to Dev Drive insights, advanced File Explorer settings, virtual machine management, and the ability to quiet background processes, giving developers more control over their Windows machine. Submit feature requests for what you want to see in Windows Customization on </span><a href="https://github.com/microsoft/devhome"><span data-contrast="none">GitHub</span></a><span data-contrast="auto">. </span><span data-ccp-props="{&quot;201341983&quot;:0,&quot;335559739&quot;:160,&quot;335559740&quot;:257}"> </span>

<span data-ccp-props="{&quot;201341983&quot;:0,&quot;335559739&quot;:0,&quot;335559740&quot;:240}"> <img class="aligncenter wp-image-56979 size-large" src="https://blogs.windows.com/wp-content/uploads/prod/sites/3/2024/05/Dev-Home-Windows-Customization-1024x547.png" alt="Windows customization folders in Dev Home" width="1024" height="547" /></span>
<h3><b><span data-contrast="auto">New Export feature in Dev Home Machine Configuration allows you to quickly create configuration files to share with your teammates, boosting productivity</span></b><span data-ccp-props="{&quot;201341983&quot;:0,&quot;335559739&quot;:160,&quot;335559740&quot;:257}"> </span></h3>
<a href="https://learn.microsoft.com/windows/package-manager/configuration/"><span data-contrast="none">WinGet configuration files</span></a><span data-contrast="auto"> are an easy way to get your machine set up for development exactly how you like it. For a streamlined experience, try the new export feature in Dev Home which allows you to generate a configuration file based on the choices you made in Dev Home's Machine Configuration setup flow, allowing you to quickly create configuration files to share with your teammates for a consistent machine setup. </span><span data-ccp-props="{&quot;201341983&quot;:0,&quot;335559739&quot;:160,&quot;335559740&quot;:257}"> </span>

<span data-contrast="auto">Lastly, when cloning a repository in Dev Home that contains a configuration file, Dev Home can now detect that file and let you run it right away, allowing you to get set up for coding even faster than before. </span><span data-ccp-props="{&quot;201341983&quot;:0,&quot;335559739&quot;:160,&quot;335559740&quot;:257}"> </span>

<span data-contrast="auto">In addition to these new features, we are bringing WSL and a subset of PowerToys utilities to Dev Home, truly making Dev Home your one-stop shop for all your development needs. You can now access WSL right from Dev Home in the Environments tab. Also, a subset of PowerToys utilities such as </span><a href="https://learn.microsoft.com/windows/powertoys/hosts-file-editor"><span data-contrast="none">Hosts File Editor</span></a><span data-contrast="auto">, </span><a href="https://learn.microsoft.com/windows/powertoys/environment-variables"><span data-contrast="none">Environment Variables</span></a><span data-contrast="auto">, and </span><a href="https://learn.microsoft.com/windows/powertoys/registry-preview"><span data-contrast="none">Registry Preview</span></a><span data-contrast="auto"> can be accessed in the new Utilities tab on Dev Home. These features are currently available in preview. </span><span data-contrast="none"> </span><span data-ccp-props="{&quot;201341983&quot;:0,&quot;335559739&quot;:0,&quot;335559740&quot;:240}"> </span>
<h3><span data-ccp-props="{&quot;201341983&quot;:0,&quot;335559739&quot;:0,&quot;335559740&quot;:240}"> </span><b><span data-contrast="auto">Dev Drive introduces block cloning that will allow developers to perform large file copy operations, instantaneously </span></b><span data-ccp-props="{&quot;201341983&quot;:0,&quot;335559739&quot;:160,&quot;335559740&quot;:257}"> </span></h3>
<span data-contrast="auto">At the heart of developer productivity lies improving performance for developer workloads on Windows. </span><a href="https://blogs.windows.com/windowsdeveloper/2023/05/23/bringing-the-power-of-ai-to-windows-11-unlocking-a-new-era-of-productivity-for-customers-and-developers-with-windows-copilot-and-dev-home/"><span data-contrast="none">Last year at Build</span></a><b><span data-contrast="auto">, </span></b><span data-contrast="auto">we announced Dev Drive a new storage volume tailor-made for developers and supercharged for performance and security. Since then, we have continued to invest further in Windows performance improvements for developer workloads. </span><span data-ccp-props="{&quot;201341983&quot;:0,&quot;335559739&quot;:160,&quot;335559740&quot;:257}"> </span>

<span data-contrast="auto">With the release of Windows 11 24H2, workflows will get even faster when developing on a Dev Drive. Windows copy engine now has Filesystem Block Cloning, resulting in nearly instantaneous copy actions and drastically improving performance, especially in developer scenarios that copy large files. Our benchmarks include the following: </span><span data-ccp-props="{&quot;201341983&quot;:0,&quot;335559739&quot;:160,&quot;335559740&quot;:257}"> </span>
<table style="margin: 0 auto;" data-tablestyle="MsoNormalTable" data-tablelook="1184">
<tbody>
<tr>
<td data-celllook="69905"><b><span data-contrast="none">File(s) Copied</span></b><span data-contrast="none"> </span><span data-ccp-props="{&quot;201341983&quot;:0,&quot;335559739&quot;:0,&quot;335559740&quot;:240}"> </span></td>
<td data-celllook="69905"><b><span data-contrast="none">NTFS </span></b><span data-contrast="none"> </span><span data-ccp-props="{&quot;201341983&quot;:0,&quot;335559739&quot;:0,&quot;335559740&quot;:240}"> </span></td>
<td data-celllook="69905"><b><span data-contrast="none">Dev Drive </span></b><span data-contrast="none"> </span>
<b><span data-contrast="none">w/ Block Cloning</span></b><span data-contrast="none"> </span><span data-ccp-props="{&quot;201341983&quot;:0,&quot;335559739&quot;:0,&quot;335559740&quot;:240}"> </span></td>
<td data-celllook="69905"><b><span data-contrast="auto">% Improvement</span></b><span data-contrast="auto"> </span><span data-ccp-props="{&quot;201341983&quot;:0,&quot;335559739&quot;:0,&quot;335559740&quot;:240}"> </span></td>
</tr>
<tr>
<td data-celllook="69905"><span data-contrast="none">10GB file </span><span data-ccp-props="{&quot;201341983&quot;:0,&quot;335559739&quot;:0,&quot;335559740&quot;:240}"> </span></td>
<td data-celllook="69905"><span data-contrast="none">7s 964ms </span><span data-ccp-props="{&quot;201341983&quot;:0,&quot;335559739&quot;:0,&quot;335559740&quot;:240}"> </span></td>
<td data-celllook="69905"><span data-contrast="none">641ms </span><span data-ccp-props="{&quot;201341983&quot;:0,&quot;335559739&quot;:0,&quot;335559740&quot;:240}"> </span></td>
<td data-celllook="69905"><span data-contrast="none">92% </span><span data-ccp-props="{&quot;201341983&quot;:0,&quot;335559739&quot;:0,&quot;335559740&quot;:240}"> </span></td>
</tr>
<tr>
<td data-celllook="69905"><span data-contrast="none">1GB file </span><span data-ccp-props="{&quot;201341983&quot;:0,&quot;335559739&quot;:0,&quot;335559740&quot;:240}"> </span></td>
<td data-celllook="69905"><span data-contrast="none">681ms </span><span data-ccp-props="{&quot;201341983&quot;:0,&quot;335559739&quot;:0,&quot;335559740&quot;:240}"> </span></td>
<td data-celllook="69905"><span data-contrast="none">38ms </span><span data-ccp-props="{&quot;201341983&quot;:0,&quot;335559739&quot;:0,&quot;335559740&quot;:240}"> </span></td>
<td data-celllook="69905"><span data-contrast="none">94% </span><span data-ccp-props="{&quot;201341983&quot;:0,&quot;335559739&quot;:0,&quot;335559740&quot;:240}"> </span></td>
</tr>
<tr>
<td data-celllook="69905"><span data-contrast="none">1MB file </span><span data-ccp-props="{&quot;201341983&quot;:0,&quot;335559739&quot;:0,&quot;335559740&quot;:240}"> </span></td>
<td data-celllook="69905"><span data-contrast="none">11ms </span><span data-ccp-props="{&quot;201341983&quot;:0,&quot;335559739&quot;:0,&quot;335559740&quot;:240}"> </span></td>
<td data-celllook="69905"><span data-contrast="none">9ms </span><span data-ccp-props="{&quot;201341983&quot;:0,&quot;335559739&quot;:0,&quot;335559740&quot;:240}"> </span></td>
<td data-celllook="69905"><span data-contrast="none">18% </span><span data-ccp-props="{&quot;201341983&quot;:0,&quot;335559739&quot;:0,&quot;335559740&quot;:240}"> </span></td>
</tr>
<tr>
<td data-celllook="69905"><span data-contrast="none">18GB folder(5815 files) </span><span data-ccp-props="{&quot;201341983&quot;:0,&quot;335559739&quot;:0,&quot;335559740&quot;:240}"> </span></td>
<td data-celllook="69905"><span data-contrast="none">30s 867ms </span><span data-ccp-props="{&quot;201341983&quot;:0,&quot;335559739&quot;:0,&quot;335559740&quot;:240}"> </span></td>
<td data-celllook="69905"><span data-contrast="none">6s 306ms </span><span data-ccp-props="{&quot;201341983&quot;:0,&quot;335559739&quot;:0,&quot;335559740&quot;:240}"> </span></td>
<td data-celllook="69905"><span data-contrast="none">80% </span><span data-ccp-props="{&quot;201341983&quot;:0,&quot;335559739&quot;:0,&quot;335559740&quot;:240}"> </span></td>
</tr>
</tbody>
</table>
<span data-ccp-props="{&quot;201341983&quot;:0,&quot;335559738&quot;:20,&quot;335559739&quot;:0,&quot;335559740&quot;:240}"> </span>

<span data-contrast="auto">Dev Drive is a must for any developer, especially if you are dealing with repositories with many files, or large files. You can set up Dev Drive through the Settings app under System-&gt;Storage-&gt;Disks and Volumes page.</span><span data-ccp-props="{&quot;201341983&quot;:0,&quot;335559738&quot;:20,&quot;335559739&quot;:0,&quot;335559740&quot;:240}"> </span>

<span data-contrast="auto">Reducing toil and unlocking the fun and joy of development on Windows with new features and improvements</span><span data-ccp-props="{&quot;201341983&quot;:0,&quot;335559739&quot;:160,&quot;335559740&quot;:257}"> </span>
<h3><b><span data-contrast="auto">Sudo for Windows allows developers to run elevated commands right in Terminal</span></b><span data-ccp-props="{&quot;134245418&quot;:true,&quot;134245529&quot;:true,&quot;201341983&quot;:0,&quot;335559738&quot;:160,&quot;335559739&quot;:80,&quot;335559740&quot;:279}"> </span></h3>
<span data-contrast="auto">For command line users, we’re providing a simple and familiar way for elevating your command prompt with Sudo for Windows. Simply enable Sudo within Windows developer settings and you can get started running elevated commands with Sudo right in your terminal. You can learn more about Sudo on </span><a href="https://github.com/microsoft/sudo"><span data-contrast="none">GitHub.</span></a><span data-contrast="auto"> </span><span data-ccp-props="{&quot;201341983&quot;:0,&quot;335559739&quot;:160,&quot;335559740&quot;:279}"> </span>
<h3><b><span data-contrast="auto">New Source code integration in File Explorer allows tracking commit messages and file status directly in File Explorer </span></b><span data-ccp-props="{&quot;201341983&quot;:0,&quot;335559739&quot;:160,&quot;335559740&quot;:279}"> </span></h3>
<span data-contrast="auto">File Explorer will provide even more power to developers with version control protocol integration (including Git). This allows developers to monitor data including file status, commit messages, and current branch directly from File Explorer. File Explorer has also gained the ability to compress to 7zip and TAR.</span><span data-ccp-props="{&quot;201341983&quot;:0,&quot;335559739&quot;:160,&quot;335559740&quot;:279}"> </span>

<img class="aligncenter wp-image-56977 size-large" src="https://blogs.windows.com/wp-content/uploads/prod/sites/3/2024/05/File-Explorer-Source-Code-Integration-1024x646.png" alt="File Explorer Source Code folders" width="1024" height="646" />
<h3><b><span data-contrast="none">Continuing to innovate and accelerating development for Windows on Arm </span></b><span data-ccp-props="{&quot;201341983&quot;:0,&quot;335559738&quot;:300,&quot;335559739&quot;:330,&quot;335559740&quot;:279}"> </span></h3>
<span data-contrast="none">The Arm developer ecosystem momentum continues to grow with updates to Visual Studio, .NET, and many key tools delivering Arm native versions. Windows is continuing to welcome more third-party Windows apps, middleware partners and Open-Source Software natively to Arm. </span><a href="https://learn.microsoft.com/windows/arm/add-arm-support"><span data-contrast="none">Learn how to add Arm support for your apps.</span></a><span data-contrast="auto"> </span><span data-ccp-props="{&quot;201341983&quot;:0,&quot;335559739&quot;:0,&quot;335559740&quot;:240}"> </span>
<ul>
 	<li data-leveltext="" data-font="Symbol" data-listid="23" data-list-defn-props="{&quot;335552541&quot;:1,&quot;335559685&quot;:720,&quot;335559991&quot;:360,&quot;469769226&quot;:&quot;Symbol&quot;,&quot;469769242&quot;:[8226],&quot;469777803&quot;:&quot;left&quot;,&quot;469777804&quot;:&quot;&quot;,&quot;469777815&quot;:&quot;hybridMultilevel&quot;}" data-aria-posinset="1" data-aria-level="1"><span data-contrast="none">Visual Studio now includes Arm native SQL Server Developer Tools (SSDT), the #1 requested Arm native workload for VS. </span><a href="https://devblogs.microsoft.com/visualstudio/arm64-in-ssdt/"><span data-contrast="none">Learn more</span></a><span data-ccp-props="{&quot;201341983&quot;:0,&quot;335559739&quot;:0,&quot;335559740&quot;:240}"> </span></li>
 	<li data-leveltext="" data-font="Symbol" data-listid="23" data-list-defn-props="{&quot;335552541&quot;:1,&quot;335559685&quot;:720,&quot;335559991&quot;:360,&quot;469769226&quot;:&quot;Symbol&quot;,&quot;469769242&quot;:[8226],&quot;469777803&quot;:&quot;left&quot;,&quot;469777804&quot;:&quot;&quot;,&quot;469777815&quot;:&quot;hybridMultilevel&quot;}" data-aria-posinset="2" data-aria-level="1"><span data-contrast="none">.NET 8 includes tons of performance improvements for Arm: </span><a href="https://devblogs.microsoft.com/dotnet/performance-improvements-in-net-8/"><span data-contrast="none">Performance Improvements in .NET 8 - .NET Blog (microsoft.com)</span></a><span data-ccp-props="{&quot;201341983&quot;:0,&quot;335559739&quot;:0,&quot;335559740&quot;:240}"> </span></li>
 	<li data-leveltext="" data-font="Symbol" data-listid="23" data-list-defn-props="{&quot;335552541&quot;:1,&quot;335559685&quot;:720,&quot;335559991&quot;:360,&quot;469769226&quot;:&quot;Symbol&quot;,&quot;469769242&quot;:[8226],&quot;469777803&quot;:&quot;left&quot;,&quot;469777804&quot;:&quot;&quot;,&quot;469777815&quot;:&quot;hybridMultilevel&quot;}" data-aria-posinset="3" data-aria-level="1"><span data-contrast="none">Unity games editor is now available in preview and will release to market with the next Unity update, allowing game developers to build, test and run Unity titles for Arm powered Windows devices. </span><span data-contrast="none"> </span><span data-ccp-props="{&quot;201341983&quot;:0,&quot;335559739&quot;:0,&quot;335559740&quot;:240}"> </span></li>
 	<li data-leveltext="" data-font="Symbol" data-listid="23" data-list-defn-props="{&quot;335552541&quot;:1,&quot;335559685&quot;:720,&quot;335559991&quot;:360,&quot;469769226&quot;:&quot;Symbol&quot;,&quot;469769242&quot;:[8226],&quot;469777803&quot;:&quot;left&quot;,&quot;469777804&quot;:&quot;&quot;,&quot;469777815&quot;:&quot;hybridMultilevel&quot;}" data-aria-posinset="4" data-aria-level="1"><span data-contrast="none">Blender Arm native builds is available in preview with the official builds with long term support expected to ship in June. Blender is </span><i><span data-contrast="none">the</span></i><span data-contrast="none"> free and open source 3D creation suite. It supports the entirety of the 3D pipeline—modelling, rigging, animation, simulation, rendering, compositing and motion tracking, even video editing and game creation.</span><span data-ccp-props="{&quot;201341983&quot;:0,&quot;335559739&quot;:0,&quot;335559740&quot;:240}"> </span></li>
 	<li data-leveltext="" data-font="Symbol" data-listid="23" data-list-defn-props="{&quot;335552541&quot;:1,&quot;335559685&quot;:720,&quot;335559991&quot;:360,&quot;469769226&quot;:&quot;Symbol&quot;,&quot;469769242&quot;:[8226],&quot;469777803&quot;:&quot;left&quot;,&quot;469777804&quot;:&quot;&quot;,&quot;469777815&quot;:&quot;hybridMultilevel&quot;}" data-aria-posinset="5" data-aria-level="1"><span data-contrast="none">Arm Native Docker tools for Windows are now available.</span><span data-contrast="none"> </span><span data-ccp-props="{&quot;201341983&quot;:0,&quot;335559739&quot;:0,&quot;335559740&quot;:240}"> </span></li>
 	<li data-leveltext="" data-font="Symbol" data-listid="23" data-list-defn-props="{&quot;335552541&quot;:1,&quot;335559685&quot;:720,&quot;335559991&quot;:360,&quot;469769226&quot;:&quot;Symbol&quot;,&quot;469769242&quot;:[8226],&quot;469777803&quot;:&quot;left&quot;,&quot;469777804&quot;:&quot;&quot;,&quot;469777815&quot;:&quot;hybridMultilevel&quot;}" data-aria-posinset="6" data-aria-level="1"><span data-contrast="none">Github Actions now has Arm64 runners on Windows. This is now available in private preview with a public preview expected in the coming months. You can apply to join </span><a href="https://resources.github.com/devops/accelerate-your-cicd-with-arm-and-gpu-runners-in-github-actions/#form"><span data-contrast="none">here</span></a><span data-contrast="none">. </span><span data-ccp-props="{&quot;134233117&quot;:false,&quot;134233118&quot;:false,&quot;201341983&quot;:0,&quot;335559739&quot;:0,&quot;335559740&quot;:240}"> </span></li>
 	<li data-leveltext="" data-font="Symbol" data-listid="23" data-list-defn-props="{&quot;335552541&quot;:1,&quot;335559685&quot;:720,&quot;335559991&quot;:360,&quot;469769226&quot;:&quot;Symbol&quot;,&quot;469769242&quot;:[8226],&quot;469777803&quot;:&quot;left&quot;,&quot;469777804&quot;:&quot;&quot;,&quot;469777815&quot;:&quot;hybridMultilevel&quot;}" data-aria-posinset="7" data-aria-level="1"><span data-contrast="none">GIMP adds Arm native with long term support from v3.0 will be available in May.</span><span data-contrast="none"> </span><span data-ccp-props="{&quot;201341983&quot;:0,&quot;335559739&quot;:0,&quot;335559740&quot;:240}"> </span></li>
 	<li data-leveltext="" data-font="Symbol" data-listid="23" data-list-defn-props="{&quot;335552541&quot;:1,&quot;335559685&quot;:720,&quot;335559991&quot;:360,&quot;469769226&quot;:&quot;Symbol&quot;,&quot;469769242&quot;:[8226],&quot;469777803&quot;:&quot;left&quot;,&quot;469777804&quot;:&quot;&quot;,&quot;469777815&quot;:&quot;hybridMultilevel&quot;}" data-aria-posinset="8" data-aria-level="1"><span data-contrast="none">Qt 6.8 release due in September will move Arm native to LTS for Windows.</span><span data-ccp-props="{&quot;201341983&quot;:0,&quot;335557856&quot;:16777215,&quot;335559738&quot;:220,&quot;335559739&quot;:220,&quot;335559740&quot;:279}"> </span></li>
</ul>
<h3><b><span data-contrast="none">Continuing investments in WinUI3 and WPF to help developers build rich, modern Windows applications </span></b><span data-ccp-props="{&quot;201341983&quot;:0,&quot;335559739&quot;:160,&quot;335559740&quot;:279}"> </span></h3>
<span data-contrast="auto">Windows is an open and versatile platform that supports a wide range of UI technologies. If you are looking to develop native Windows applications using our preferred UI development language, XAML, we recommend using either WinUI 3 or WPF.</span><span data-ccp-props="{&quot;201341983&quot;:0,&quot;335559739&quot;:160,&quot;335559740&quot;:279}"> </span>

<span data-contrast="auto">WinUI 3 includes a modern native compositor and excels at media and graphics-focused consumer and commercial applications. WPF has a longer history and can take advantage of a deep ecosystem of commercial products as well as free and open source projects, many of which are focused on enterprise and data-intensive scenarios. We recommend you first consider WinUI 3, and if that meets your app’s  needs, proceed with it for the most modern experience. Otherwise, WPF is an excellent choice. Both WinUI 3 and WPF can take advantage of all Windows has to offer, including the new features and APIs in the Windows App SDK, so you can feel confident in creating a modern application in either technology.</span><span data-ccp-props="{&quot;201341983&quot;:0,&quot;335559739&quot;:160,&quot;335559740&quot;:279}"> </span>
<h3><b><span data-contrast="auto">WinUI 3 and Windows App SDK now support native Maps control and .NET 8 </span></b><span data-ccp-props="{&quot;134245418&quot;:true,&quot;134245529&quot;:true,&quot;201341983&quot;:0,&quot;335559738&quot;:160,&quot;335559739&quot;:80,&quot;335559740&quot;:279}"> </span></h3>
<span data-contrast="auto">With the latest updates to Windows App SDK 1.5+ we shipped several developer-requested features including support for .NET 8, with its faster startup, smaller footprint, and new runtime features. We’ve also brought to WinUI 3 one of the most requested features, the Maps control, powered by WebView 2 and Azure Maps. You can learn more about the controls and features in WinUI 3 in the interactive </span><a href="https://www.microsoft.com/store/productId/9P3JFPWWDZRC?ocid=pdpshare"><span data-contrast="none">WinUI 3 Gallery App</span></a><span data-ccp-props="{&quot;201341983&quot;:0,&quot;335559739&quot;:160,&quot;335559740&quot;:279}"> </span>

<span data-contrast="auto">Microsoft apps like Photos and File Explorer have migrated to WinUI3 along with developers like Apple (Apple TV, Apple Music, iCloud, Apple Devices) and Yair A (Files App), who are also adopting WinUI 3.</span><span data-ccp-props="{&quot;201341983&quot;:0,&quot;335559739&quot;:160,&quot;335559740&quot;:279}"> </span>
<h3><b><span data-contrast="auto">Windows 11 theme support makes it easy to modernize the look and feel of your WPF applications</span></b><span data-ccp-props="{&quot;134245418&quot;:true,&quot;134245529&quot;:true,&quot;201341983&quot;:0,&quot;335559738&quot;:160,&quot;335559739&quot;:80,&quot;335559740&quot;:279}"> </span></h3>
<span data-contrast="auto">WPF is popular, especially for data-heavy and enterprise apps. We listened to your feedback and are committed to continuing investments in WPF. With the latest updates to WPF, we have made it easier than ever to modernize the look and feel of your app through support for Windows 11 theming. We also improved integration with Windows by including a native FolderBrowserDialog and managed DWrite.</span><span data-ccp-props="{&quot;201341983&quot;:0,&quot;335559739&quot;:160,&quot;335559740&quot;:279}"> </span>

<span data-contrast="auto">Developers, including Morgan Stanley and Reincubate</span><b><span data-contrast="auto">, </span></b><span data-contrast="auto">have created great apps that showcase what can be built using WPF. </span><span data-ccp-props="{&quot;201341983&quot;:0,&quot;335559739&quot;:160,&quot;335559740&quot;:279}"> </span>

<span data-contrast="auto">Our updated </span><a href="https://developer.microsoft.com/windows/"><span data-contrast="none">Windows Dev Center</span></a><span data-contrast="auto"> includes information on both WinUI3 and WPF to help you make the best decision for your application. </span><span data-ccp-props="{&quot;201341983&quot;:0,&quot;335559739&quot;:160,&quot;335559740&quot;:279}"> </span>
<h3><b><span data-contrast="auto">Extend Windows apps into 3D space</span></b><span data-ccp-props="{&quot;201341983&quot;:0,&quot;335559739&quot;:160,&quot;335559740&quot;:259}"> </span></h3>
<span data-contrast="auto">As Windows transforms for the era of AI we are continuing to expand the reach of the platform including all the AI experiences developers create with the Windows Copilot Runtime. We are delivering Windows from the cloud with Windows 365 so apps can reach any device, anywhere. And we are introducing Windows experiences to new form factors beyond the PC. </span><span data-ccp-props="{&quot;201341983&quot;:0,&quot;335559739&quot;:160,&quot;335559740&quot;:259}"> </span>

<span data-contrast="auto">For example, we are deepening our partnership with Meta to make Windows a first-class experience on Quest devices. And Windows can take advantage of Quest’s unique capabilities to extend Windows apps into 3D space. We call these Volumetric apps. Developers will have access to a volumetric API. This is just one of many ways to broaden your reach through the Windows ecosystem.</span><span data-ccp-props="{&quot;201341983&quot;:0,&quot;335559739&quot;:160,&quot;335559740&quot;:259}"> </span>
<h3><b><span data-contrast="none">Building for the future of AI</span></b> <b><span data-contrast="none">on Windows</span></b><span data-ccp-props="{&quot;201341983&quot;:0,&quot;335559739&quot;:160,&quot;335559740&quot;:279}"> </span></h3>
<span data-contrast="none">This past year has been incredibly exciting as we reimagined the Windows PC in this new era of AI. But this is just the start of our journey. With the most efficient and performant Windows PCs ever built, powered by the game-changing NPU technology, and an OS with AI at its core, we have listened to your feedback and worked to make Windows the very best platform for developers. </span><span data-ccp-props="{&quot;201341983&quot;:0,&quot;335559739&quot;:160,&quot;335559740&quot;:279}"> </span>

<span data-contrast="none">We look forward to continuing to partner with you, our developer and MVP community, to bring innovation to our platform and tools, and enabling each of you to create future AI experiences that will empower every person on the planet to achieve more. We can’t wait to see what you will build next. </span><span data-ccp-props="{&quot;201341983&quot;:0,&quot;335559739&quot;:160,&quot;335559740&quot;:279}"> </span>

<span class="ui-provider a b c d e f g h i j k l m n o p q r s t u v w x y z ab ac ae af ag ah ai aj ak" dir="ltr">Editor's note, May 21, 2024: This post was updated to reflect the latest product information on Snapdragon Dev Kit for Windows.</span>

<strong>Disclaimers</strong><span data-ccp-props="{&quot;201341983&quot;:0,&quot;335559739&quot;:160,&quot;335559740&quot;:279}"> </span>

<i><span data-contrast="auto">1 Tested April 2024 using debug application for Windows Studio Effects workload comparing pre-release Copilot+ PC builds with Snapdragon Elite X 12 Core to Windows 11 PC with Intel 12th gen i7 configuration</span></i><span data-ccp-props="{&quot;201341983&quot;:0,&quot;335559739&quot;:160,&quot;335559740&quot;:279}"> </span>

<i><span data-contrast="auto">2 Tested April 2024 using Phi SLM workload running 512-token prompt processing in a loop with default settings comparing pre-release Copilot+ PC builds with Snapdragon Elite X 12 Core and Snapdragon X Plus 10 core configurations (QNN build) to Windows 11 PC with NVIDIA 4080 GPU configuration (CUDA build).</span></i><span data-ccp-props="{&quot;201341983&quot;:0,&quot;335559739&quot;:160,&quot;335559740&quot;:279}"> </span>

<i><span data-contrast="auto">3 Optimized for select languages (English, Chinese (simplified), French, German, Japanese, and Spanish.) Content-based and storage limitations apply. See [</span></i><span data-contrast="none">aka.ms/copilotpluspcs</span><i><span data-contrast="auto">].</span></i><span data-ccp-props="{&quot;201341983&quot;:0,&quot;335559739&quot;:160,&quot;335559740&quot;:279}"> </span>

<i><span data-contrast="auto">4 </span></i><span data-contrast="auto">Optimized for English text prompts. See aka.ms/copilotpluspcs.</span><span data-ccp-props="{&quot;201341983&quot;:0,&quot;335559739&quot;:160,&quot;335559740&quot;:279}"> </span>]]></content:encoded>
					
		
		
			</item>
		<item>
		<title>Microsoft App Assure helps Opera build Arm-optimized browser</title>
		<link>https://blogs.windows.com/windowsdeveloper/2024/05/16/microsoft-app-assure-helps-opera-build-arm-optimized-browser/</link>
		
		<dc:creator><![CDATA[Mike Adams, Corporate Vice President, Customer Experience Engineering]]></dc:creator>
		<pubDate>Thu, 16 May 2024 16:00:04 +0000</pubDate>
				<category><![CDATA[Windows Developers]]></category>
		<category><![CDATA[App Assure]]></category>
		<category><![CDATA[ARM]]></category>
		<category><![CDATA[browser]]></category>
		<category><![CDATA[Developers]]></category>
		<category><![CDATA[opera]]></category>
		<guid isPermaLink="false">https://blogs.windows.com/windowsdeveloper/?p=56961</guid>

					<description><![CDATA[<p>The Microsoft App Assure team helps app developers around the world to ensure their users have top-notch experience on all Microsoft platforms. Today, I want to highlight one of our many successful engagements: the new Opera Browser for Arm-based Win</p>
<p>The post <a href="https://blogs.windows.com/windowsdeveloper/2024/05/16/microsoft-app-assure-helps-opera-build-arm-optimized-browser/">Microsoft App Assure helps Opera build Arm-optimized browser</a> appeared first on <a href="https://blogs.windows.com/windowsdeveloper">Windows Developer Blog</a>.</p>
]]></description>
										<content:encoded><![CDATA[The Microsoft App Assure team helps app developers around the world to ensure their users have top-notch experience on all Microsoft platforms. Today, I want to highlight one of our many successful engagements: the new Opera Browser for Arm-based Windows devices. In May, an Arm-optimized version of Opera for Windows was made available on the <a href="https://www.opera.com/browsers/opera/developer">developer stream</a> of the browser. Engineering assistance from the Microsoft App Assure team played a key role in this effort.

The App Assure program delivers on Microsoft’s application compatibility promise: your apps will run on Windows on Arm, and if you encounter any issues, Microsoft will help you remediate them. This no-cost program has a proven track record helping over 300 market-leading developers build Arm-optimized apps for Windows. With the recent worldwide release of our <a href="https://blogs.windows.com/windowsdeveloper/2024/03/13/announcing-worldwide-availability-of-arm-advisory-service-for-developers/">Arm Advisory Service</a>, more developers than ever before have been turning to App Assure for guidance.

We continue to see excitement in the market for the coming wave of Windows PCs based on the Qualcomm Snapdragon X Elite platform. These new devices feature powerful on-device AI capability, which will herald a new age of groundbreaking AI features. As with all Arm-based Windows devices, they offer fast connectivity, extended battery life, best-in-class performance, advanced camera capabilities, along with many other benefits.
<h4>Porting to Windows Arm is easy</h4>
Windows users expect their favorite apps to work great on Arm-based PCs. To meet this expectation, App Assure engages with the most popular apps, such as the Opera Browser, helping them optimize for the platform. App Assure engineers worked directly with Opera’s engineering team, offering technical assistance and guidance. It quickly became apparent that both teams had a similar take on strong signals reflecting growing industry awareness of the performance and efficiency benefits offered by Arm devices.

<img class="alignnone size-full wp-image-56964" src="https://blogs.windows.com/wp-content/uploads/prod/sites/3/2024/05/App-Assure-Opera-Screen-Shot-With-Shadow.jpg" alt="Screenshot of the Opera browser" width="1000" height="714" />

“Windows is our biggest audience, so it is very important for us to deliver a seamless experience on all Windows devices,” said Bartosz Wiklak, head of QA and Automation at Opera. “We had been seeing increased market excitement about the future of Arm-based PCs for some time. When the App Assure team got in touch with us, we decided it was a great time to start focusing on it. We always aim to be at the forefront of the adoption curve and offer more options for our customers.”

Through a series of technical workshops, App Assure engineers met with Opera engineers to discuss the nuts and bolts of optimizing for Arm. These in-depth sessions provided a deep dive into the intricacies of Arm's architecture, covering details that go beyond simple cross-platform build configuration or signing multi-architecture app bundles. App Assure engineers also provided technical documentation to further Opera’s understanding of Windows on Arm. This work helped lay the foundation for a version of Opera that is not only compatible with Arm devices, but also takes advantage of the best-in-class performance offered by these devices.

“Our experience developing for other Arm platforms was that it took quite a bit of work, so we were initially concerned about the time commitment. But when we looked deeper into it, we found out that a lot of the porting work had already been done in the Chromium project for the Arm-native release of Microsoft Edge. So, it was a very smooth process. We produced a first build in just a few days.” said Wiklak. “Once the builds passed quality bar, we benchmarked optimized browser using Speedometer, a widely popular benchmark for web browsers. We were really pleased that the score was more than double when compared to emulated version.” The Arm-optimized version of Opera will be first available on the <a href="https://www.opera.com/browsers/opera/developer">developer stream</a> of the browser, allowing early adopters to try it out on Arm-based Windows devices.

<img class="alignnone size-large wp-image-56965" src="https://blogs.windows.com/wp-content/uploads/prod/sites/3/2024/05/Designed-quote_Bartosz-Opera-1-1024x224.jpg" alt="Developer quote and thumbnail photo" width="1024" height="224" />
<h4>App Assure helps developers unlock potential</h4>
We are confident that Windows on Arm is going to revolutionize personal computing, and we are excited to offer App Assure to Windows on Arm developers to help all organizations see just how easy it is to build for this platform.

If you’d like to know more about how to add Arm support to your Windows app, check out the <a href="http://aka.ms/win/arm/howto">technical documentation</a>.

Once you’re ready to begin your porting journey, Microsoft’s Arm Advisory Service can provide detailed insights into platform features, best practices and code examples. For example, App Assure engineers can help you:
<ul>
 	<li>Understand the nuances of emulated code translation and how to seamlessly interoperate between native and x64 code.</li>
 	<li>Configure build systems most efficiently for multi-architecture delivery.</li>
 	<li>Obtain Arm-based hardware or get started with Azure Virtual Machines and then prepare those environments for development, continuous integration, or test runners.</li>
</ul>
If this sounds like something you’re interested in, <a href="https://aka.ms/AppAssureServicesForm">reach out to us by completing this form</a>.]]></content:encoded>
					
		
		
			</item>
		<item>
		<title>Part 3 – Babylon.js 7.0: One incredible community</title>
		<link>https://blogs.windows.com/windowsdeveloper/2024/04/11/part-3-babylon-js-7-0-one-incredible-community/</link>
		
		<dc:creator><![CDATA[Steve Clarke, Editor]]></dc:creator>
		<pubDate>Thu, 11 Apr 2024 17:01:42 +0000</pubDate>
				<category><![CDATA[Uncategorized]]></category>
		<guid isPermaLink="false">https://blogs.windows.com/windowsdeveloper/?p=56955</guid>

					<description><![CDATA[<p>Babylon.js is powered and supported by one of the most incredible open source communities in the world. Over 500 people from across the globe have contributed to making it one of the most powerful, beautiful, simple, and open web rendering engines ou</p>
<p>The post <a href="https://blogs.windows.com/windowsdeveloper/2024/04/11/part-3-babylon-js-7-0-one-incredible-community/">Part 3 – Babylon.js 7.0: One incredible community</a> appeared first on <a href="https://blogs.windows.com/windowsdeveloper">Windows Developer Blog</a>.</p>
]]></description>
										<content:encoded><![CDATA[Babylon.js is powered and supported by one of the most incredible open source communities in the world. Over 500 people from across the globe have contributed to making it one of the most powerful, beautiful, simple, and open web rendering engines out there. With Babylon.js 7.0, this community continues to shine bright, by adding some incredible new features and extensions to this passionately shared and nurtured platform.
<h3><strong>The Greased Line</strong></h3>
Built right into the core engine, the new Greased Line system unlocks some exciting new possibilities for web creators. This new special type of line is built using the mesh system to display lines of any specified width. The extra sprinkling of non-trademarked fantasy dust is that these lines are equipped with a special shader that allows the line to always face the camera so they can be viewed consistently no matter where the camera moves to.

See it in action: <a href="https://aka.ms/babylon7GLDemo">https://aka.ms/babylon7GLDemo</a>

Learn more: <a href="https://aka.ms/babylon7GLDoc">https://aka.ms/babylon7GLDoc</a>

https://youtu.be/SEUsue6nAGU
<h3><strong>Advanced Ground Projection</strong></h3>
This one is honestly just too cool to put into words, but we’ll do our best. Imagine taking a 360 skybox/environment and then magically transforming the lower half into a “fake” ground that seems to support the 3D objects in your scene. This illusion provides a perfectly smooth transition from the ground to the sky within your scene. Sound like wizardry? Well what are you waiting for? Check it out!

See it in action: <a href="https://aka.ms/babylon7GProjDemo">https://aka.ms/babylon7GProjDemo</a>

Learn more: <a href="https://aka.ms/babylon7GProjDoc">https://aka.ms/babylon7GProjDoc</a>

https://youtu.be/FtiaFVKPjco
<h3><strong> </strong><strong>Seamless Texture Decals</strong></h3>
Introduced with Babylon.js 6.0, texture decals offered a powerful new option of projecting images onto an existing texture of a 3D object in your scene. With Babylon.js 7.0, that same system is given superpowers by allowing the decals to seamlessly map across UV boundaries! That means that no matter how pretty or less-pretty your UV layout might be, decals will work perfectly on any 3D object!

Check it out: <a href="https://aka.ms/babylon7SeamTsDemo">https://aka.ms/babylon7SeamTsDemo</a>

Learn more: <a href="https://aka.ms/babylon7SeamTsDoc">https://aka.ms/babylon7SeamTsDoc</a>

https://youtu.be/BiIXrO40XgI
<h3><strong>MMD Support Community Extension</strong></h3>
This exciting extension to Babylon.js 7.0 offers creators the ability to import 3D assets and animations from the popular 3D Creation Software: <a href="https://mikumikudance.en.softonic.com/">MikuMikuDance</a> or MMD for short. In addition to loading assets and animations, it also has support for IK solvers, a morph system, synced audio playback, player controls, and much much more.

Check it out: <a href="https://aka.ms/babylon7MMDDemo">https://aka.ms/babylon7MMDDemo</a>

Learn more here: <a href="https://aka.ms/babylon7MMDDoc">https://aka.ms/babylon7MMDDoc</a>

https://youtu.be/KFBO-zm-9mo
<h3><strong>Thank You</strong></h3>
With each evolution of Babylon.js comes a revolution in web rendering technology and an overwhelming feeling of gratitude. The Babylon platform simply wouldn’t be possible without the incredible community of developers, the 500+ contributors, and the steadfast advocates that contribute their knowledge, expertise, help, and passion to this amazing technology. “Thank you” to each one of you for all that you do to help make Babylon.js one of the most powerful, beautiful, simple, and open web rendering platforms in the world.]]></content:encoded>
					
		
		
			</item>
		<item>
		<title>Part 1 – Announcing Babylon.js 7.0</title>
		<link>https://blogs.windows.com/windowsdeveloper/2024/03/28/part-1-announcing-babylon-js-7-0/</link>
		
		<dc:creator><![CDATA[Thomas Lucchini]]></dc:creator>
		<pubDate>Thu, 28 Mar 2024 20:15:14 +0000</pubDate>
				<category><![CDATA[Uncategorized]]></category>
		<guid isPermaLink="false">https://blogs.windows.com/windowsdeveloper/?p=56949</guid>

					<description><![CDATA[<p>Our mission is to build one of the most powerful, beautiful, simple, and open web rendering engines in the world, and we are excited to announce that mission takes another step forward today, with Babylon.js 7.0.</p>
<p>https://youtu.be/5V07vm5u74Q</p>
<p>Babylo</p>
<p>The post <a href="https://blogs.windows.com/windowsdeveloper/2024/03/28/part-1-announcing-babylon-js-7-0/">Part 1 – Announcing Babylon.js 7.0</a> appeared first on <a href="https://blogs.windows.com/windowsdeveloper">Windows Developer Blog</a>.</p>
]]></description>
										<content:encoded><![CDATA[Our mission is to build one of the most powerful, beautiful, simple, and open web rendering engines in the world, and we are excited to announce that mission takes another step forward today, with Babylon.js 7.0.

https://youtu.be/5V07vm5u74Q

Babylon.js 7.0 is a <a href="https://aka.ms/bayblon7Celebration">celebration</a> of a year’s worth of new features, optimizations, and performance improvements that unlock new capabilities for web developers everywhere.

So, let’s dive in and see what new goodness awaits you.
<h3><strong>Procedural Geometry (Node Geometry)</strong></h3>
We are absolutely thrilled to announce that Babylon.js now features procedural geometry. We call it “Node Geometry.” An advanced system that allows you to create procedural geometry using a non-destructive node tree system.

If you’re already familiar with Babylon’s <a href="https://doc.babylonjs.com/features/featuresDeepDive/materials/node_material">Node Material</a> and the <a href="https://nme.babylonjs.com/">Node Material Editor (NME)</a>, then you’ll feel right at home in the <a href="https://nge.babylonjs.com/">Node Geometry Editor</a>. This simple to use tool lets you assemble a non-destructive geometry tree, allowing you to create anything from tiny geometric variations to entire procedural worlds/landscapes.

Procedural geometry offers the ability to create complex geometry at run/build time. This means that the end-user doesn’t have to download large 3D assets. Instead, the local machines/devices can use the CPU to create those assets. This means rather than requiring your web visitors to download hundreds of MBs worth of 3D assets, they can instead download a few KBs worth of Node Geometry data and allow their own machine to create the geometry. This adds a tremendous layer of flexibility for creators to offer the perfect loading/performance optimization for their unique web experience!

There’s really no better way to experience all that Node Geometry will offer other than for you to dive in and try it out yourself!

Try it out yourself: <a href="https://nge.babylonjs.com/">Node Geometry Editor</a>

Check out a demo: <a href="https://aka.ms/babylon7NgeDemo">https://aka.ms/babylon7NgeDemo</a>

Learn more: <a href="https://aka.ms/babylon7NgeDoc">https://aka.ms/babylon7NgeDoc</a>

https://youtu.be/gqvHzjaHvPM
<h3><strong>Global Illumination</strong></h3>
Empowering web creators to conjure up more beautiful and immersive experiences is a foundational part of the Babylon Mission. With Babylon.js 7.0, we are excited to introduce support for basic Global Illumination. This highly desired and advanced feature allows Babylon.js scenes to render even more lifelike experiences by allowing light and shadows to “bounce” around environments in a way that much closer matches reality.

Global Illumination represents a major advancement in web rendering and, just like everything that comes with Babylon.js 7.0, is completely free and open source. To truly appreciate the beauty this adds to scenes, you just need to check it out.

Global Illumination demo: <a href="https://aka.ms/babylon7GIDemo">https://aka.ms/babylon7GIDemo</a>

Learn more here: <a href="https://aka.ms/babylon7GIDoc">https://aka.ms/babylon7GIDoc</a>

https://youtu.be/r0QteNkE88s
<h3><strong>Gaussian Splat Rendering</strong></h3>
<a href="https://en.wikipedia.org/wiki/Gaussian_splatting">Gaussian Splatting</a> is a new technique to capture and display volumetric data using <a href="https://en.wikipedia.org/wiki/Neural_radiance_field">Neural Radiance Fields</a>, point clouds and billboards. In more simple terms, it’s an advanced way of allowing people to capture and display the real world with a level of unmatched visual fidelity and performance.

Babylon.js 7.0 adds support for rendering Gaussian Splats on the web, across all devices, running at 60 fps!

Try it out: <a href="https://aka.ms/babylon7GSplatDemo">https://aka.ms/babylon7GSplatDemo</a>

Learn more here: <a href="https://aka.ms/babylon7GSplatDoc">https://aka.ms/babylon7GSplatDoc</a>

https://youtu.be/JuNfLFPc7Ok
<h3><strong>Ragdoll Physics</strong></h3>
Babylon.js 7.0 builds on the momentum (see what we did there?) of Havok physics support in Babylon, by adding support for ragdoll animation. This allows any skeletal rigged asset to collapse and flop around with limp lifelessness at the push of a button. What are you waiting for? Try it out!

Try it here: <a href="https://aka.ms/babylon7RagdollDemo">https://aka.ms/babylon7RagdollDemo</a>

Learn more here: <a href="https://aka.ms/babylon7RagdollDoc">https://aka.ms/babylon7RagdollDoc</a>

https://youtu.be/w1eR7IYqDWY

Those are just some of the main features of Babylon.js 7.0, there is much more! Tune in for next posts and learn more about WebXR, glTF and animation advancements, up to the incredible contributions from the community.<strong>
</strong>]]></content:encoded>
					
		
		
			</item>
		<item>
		<title>Announcing worldwide availability of Arm Advisory Service for developers</title>
		<link>https://blogs.windows.com/windowsdeveloper/2024/03/13/announcing-worldwide-availability-of-arm-advisory-service-for-developers/</link>
		
		<dc:creator><![CDATA[Mike Adams, Corporate Vice President, Customer Experience Engineering]]></dc:creator>
		<pubDate>Wed, 13 Mar 2024 13:05:43 +0000</pubDate>
				<category><![CDATA[Uncategorized]]></category>
		<guid isPermaLink="false">https://blogs.windows.com/windowsdeveloper/?p=56946</guid>

					<description><![CDATA[<p>In October 2023, Microsoft introduced the <a href="https://blogs.windows.com/windowsdeveloper/2023/10/16/windows-launching-arm-advisory-service-for-developers/">Arm Advisory Service</a>. Since then, interest has risen steeply. This is no surprise, as</p>
<p>The post <a href="https://blogs.windows.com/windowsdeveloper/2024/03/13/announcing-worldwide-availability-of-arm-advisory-service-for-developers/">Announcing worldwide availability of Arm Advisory Service for developers</a> appeared first on <a href="https://blogs.windows.com/windowsdeveloper">Windows Developer Blog</a>.</p>
]]></description>
										<content:encoded><![CDATA[In October 2023, Microsoft introduced the <a href="https://blogs.windows.com/windowsdeveloper/2023/10/16/windows-launching-arm-advisory-service-for-developers/">Arm Advisory Service</a>. Since then, interest has risen steeply. This is no surprise, as many across the industry consider Windows on Arm devices as the future of computing, with unparalleled speed, battery life, and connectivity. Our no-cost engineering advisory program has a proven track record helping developers build Arm-optimized apps for Windows.

With all the momentum around the growing ecosystem, I’m very excited to announce that we are officially expanding the service to developers around the world. We now offer:
<ul>
 	<li>More languages: Support is now provided in English, Chinese (simplified, traditional), and Japanese.</li>
 	<li>More availability: We’re open during business hours in your local time zone, wherever you are.</li>
 	<li>More regions: Our expansion covers all regions worldwide.</li>
</ul>
To get started with the Arm Advisory Service, <a href="https://aka.ms/AppAssureServicesForm">please fill out this form.</a>
<h3><strong>The Arm Advisory Service now helps developers around the world</strong></h3>
With the coming release of Qualcomm's Snapdragon X Elite platform, Microsoft’s hardware partners will release a broad spectrum of devices across many form factors and price points. These devices will showcase a new generation of AI capabilities, empowering the next wave of app innovation. Developers have an opportunity to participate in this growing ecosystem by ensuring their apps take advantage of the unique benefits of Arm-based devices.

The Arm Advisory Service has been instrumental in helping developers get started. With our expanded services, it’s easier than ever to get helpful guidance from our App Assure team who are ready and available to assist you in creating, porting, debugging, or enhancing your apps. If you’ve been waiting for the right time to develop for Arm on Windows, with our expanded support, your time is now! Know that we are here to help you, with:
<ul>
 	<li>Best practices, guidance, and implementation support</li>
 	<li>Suggestions on platform features</li>
 	<li>Code samples and reviews</li>
 	<li>Break-fix assistance</li>
 	<li>An escalation path to Microsoft engineers</li>
</ul>
<h3><strong>Featured ISV engagements</strong></h3>
Curious what it’s like to work with us? Check out these examples and feedback from some of the developers we’ve helped.

<strong>Lenovo China</strong>

<em>Since we are new to the Arm platform, we are deeply grateful for Microsoft Arm adaptation support. The service helped us quickly transition to the new technology, which effectively improved product scalability. In particular, we appreciate the excellent problem-solving support - whenever we have any difficulties or questions, we receive quick, effective help. Thank you for your assistance and we look forward to even greater success in our future cooperation.</em>

-          <em>PC Product Manager</em>

<strong>NordVPN</strong>

<em>We knew we wanted to develop a Windows on Arm solution but at first it looked daunting, with so many possible paths for migrating apps to Windows. But as it turns out, our biggest decision was choosing to go with native Arm and kicking off the project. Once we started working with the App Assure team, everything looked a lot simpler. Their advice was just what we needed to move ahead.</em>

-          <em>Head of Engineering, Windows platform</em>

The App Assure team has provided the Arm Advisory Service to help many ISVs, including:

<img class="alignnone wp-image-56948 size-large" src="https://blogs.windows.com/wp-content/uploads/prod/sites/3/2024/03/Logos_final-1024x255.png" alt="Eleven company logos" width="1024" height="255" />

<em>The DELL TECHNOLOGIES logo is a trademark of Dell Inc.</em>
<h3><strong>We’re in your corner</strong></h3>
Working with developers focused on Windows apps on Arm is just one of the ways the App Assure <a href="https://www.youtube.com/watch?v=IM_zz9S0XCs">Arm Advisory Service</a> supports the Windows app community. We regularly collaborate with first- and third-party software vendors to help ensure smoother run time, greater stability, expanded app abilities, and greater protection from security threats.

The goal: making sure your apps work on the latest software. It’s all about solving problems, removing hurdles, and ultimately, ensuring your end users have the experiences they’re counting on.
<h3><strong>Windows on Arm just makes sense</strong></h3>
Unprecedented battery life and energy efficiency. High performance. Light weight design that’s perfect for on-the-go. Arm devices offer compelling options for users, and 2024 promises to be a very exciting year for developers who want to take advantage of this market opportunity.

If this sounds like something you’re interested in, I encourage you to reach out to explore how we can help. <a href="https://aka.ms/AppAssureServicesForm">Complete this form</a> and our App Assure team will reach out to you. We look forward to working together to help you deliver amazing solutions for your customers.]]></content:encoded>
					
		
		
			</item>
		<item>
		<title>Sandboxing Python with Win32 App Isolation </title>
		<link>https://blogs.windows.com/windowsdeveloper/2024/03/06/sandboxing-python-with-win32-app-isolation/</link>
		
		<dc:creator><![CDATA[Tian Gao]]></dc:creator>
		<pubDate>Wed, 06 Mar 2024 22:25:15 +0000</pubDate>
				<category><![CDATA[Uncategorized]]></category>
		<guid isPermaLink="false">https://blogs.windows.com/windowsdeveloper/?p=56923</guid>

					<description><![CDATA[<p><span data-contrast="auto">Sandboxing Python can be very useful for developers but has been challenging due to the flexibility of CPython implementation. It is particularly useful in many scenarios to have sandboxed Python.  For example, on any webs</p>
<p>The post <a href="https://blogs.windows.com/windowsdeveloper/2024/03/06/sandboxing-python-with-win32-app-isolation/">Sandboxing Python with Win32 App Isolation </a> appeared first on <a href="https://blogs.windows.com/windowsdeveloper">Windows Developer Blog</a>.</p>
]]></description>
										<content:encoded><![CDATA[<span data-contrast="auto">Sandboxing Python can be very useful for developers but has been challenging due to the flexibility of CPython implementation. It is particularly useful in many scenarios to have sandboxed Python.  For example, on any website that needs to execute arbitrary code from users, like coding practice sites or online interpreters. It could also be useful to help prevent increasing attacks on LLMs (Large Language Models).</span><span data-ccp-props="{&quot;201341983&quot;:0,&quot;335559739&quot;:160,&quot;335559740&quot;:279}"> </span>

<span data-contrast="auto">Win32 App Isolation (https://github.com/microsoft/win32-app-isolation) lights up a different path to sandboxing Python – not on a Python library level, but on an application/OS level.</span><span data-ccp-props="{&quot;201341983&quot;:0,&quot;335559739&quot;:160,&quot;335559740&quot;:279}"> </span>

<span data-contrast="auto">Win32 App Isolation is designed to isolate Win32 application by creating a security boundary between the application and the OS, using the combination of AppContainer, virtualized resources and brokering file system, which helps to prevent the application from compromising the operating system.</span><span data-ccp-props="{&quot;201341983&quot;:0,&quot;335559739&quot;:160,&quot;335559740&quot;:279}"> </span>

<span data-contrast="auto">Following are the specifics requirements and guidance for sandboxing</span> <span data-contrast="auto">CPython with Win32 App Isolation on recent Windows Insider releases. It takes about 30-60 minutes and anyone with the insider version of Windows can do it on their local machine.</span><span data-ccp-props="{&quot;201341983&quot;:0,&quot;335559739&quot;:160,&quot;335559740&quot;:279}"> </span>

<span data-contrast="auto">To use Win32 App Isolation, you need the insider version of Windows with version number &gt; 25357, and the MSIX Packaging Tool from https://github.com/microsoft/win32-app-isolation/releases/</span><span data-ccp-props="{&quot;201341983&quot;:0,&quot;335559739&quot;:160,&quot;335559740&quot;:279}"> </span>

<span data-contrast="auto">Step One:</span><span data-ccp-props="{&quot;201341983&quot;:0,&quot;335559739&quot;:160,&quot;335559740&quot;:279}"> </span>

<span data-contrast="auto">Download the Python installer for Windows from python.org. 3.12.2 was used for this specific example.</span><span data-ccp-props="{&quot;201341983&quot;:0,&quot;335559739&quot;:160,&quot;335559740&quot;:279}"> </span>

<span data-contrast="auto">Step Two:</span><span data-ccp-props="{&quot;201341983&quot;:0,&quot;335559739&quot;:160,&quot;335559740&quot;:279}"> </span>

<span data-contrast="auto">Package it by following the documentation (</span><a href="https://github.com/microsoft/win32-app-isolation/blob/main/docs/packaging/msix-packaging-tool.md"><span data-contrast="none">https://github.com/microsoft/win32-app-isolation/blob/main/docs/packaging/msix-packaging-tool.md</span></a><span data-contrast="auto">). You may need a certificate to sign the package to install it (https://learn.microsoft.com/en-us/windows/msix/packaging-tool/create-app-package#signing-preference).</span><span data-ccp-props="{&quot;201341983&quot;:0,&quot;335559739&quot;:160,&quot;335559740&quot;:279}"> </span>

<span data-contrast="auto">Add <code class="EnlighterJSRAW" data-enlighter-language="generic">isolatedWin32-PromptForAccess </code></span><span data-contrast="auto">capability for demonstration purposes, so you can allow it to access certain resources in prompts. Without the capability, all access to the user files that are not explicitly set to be available to the application would be denied.</span><span data-ccp-props="{&quot;201341983&quot;:0,&quot;335559739&quot;:160,&quot;335559740&quot;:279}"> </span>

<span data-contrast="auto">Add an alias <code class="EnlighterJSRAW" data-enlighter-language="generic">python3.12.exe </code></span><span data-contrast="auto">to use it from PowerShell.</span><span data-ccp-props="{&quot;201341983&quot;:0,&quot;335559739&quot;:160,&quot;335559740&quot;:279}"> </span>

<span data-contrast="auto">Step Three:</span><span data-ccp-props="{&quot;201341983&quot;:0,&quot;335559739&quot;:160,&quot;335559740&quot;:279}"> </span>

<span data-contrast="auto">Install the package. Use the defined alias <code class="EnlighterJSRAW" data-enlighter-language="generic">python3.12.exe</code> </span><span data-contrast="auto">in PowerShell to bring up the Python interpreter.</span><span data-ccp-props="{&quot;201341983&quot;:0,&quot;335559739&quot;:160,&quot;335559740&quot;:279}"> </span>

<img class="alignnone wp-image-56928 size-full" src="https://blogs.windows.com/wp-content/uploads/prod/sites/3/2024/02/1.png" alt="A screenshot of a computer" width="624" height="355" />

<span data-contrast="auto">When starting the Python interpreter, it will prompt you to ask permission to the current working directory. Python itself would be brought up with either option – but this determines whether Python has access to the files in the current directory.</span><span data-ccp-props="{&quot;201341983&quot;:0,&quot;335559739&quot;:160,&quot;335559740&quot;:279}"> </span>

<span data-contrast="auto">For example, if you clicked “No” here, you would not be able to list the files in the current directory anymore:</span><span data-ccp-props="{&quot;201341983&quot;:0,&quot;335559739&quot;:160,&quot;335559740&quot;:279}"> </span>

<img class="alignnone wp-image-56930 size-full" src="https://blogs.windows.com/wp-content/uploads/prod/sites/3/2024/02/Picture2.png" alt="A screenshot of a computer" width="624" height="356" />

<span data-contrast="auto">The selection will be remembered so the application will only prompt once for any file/folder. The user can reset the file permissions in Settings – Privacy &amp; security – File system:</span><span data-ccp-props="{&quot;201341983&quot;:0,&quot;335559739&quot;:160,&quot;335559740&quot;:279}"> </span>

<span data-ccp-props="{&quot;201341983&quot;:0,&quot;335559739&quot;:160,&quot;335559740&quot;:279}"> <img class="alignnone wp-image-56931 size-full" src="https://blogs.windows.com/wp-content/uploads/prod/sites/3/2024/02/Picture3.png" alt="A screenshot of a computer" width="624" height="466" /></span>

<span data-contrast="auto">The Python interpreter should work well on its own given no code has been changed. </span><span data-ccp-props="{&quot;201341983&quot;:0,&quot;335559739&quot;:160,&quot;335559740&quot;:279}"> </span>

<img class="alignnone wp-image-56932 size-full" src="https://blogs.windows.com/wp-content/uploads/prod/sites/3/2024/02/Picture4.png" alt="A screenshot of a computer" width="624" height="356" />

<span data-contrast="auto">The more interesting aspects to check out are the “sandboxing” features – network and file system.</span><span data-ccp-props="{&quot;201341983&quot;:0,&quot;335559739&quot;:160,&quot;335559740&quot;:279}"> </span>

<span data-contrast="auto">But before that, try to execute a script using isolated Python.</span><span data-contrast="auto"> </span><span data-ccp-props="{&quot;201341983&quot;:0,&quot;335559739&quot;:160,&quot;335559740&quot;:279}"> </span>

<img class="alignnone wp-image-56933 size-full" src="https://blogs.windows.com/wp-content/uploads/prod/sites/3/2024/02/Picture5.png" alt="A screenshot of a computer" width="624" height="357" />

<span data-contrast="auto">As you are trying to access and execute a user file (the script), it will prompt for the access. If denied, the script will not run:</span><span data-ccp-props="{&quot;201341983&quot;:0,&quot;335559739&quot;:160,&quot;335559740&quot;:279}"> </span>

<img class="alignnone wp-image-56934 size-full" src="https://blogs.windows.com/wp-content/uploads/prod/sites/3/2024/02/Picture6.png" alt="A screenshot of a computer" width="624" height="357" />

<span data-contrast="auto">Allow it to review some examples, starting with network access.</span><span data-ccp-props="{&quot;201341983&quot;:0,&quot;335559739&quot;:160,&quot;335559740&quot;:279}"> </span>

<span data-contrast="auto">As you did not provide any network capabilities when packaging, Python will not have any access to the network. Confirm this by running this script:</span><span data-ccp-props="{&quot;201341983&quot;:0,&quot;335559739&quot;:160,&quot;335559740&quot;:279}"> </span>
<pre class="EnlighterJSRAW" data-enlighter-language="generic">def test_urllib(): 
    with urllib.request.urlopen(&quot;http://www.microsoft.com&quot;) as response: 
        print(response.read())</pre>
<img class="alignnone wp-image-56935 size-full" src="https://blogs.windows.com/wp-content/uploads/prod/sites/3/2024/02/Picture7.png" alt="A screenshot of a computer" width="624" height="355" />

<span data-contrast="auto">Also try to access the file system.</span><span data-ccp-props="{&quot;201341983&quot;:0,&quot;335559739&quot;:160,&quot;335559740&quot;:279}"> </span>
<pre class="EnlighterJSRAW" data-enlighter-language="generic">def test_open(): 
    with open(&quot;../data/test.txt&quot;, &quot;w&quot;) as f: 
        f.write(&quot;test&quot;)</pre>
<img class="alignnone wp-image-56936 size-full" src="https://blogs.windows.com/wp-content/uploads/prod/sites/3/2024/02/Picture8.png" alt="A screenshot of a computer" width="624" height="354" />

<span data-contrast="auto">A prompt was shown to request the access to the file to be written, and you can deny that access by clicking “No”</span><span data-ccp-props="{&quot;201341983&quot;:0,&quot;335559739&quot;:160,&quot;335559740&quot;:279}"> </span>

<img class="alignnone wp-image-56937 size-full" src="https://blogs.windows.com/wp-content/uploads/prod/sites/3/2024/02/Picture10.png" alt="A screenshot of a computer" width="624" height="354" />

<span data-contrast="auto">It will not work with the native APIs either:</span><span data-ccp-props="{&quot;201341983&quot;:0,&quot;335559739&quot;:160,&quot;335559740&quot;:279}"> </span>
<pre class="EnlighterJSRAW" data-enlighter-language="generic">def test_native(): 
    handle = ctypes.windll.kernel32.CreateFileW(&quot;../data/test.txt&quot;, 0x10000000, 0, None, 1, 0x80, 0) 
    if handle &gt; 0: 
        ctypes.windll.kernel32.CloseHandle(handle) 
    else: 
        raise RuntimeError(&quot;Failed to get the handle&quot;)</pre>
<img class="alignnone wp-image-56938 size-full" src="https://blogs.windows.com/wp-content/uploads/prod/sites/3/2024/02/Picture11.png" alt="A screenshot of a computer" width="624" height="356" />

<span data-contrast="auto">You can also test <code class="EnlighterJSRAW" data-enlighter-language="generic">os.system()</code></span><span style="background-color: #f9f9f9; font-family: 'Source Code Pro', 'Liberation Mono', 'Courier New', Courier, monospace; font-size: 0.7em;"> </span><span data-contrast="auto">and <code class="EnlighterJSRAW" data-enlighter-language="generic">subprocess</code></span><span data-contrast="auto">:</span><span data-ccp-props="{&quot;201341983&quot;:0,&quot;335559739&quot;:160,&quot;335559740&quot;:279}"> </span>
<pre class="EnlighterJSRAW" data-enlighter-language="generic">def test_os_system(): 
    os.system(&quot;powershell -command cat c:/data/test/bin/data/test.txt&quot;) 
def test_subprocess(): 
    subprocess.run([&quot;powershell&quot;, &quot;-command&quot;, &quot;cat&quot;, &quot;c:/data/test/bin/data/test.txt&quot;], shell=True)</pre>
<span data-ccp-props="{&quot;201341983&quot;:0,&quot;335559739&quot;:160,&quot;335559740&quot;:279}"><img class="alignnone wp-image-56939 size-full" src="https://blogs.windows.com/wp-content/uploads/prod/sites/3/2024/02/Picture12.png" alt="A screenshot of a computer" width="624" height="355" /></span>

<span data-contrast="auto">Importing modules by modifying <code class="EnlighterJSRAW" data-enlighter-language="generic">sys.path </code></span><span data-contrast="auto">will trigger the prompt too:</span><span data-ccp-props="{&quot;201341983&quot;:0,&quot;335559739&quot;:160,&quot;335559740&quot;:279}"> </span>
<pre class="EnlighterJSRAW" data-enlighter-language="generic">def test_import(): 
    sys.path.append(&quot;../data&quot;) 
    import example</pre>
<img class="alignnone wp-image-56940 size-full" src="https://blogs.windows.com/wp-content/uploads/prod/sites/3/2024/02/Picture13.png" alt="A screenshot of a computer" width="624" height="354" />

<span data-contrast="auto">Clicking “no” will deny the access to the module (<code class="EnlighterJSRAW" data-enlighter-language="generic">example.py</code></span><span data-contrast="auto">is in the data directory and clicking “yes” would successfully import it):</span><span data-ccp-props="{&quot;201341983&quot;:0,&quot;335559739&quot;:160,&quot;335559740&quot;:279}"> </span>

<span data-ccp-props="{&quot;201341983&quot;:0,&quot;335559739&quot;:160,&quot;335559740&quot;:279}"> <img class="alignnone wp-image-56941 size-full" src="https://blogs.windows.com/wp-content/uploads/prod/sites/3/2024/02/Picture14.png" alt="A screenshot of a computer" width="624" height="354" /></span>

<span data-contrast="auto">From the examples above, by introducing Win32 App Isolation you can help prevent Python from accessing the file system and the network without consent.</span><span data-ccp-props="{&quot;201341983&quot;:0,&quot;335559739&quot;:160,&quot;335559740&quot;:279}"> </span>

<span data-ccp-props="{&quot;201341983&quot;:0,&quot;335559739&quot;:160,&quot;335559740&quot;:279}"> </span>

<span data-contrast="auto">There are two obvious questions:</span><span data-ccp-props="{&quot;201341983&quot;:0,&quot;335559739&quot;:160,&quot;335559740&quot;:279}"> </span>
<ol>
 	<li>How can you “click” the prompts if you want to deploy this on your server? As mentioned above, <code class="EnlighterJSRAW" data-enlighter-language="generic">isolatedWin32-promptForAccess</code>is only added for demonstration purposes, and it is not needed for isolation. Without it, your system would simply deny any access to user files, thus helping to prevent attacks like ransomware.</li>
 	<li>Then how can you grant access to the application for required files like modules, scripts, and data? There are several ways to do it:<span style="font-size: min(max(16px, -0.70596px + 1rem + 0.1961vw), 20px);" data-ccp-props="{&quot;201341983&quot;:0,&quot;335559739&quot;:160,&quot;335559740&quot;:279}"> </span>
<ul>
 	<li>You can package the modules you need into your app, then they will be accessible by default.</li>
 	<li>You can put the file you need access to into the app’s profile in <code class="EnlighterJSRAW" data-enlighter-language="generic">%localappdata%</code> where the app is granted access automatically.</li>
 	<li>You can put the file to a “publisher directory”, which is any directory with a name ending with your app’s publisher ID in <code class="EnlighterJSRAW" data-enlighter-language="generic">c:\ProgramData</code>. (<a style="font-size: min(max(16px, -0.70596px + 1rem + 0.1961vw), 20px); background-color: #ffffff;" href="https://github.com/microsoft/win32-app-isolation/blob/main/docs/fundamentals/consent.md"><span data-contrast="none">win32-app-isolation/docs/fundamentals/consent.md at main · microsoft/win32-app-isolation (github.com)</span></a><span style="font-size: min(max(16px, -0.70596px + 1rem + 0.1961vw), 20px);" data-contrast="auto">)</span></li>
 	<li>You can set the access of files and directories with icalcs to allow your app or all apps to access them.</li>
</ul>
</li>
</ol>
<span data-contrast="auto">With the technology, the users can create much lighter solutions when they try to execute code from an untrusted source. Isolated Python can live in parallel with normal Python and perform as a low-privilege interpreter on the side. Or, with correct configuration, it can be used on its own which could help protect the system from being compromised while keeping all the functionalities from Python.</span><span data-ccp-props="{&quot;201341983&quot;:0,&quot;335559739&quot;:160,&quot;335559740&quot;:279}"> </span>]]></content:encoded>
					
		
		
			</item>
		<item>
		<title>Part 2 &#8211; Babylon.js 7.0: WebXR, glTF and animation advancement</title>
		<link>https://blogs.windows.com/windowsdeveloper/2024/03/04/part-2-babylon-js-7-0-webxr-gltf-and-animation-advancement/</link>
		
		<dc:creator><![CDATA[Steve Clarke, Editor]]></dc:creator>
		<pubDate>Mon, 04 Mar 2024 17:43:47 +0000</pubDate>
				<category><![CDATA[Uncategorized]]></category>
		<guid isPermaLink="false">https://blogs.windows.com/windowsdeveloper/?p=56953</guid>

					<description><![CDATA[<p>Our mission is to create one of the most powerful, beautiful, and simple web rendering engines in the world. The latest Babylon.js 7.0 engine packs a ton of new improvements to help you create stunning experiences.</p>
<h3><strong>State of Art WebXR Sup</p>
<p>The post <a href="https://blogs.windows.com/windowsdeveloper/2024/03/04/part-2-babylon-js-7-0-webxr-gltf-and-animation-advancement/">Part 2 &#8211; Babylon.js 7.0: WebXR, glTF and animation advancement</a> appeared first on <a href="https://blogs.windows.com/windowsdeveloper">Windows Developer Blog</a>.</p>
]]></description>
										<content:encoded><![CDATA[Our mission is to create one of the most powerful, beautiful, and simple web rendering engines in the world. The latest Babylon.js 7.0 engine packs a ton of new improvements to help you create stunning experiences.
<h3><strong>State of Art WebXR Support</strong></h3>
Babylon.js continues to support the full WebXR spec, making it as simple as possible to create incredibly immersive web experiences. With this release, Babylon.js 7.0 adds support for several new WebXR features including: full-screen GUI, touchable UI elements, world scale, antialiased multiviews, and the ability to use hands and controllers at the same time! If you are excited about creating immersive experiences on the web, then this version has your name on it!

Check it out: <a href="https://aka.ms/babylon7WebXRDemo">https://aka.ms/babylon7WebXRDemo</a>

Learn more here: <a href="https://aka.ms/babylon7WebXRLayers">https://aka.ms/babylon7WebXRLayers</a> and <a href="https://aka.ms/babylon7WebXRHC">https://aka.ms/babylon7WebXRHC</a>

https://youtu.be/UQogk_INTk8
<h3><strong>Apple Vision Pro Support</strong></h3>
Apple’s Vision Pro is an exciting product that provides a blending of the real and virtual worlds in fascinating new ways. We are excited to share that Babylon.js 7.0 adds full support for Vision Pro allowing Apple fans to experience immersive worlds through the web at the push of a button.

If you have an Apple Vision Pro, dive into a Babylon.js world here: <a href="https://aka.ms/babylon7VPDemo">https://aka.ms/babylon7VPDemo</a>

https://youtu.be/KrkcPssn-_g
<h3><strong>Advanced Animation System Updates</strong></h3>
The world of computer animation is always evolving and Babylon.js evolves hand in hand with it. Babylon.js 7.0 brings some exciting new features to the underlying animation engine, unlocking powerful new capabilities for real-time animations on the web. These updates add the ability to blend animation groups and mask specific portions of animations allowing creators to fine tune their experiences like never before. Interested in a forward walk cycle, blended with a sideways strafe, all with active morph target lip sync? It’s now all possible thanks to the exciting updates to the animation system.

Learn more: <a href="https://aka.ms/babylon7AnimGroupDoc">https://aka.ms/babylon7AnimGroupDoc</a>, <a href="https://aka.ms/babylon7AnimMaskDoc">https://aka.ms/babylon7AnimMaskDoc</a>

https://youtu.be/fTM5rYnEHqE
<h3><strong>State of the Art glTF support</strong></h3>
Every version of Babylon.js comes with updated support for the full glTF spec. This means you can always count on the Babylon platform to render the very state-of-the-art and cutting edge rendering advancements on the web. With Babylon.js 7.0, that rich tradition continues with the added support of the Dispersion and Anisotropy glTF extensions.

KHR_materials_dispersion demo: <a href="https://aka.ms/babylon7Dispersion">https://aka.ms/babylon7Dispersion</a>

KHR_materials_anisotropy demo: <a href="https://aka.ms/babylon7Anisotropy">https://aka.ms/babylon7Anisotropy</a>

https://youtu.be/Q1_-lW3uSEU

Babylon.js is powered and supported by one of the most incredible open-source communities in the world. Tune in next time to learn more about the new features and extensions contributed by the community.]]></content:encoded>
					
		
		
			</item>
	</channel>
</rss>
